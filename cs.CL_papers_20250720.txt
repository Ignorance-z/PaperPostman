1: AdaptiSent: Context-Aware Adaptive Attention for Multimodal Aspect-Based  Sentiment Analysis
Authors: ['S M Rafiuddin', 'Sadia Kamal', 'Mohammed Rakib', 'Arunkumar Bagavathi', 'Atriya Sen']
Summary: We introduce AdaptiSent, a new framework for Multimodal Aspect-BasedSentiment Analysis (MABSA) that uses adaptive cross-modal attention mechanismsto improve sentiment classification and aspect term extraction from both textand images. Our model integrates dynamic modality weighting andcontext-adaptive attention, enhancing the extraction of sentiment andaspect-related information by focusing on how textual cues and visual contextinteract. We tested our approach against several baselines, includingtraditional text-based models and other multimodal methods. Results fromstandard Twitter datasets show that AdaptiSent surpasses existing models inprecision, recall, and F1 score, and is particularly effective in identifyingnuanced inter-modal relationships that are crucial for accurate sentiment andaspect term extraction. This effectiveness comes from the model's ability toadjust its focus dynamically based on the context's relevance, improving thedepth and accuracy of sentiment analysis across various multimodal data sets.AdaptiSent sets a new standard for MABSA, significantly outperforming currentmethods, especially in understanding complex multimodal information.
Link: http://arxiv.org/abs/2507.12695v1

2: AudioJudge: Understanding What Works in Large Audio Model Based Speech  Evaluation
Authors: ['Potsawee Manakul', 'Woody Haosheng Gan', 'Michael J. Ryan', 'Ali Sartaz Khan', 'Warit Sirichotedumrong', 'Kunat Pipatanakul', 'William Held', 'Diyi Yang']
Summary: Current speech evaluation suffers from two critical limitations: the need anddifficulty of designing specialized systems targeting individual audiocharacteristics, and poor correlation between automatic evaluation methods andhuman preferences. This work presents a systematic study of Large Audio Model(LAM) as a Judge, AudioJudge, investigating whether it can provide a unifiedevaluation framework that addresses both challenges. We systematically exploreAudioJudge across audio characteristic detection tasks, includingpronunciation, speaking rate, speaker identification and speech quality, andsystem-level human preference simulation for automated benchmarking. Weinvestigate different prompt engineering strategies, finding that audioconcatenation combined with in-context learning significantly improvesperformance across both audio characteristic detection and human preferencesimulation tasks. We further introduce a multi-aspect ensemble AudioJudge toenable general-purpose multi-aspect audio evaluation. This method decomposesspeech assessment into specialized judges for lexical content, speech quality,and paralinguistic features, achieving up to 0.91 Spearman correlation withhuman preferences on our system ranking benchmark. Robustness analysis revealsthat while LAMs maintain strong performance under acoustic noise, they exhibitsignificant verbosity and positional biases that require careful mitigation.
Link: http://arxiv.org/abs/2507.12705v1

3: FLEXITOKENS: Flexible Tokenization for Evolving Language Models
Authors: ['Abraham Toluase Owodunni', 'Orevaoghene Ahia', 'Sachin Kumar']
Summary: Language models (LMs) are challenging to adapt to new data distributions bysimple finetuning. This is due to the rigidity of their subword tokenizers,which typically remain unchanged during adaptation. This inflexibility oftenleads to inefficient tokenization, causing overfragmentation ofout-of-distribution domains, unseen languages, or scripts. In this work, wedevelop byte-level LMs with learnable tokenizers to make tokenization adaptive.Our models include a submodule that learns to predict boundaries between theinput byte sequence, encoding it into variable-length segments. Existingtokenizer-free methods train this boundary predictor using an auxiliary lossthat enforces a fixed compression rate across the training corpus, introducinga new kind of rigidity. We propose FLEXITOKENS, a simplified training objectivethat enables significantly greater flexibility during adaptation. Evaluatingacross multiple multilingual benchmarks, morphologically diverse tasks, anddomains, we demonstrate that FLEXITOKENS consistently reduces tokenover-fragmentation and achieves up to 10\% improvements on downstream taskperformance compared to subword and other gradient-based tokenizers. Code anddata for our experiments will be released athttps://github.com/owos/flexitokens
Link: http://arxiv.org/abs/2507.12720v1

4: TransEvalnia: Reasoning-based Evaluation and Ranking of Translations
Authors: ['Richard Sproat', 'Tianyu Zhao', 'Llion Jones']
Summary: We present TransEvalnia, a prompting-based translation evaluation and rankingsystem that uses reasoning in performing its evaluations and ranking. Thissystem presents fine-grained evaluations based on a subset of theMultidimensional Quality Metrics (https://themqm.org/), returns an assessmentof which translation it deems the best, and provides numerical scores for thevarious dimensions and for the overall translation. We show that TransEvalniaperforms as well as or better than the state-of-the-art MT-Ranker (Moosa et al.2024) on our own English-Japanese data as well as several language pairs fromvarious WMT shared tasks. Using Anthropic's Claude-3.5-Sonnet andQwen-2.5-72B-Instruct as the evaluation LLMs, we show that the evaluationsreturned are deemed highly acceptable to human raters, and that the scoresassigned to the translations by Sonnet, as well as other LLMs, correlate wellwith scores assigned by the human raters. We also note the sensitivity of oursystem -- as well as MT-Ranker -- to the order in which the translations arepresented, and we propose methods to address this position bias. All data,including the system's evaluation and reasoning, human assessments, as well ascode is released.
Link: http://arxiv.org/abs/2507.12724v1

5: Strategy Adaptation in Large Language Model Werewolf Agents
Authors: ['Fuya Nakamori', 'Yin Jou Huang', 'Fei Cheng']
Summary: This study proposes a method to improve the performance of Werewolf agents byswitching between predefined strategies based on the attitudes of other playersand the context of conversations. While prior works of Werewolf agents usingprompt engineering have employed methods where effective strategies areimplicitly defined, they cannot adapt to changing situations. In this research,we propose a method that explicitly selects an appropriate strategy based onthe game context and the estimated roles of other players. We compare thestrategy adaptation Werewolf agents with baseline agents using implicit orfixed strategies and verify the effectiveness of our proposed method.
Link: http://arxiv.org/abs/2507.12732v1

6: Logit Arithmetic Elicits Long Reasoning Capabilities Without Training
Authors: ['Yunxiang Zhang', 'Muhammad Khalifa', 'Lechen Zhang', 'Xin Liu', 'Ayoung Lee', 'Xinliang Frederick Zhang', 'Farima Fatahi Bayat', 'Lu Wang']
Summary: Large reasoning models (LRMs) can do complex reasoning via longchain-of-thought (CoT) involving cognitive strategies such as backtracking andself-correction. Recent studies suggest that some models inherently possessthese long reasoning abilities, which may be unlocked via extra training. Ourwork first investigates whether we can elicit such behavior without anytraining. To this end, we propose a decoding-time approach, ThinkLogit, whichutilizes logits arithmetic (Liu et al., 2024) to tune a target large LM forlong reasoning using a substantially smaller model as guider. We then show thatwe can further boost performance by training the guider model with preferenceoptimization over correct/incorrect reasoning pairs sampled from both thetarget and guider model -- a setup we refer to as ThinkLogit-DPO. Ourexperiments demonstrate that ThinkLogit and ThinkLogit-DPO achieve a relativeimprovement in pass@1 by 26% and 29%, respectively, over four mathematicaldatasets using the Qwen2.5-32B when guided by R1-Distill-Qwen-1.5B -- a model21x smaller. Lastly, we show that ThinkLogit can transfer long reasoning skillsacquired through reinforcement learning, improving pass@1 by 13% relativecompared to the Qwen2.5-32B base model. Our work presents acomputationally-efficient method to elicit long reasoning in large models withminimal or no additional training.
Link: http://arxiv.org/abs/2507.12759v1

7: Synergy: End-to-end Concept Model
Authors: ['Keli Zheng', 'Zerong Xie']
Summary: In this paper, we present Synergy, a language model that bridges differentlevels of abstraction in an end-to-end fashion through a learned routingmechanism. Focusing on low-level linguistic abstraction, we trained our modelas a byte-level language model. Our model spontaneously learns to tokenizebytes, producing fewer concept tokens than Byte-level Byte Pair Encoder (BBPE)tokenizers while keeping comparable performance. By comparing with Llama3, weobserved an advantage of Synergy under the same model scale and trainingdataset size. Further studies show that the middle part (the higher abstractionpart) of our model performs better when positional encodings are removed,suggesting the emergence of position-independent concepts. These findingsdemonstrate the feasibility of tokenizer-free architectures, paving the way formore robust and flexible pipelines.
Link: http://arxiv.org/abs/2507.12769v1

8: A Comprehensive Survey of Electronic Health Record Modeling: From Deep  Learning Approaches to Large Language Models
Authors: ['Weijieying Ren', 'Jingxi Zhu', 'Zehao Liu', 'Tianxiang Zhao', 'Vasant Honavar']
Summary: Artificial intelligence (AI) has demonstrated significant potential intransforming healthcare through the analysis and modeling of electronic healthrecords (EHRs). However, the inherent heterogeneity, temporal irregularity, anddomain-specific nature of EHR data present unique challenges that differfundamentally from those in vision and natural language tasks. This surveyoffers a comprehensive overview of recent advancements at the intersection ofdeep learning, large language models (LLMs), and EHR modeling. We introduce aunified taxonomy that spans five key design dimensions: data-centricapproaches, neural architecture design, learning-focused strategies, multimodallearning, and LLM-based modeling systems. Within each dimension, we reviewrepresentative methods addressing data quality enhancement, structural andtemporal representation, self-supervised learning, and integration withclinical knowledge. We further highlight emerging trends such as foundationmodels, LLM-driven clinical agents, and EHR-to-text translation for downstreamreasoning. Finally, we discuss open challenges in benchmarking, explainability,clinical alignment, and generalization across diverse clinical settings. Thissurvey aims to provide a structured roadmap for advancing AI-driven EHRmodeling and clinical decision support. For a comprehensive list of EHR-relatedmethods, kindly refer to https://survey-on-tabular-data.github.io/.
Link: http://arxiv.org/abs/2507.12774v1

9: Learning Robust Negation Text Representations
Authors: ['Thinh Hung Truong', 'Karin Verspoor', 'Trevor Cohn', 'Timothy Baldwin']
Summary: Despite rapid adoption of autoregressive large language models, smaller textencoders still play an important role in text understanding tasks that requirerich contextualized representations. Negation is an important semantic functionthat is still not properly captured by such methods, affecting many downstreamapplications relying on text embeddings. We propose a strategy to improvenegation robustness of text encoders, by distilling data from large languagemodels using diverse patterns of negation and hedging. We adopt a standardcontrastive learning strategy to finetune a strong BERT-based model, andobserve large improvement in negation understanding capabilities whilemaintaining competitive performance on general benchmarks. In addition, we alsoshow that our method can be adapted to LLMs, leading to improved performance onnegation benchmarks.
Link: http://arxiv.org/abs/2507.12782v1

10: PMKLC: Parallel Multi-Knowledge Learning-based Lossless Compression for  Large-Scale Genomics Database
Authors: ['Hui Sun', 'Yanfeng Ding', 'Liping Yi', 'Huidong Ma', 'Gang Wang', 'Xiaoguang Liu', 'Cheng Zhong', 'Wentong Cai']
Summary: Learning-based lossless compressors play a crucial role in large-scalegenomic database backup, storage, transmission, and management. However, their1) inadequate compression ratio, 2) low compression \& decompressionthroughput, and 3) poor compression robustness limit their widespread adoptionand application in both industry and academia. To solve those challenges, wepropose a novel \underline{P}arallel \underline{M}ulti-\underline{K}nowledge\underline{L}earning-based \underline{C}ompressor (PMKLC) with four crucialdesigns: 1) We propose an automated multi-knowledge learning-based compressionframework as compressors' backbone to enhance compression ratio and robustness;2) we design a GPU-accelerated ($s$,$k$)-mer encoder to optimize compressionthroughput and computing resource usage; 3) we introduce data blockpartitioning and Step-wise Model Passing (SMP) mechanisms for parallelacceleration; 4) We design two compression modes PMKLC-S and PMKLC-M to meetthe complex application scenarios, where the former runs on aresource-constrained single GPU and the latter is multi-GPU accelerated. Webenchmark PMKLC-S/M and 14 baselines (7 traditional and 7 leaning-based) on 15real-world datasets with different species and data sizes. Compared tobaselines on the testing datasets, PMKLC-S/M achieve the average compressionratio improvement up to 73.609\% and 73.480\%, the average throughputimprovement up to 3.036$\times$ and 10.710$\times$, respectively. Besides,PMKLC-S/M also achieve the best robustness and competitive memory cost,indicating its greater stability against datasets with different probabilitydistribution perturbations, and its strong ability to run on memory-constraineddevices.
Link: http://arxiv.org/abs/2507.12805v1

11: MCPEval: Automatic MCP-based Deep Evaluation for AI Agent Models
Authors: ['Zhiwei Liu', 'Jielin Qiu', 'Shiyu Wang', 'Jianguo Zhang', 'Zuxin Liu', 'Roshan Ram', 'Haolin Chen', 'Weiran Yao', 'Huan Wang', 'Shelby Heinecke', 'Silvio Savarese', 'Caiming Xiong']
Summary: The rapid rise of Large Language Models (LLMs)-based intelligent agentsunderscores the need for robust, scalable evaluation frameworks. Existingmethods rely on static benchmarks and labor-intensive data collection, limitingpractical assessment. We introduce \oursystemname, an open-source Model ContextProtocol (MCP)-based framework that automates end-to-end task generation anddeep evaluation of LLM agents across diverse domains. MCPEval standardizesmetrics, seamlessly integrates with native agent tools, and eliminates manualeffort in building evaluation pipelines. Empirical results across fivereal-world domains show its effectiveness in revealing nuanced, domain-specificperformance. We publicly release MCPEvalhttps://github.com/SalesforceAIResearch/MCPEval to promote reproducible andstandardized LLM agent evaluation.
Link: http://arxiv.org/abs/2507.12806v1

12: Large Language Models' Internal Perception of Symbolic Music
Authors: ['Andrew Shin', 'Kunitake Kaneko']
Summary: Large language models (LLMs) excel at modeling relationships between stringsin natural language and have shown promise in extending to other symbolicdomains like coding or mathematics. However, the extent to which theyimplicitly model symbolic music remains underexplored. This paper investigateshow LLMs represent musical concepts by generating symbolic music data fromtextual prompts describing combinations of genres and styles, and evaluatingtheir utility through recognition and generation tasks. We produce a dataset ofLLM-generated MIDI files without relying on explicit musical training. We thentrain neural networks entirely on this LLM-generated MIDI dataset and performgenre and style classification as well as melody completion, benchmarking theirperformance against established models. Our results demonstrate that LLMs caninfer rudimentary musical structures and temporal relationships from text,highlighting both their potential to implicitly encode musical patterns andtheir limitations due to a lack of explicit musical context, shedding light ontheir generative capabilities for symbolic music.
Link: http://arxiv.org/abs/2507.12808v1

13: Emotional Support with LLM-based Empathetic Dialogue Generation
Authors: ['Shiquan Wang', 'Ruiyu Fang', 'Zhongjiang He', 'Shuangyong Song', 'Yongxiang Li']
Summary: Emotional Support Conversation (ESC) aims to provide empathetic and effectiveemotional assistance through dialogue, addressing the growing demand for mentalhealth support. This paper presents our solution for the NLPCC 2025 Task 8 ESCevaluation, where we leverage large-scale language models enhanced by promptengineering and finetuning techniques. We explore both parameter-efficientLow-Rank Adaptation and full-parameter fine-tuning strategies to improve themodel's ability to generate supportive and contextually appropriate responses.Our best model ranked second in the competition, highlighting the potential ofcombining LLMs with effective adaptation methods for ESC tasks. Future workwill focus on further enhancing emotional understanding and responsepersonalization to build more practical and reliable emotional support systems.
Link: http://arxiv.org/abs/2507.12820v1

14: Are Knowledge and Reference in Multilingual Language Models  Cross-Lingually Consistent?
Authors: ['Xi Ai', 'Mahardika Krisna Ihsani', 'Min-Yen Kan']
Summary: Cross-lingual consistency should be considered to assess cross-lingualtransferability, maintain the factuality of the model knowledge acrosslanguages, and preserve the parity of language model performance. We are thusinterested in analyzing, evaluating, and interpreting cross-lingual consistencyfor factual knowledge. We examine code-mixed coreferential statements conveyedidentical knowledge across languages to study cross-lingual knowledgeconsistency. We use some interpretability approaches to analyze the behavior ofa model in cross-lingual contexts, discovering that multilingual models showdifferent levels of consistency, subject to language families, linguisticfactors, and a bottleneck in cross-lingual consistency on a particular layer.In addition, we evaluate common strategies aimed at improving multilingualperformance to observe whether these strategies can improve knowledgeconsistency at the same time. While knowledge is not cross-lingual consistencyin many cases, code-switching training and cross-lingual word alignmentobjectives show the most promising results, emphasizing the noteworthiness ofcross-lingual alignment supervision and code-switching training for bothmultilingual performance and cross-lingual consistency enhancement.
Link: http://arxiv.org/abs/2507.12838v1

15: Making Language Model a Hierarchical Classifier and Generator
Authors: ['Yihong Wang', 'Zhonglin Jiang', 'Ningyuan Xi', 'Yue Zhao', 'Qingqing Gu', 'Xiyuan Chen', 'Hao Wu', 'Sheng Xu', 'Hange Zhou', 'Yong Chen', 'Luo Ji']
Summary: Decoder-only language models, such as GPT and LLaMA, generally decode on thelast layer. Motivated by human's hierarchical thinking capability, we proposethat a hierarchical decoder architecture could be built with different layersdecoding texts simultaneously. Due to limited time and computationallyresources, we choose to adapt a pretrained language model into this form ofhierarchical decoder. Language heads of the last layer are copied to differentselected intermediate layers, and fine-tuned with different task inputs. Bythorough experiments, we validate that these selective intermediate layerscould be adapted to speak meaningful and reasonable contents, and this paradigmof hierarchical decoder can obtain state-of-the-art performances on multipletasks such as hierarchical text classification, classification-guidedgeneration, and hierarchical text generation. This study suggests thepossibility of a generalized hierarchical reasoner, pretraining from scratch.
Link: http://arxiv.org/abs/2507.12930v1

16: Probabilistic Soundness Guarantees in LLM Reasoning Chains
Authors: ['Weiqiu You', 'Anton Xue', 'Shreya Havaldar', 'Delip Rao', 'Helen Jin', 'Chris Callison-Burch', 'Eric Wong']
Summary: In reasoning chains generated by large language models (LLMs), initial errorsoften propagate and undermine the reliability of the final conclusion. CurrentLLM-based error detection methods often fail to detect propagated errorsbecause they do not properly account for how earlier errors might corruptjudgments of downstream reasoning. To better detect such propagated errors, weintroduce Autoregressive Reasoning Entailment Stability (ARES), a novelprobabilistic framework that prevents error propagation by judging each claimbased only on previously-assessed sound premises. This inductive method yieldsa nuanced score for each step and provides certified statistical guarantees ofits soundness, rather than a brittle binary label. ARES achievesstate-of-the-art performance across four benchmarks (72.1% Macro-F1, +8.2points) and demonstrates superior robustness on very long synthetic reasoningchains, where it excels at detecting propagated errors (90.3% F1, +27.6points).
Link: http://arxiv.org/abs/2507.12948v1

17: UniSLU: Unified Spoken Language Understanding from Heterogeneous  Cross-Task Datasets
Authors: ['Zhichao Sheng', 'Shilin Zhou', 'Chen Gong', 'Zhenghua Li']
Summary: Spoken Language Understanding (SLU) plays a crucial role in speech-centricmultimedia applications, enabling machines to comprehend spoken language inscenarios such as meetings, interviews, and customer service interactions. SLUencompasses multiple tasks, including Automatic Speech Recognition (ASR),spoken Named Entity Recognition (NER), and spoken Sentiment Analysis (SA).However, existing methods often rely on separate model architectures forindividual tasks such as spoken NER and SA, which increases system complexity,limits cross-task interaction, and fails to fully exploit heterogeneousdatasets available across tasks. To address these limitations, we proposeUniSLU, a unified framework that jointly models multiple SLU tasks within asingle architecture. Specifically, we propose a unified representation fordiverse SLU tasks, enabling full utilization of heterogeneous datasets acrossmultiple tasks. Built upon this representation, we propose a unified generativemethod that jointly models ASR, spoken NER, and SA tasks, enhancing taskinteractions and enabling seamless integration with large language models toharness their powerful generative capabilities. Extensive experiments on publicSLU datasets demonstrate the effectiveness of our approach, achieving superiorSLU performance compared to several benchmark methods, making it well-suitedfor real-world speech-based multimedia scenarios. We will release all code andmodels at github to facilitate future research.
Link: http://arxiv.org/abs/2507.12951v1

18: MRT at IberLEF-2025 PRESTA Task: Maximizing Recovery from Tables with  Multiple Steps
Authors: ['Maximiliano Hormazábal Lagos', 'Álvaro Bueno Sáez', 'Héctor Cerezo-Costas', 'Pedro Alonso Doval', 'Jorge Alcalde Vesteiro']
Summary: This paper presents our approach for the IberLEF 2025 Task PRESTA: Preguntasy Respuestas sobre Tablas en Espa\~nol (Questions and Answers about Tables inSpanish). Our solution obtains answers to the questions by implementing Pythoncode generation with LLMs that is used to filter and process the table. Thissolution evolves from the MRT implementation for the Semeval 2025 related task.The process consists of multiple steps: analyzing and understanding the contentof the table, selecting the useful columns, generating instructions in naturallanguage, translating these instructions to code, running it, and handlingpotential errors or exceptions. These steps use open-source LLMs andfine-grained optimized prompts for each step. With this approach, we achievedan accuracy score of 85\% in the task.
Link: http://arxiv.org/abs/2507.12981v1

19: Teach Old SAEs New Domain Tricks with Boosting
Authors: ['Nikita Koriagin', 'Yaroslav Aksenov', 'Daniil Laptev', 'Gleb Gerasimov', 'Nikita Balagansky', 'Daniil Gavrilov']
Summary: Sparse Autoencoders have emerged as powerful tools for interpreting theinternal representations of Large Language Models, yet they often fail tocapture domain-specific features not prevalent in their training corpora. Thispaper introduces a residual learning approach that addresses this featureblindness without requiring complete retraining. We propose training asecondary SAE specifically to model the reconstruction error of a pretrainedSAE on domain-specific texts, effectively capturing features missed by theprimary model. By summing the outputs of both models during inference, wedemonstrate significant improvements in both LLM cross-entropy and explainedvariance metrics across multiple specialized domains. Our experiments show thatthis method efficiently incorporates new domain knowledge into existing SAEswhile maintaining their performance on general tasks. This approach enablesresearchers to selectively enhance SAE interpretability for specific domains ofinterest, opening new possibilities for targeted mechanistic interpretabilityof LLMs.
Link: http://arxiv.org/abs/2507.12990v1

20: Rethinking the Embodied Gap in Vision-and-Language Navigation: A  Holistic Study of Physical and Visual Disparities
Authors: ['Liuyi Wang', 'Xinyuan Xia', 'Hui Zhao', 'Hanqing Wang', 'Tai Wang', 'Yilun Chen', 'Chengju Liu', 'Qijun Chen', 'Jiangmiao Pang']
Summary: Recent Vision-and-Language Navigation (VLN) advancements are promising, buttheir idealized assumptions about robot movement and control fail to reflectphysically embodied deployment challenges. To bridge this gap, we introduceVLN-PE, a physically realistic VLN platform supporting humanoid, quadruped, andwheeled robots. For the first time, we systematically evaluate severalego-centric VLN methods in physical robotic settings across different technicalpipelines, including classification models for single-step discrete actionprediction, a diffusion model for dense waypoint prediction, and a train-free,map-based large language model (LLM) integrated with path planning. Our resultsreveal significant performance degradation due to limited robot observationspace, environmental lighting variations, and physical challenges likecollisions and falls. This also exposes locomotion constraints for leggedrobots in complex environments. VLN-PE is highly extensible, allowing seamlessintegration of new scenes beyond MP3D, thereby enabling more comprehensive VLNevaluation. Despite the weak generalization of current models in physicaldeployment, VLN-PE provides a new pathway for improving cross-embodiment'soverall adaptability. We hope our findings and tools inspire the community torethink VLN limitations and advance robust, practical VLN models. The code isavailable at https://crystalsixone.github.io/vln_pe.github.io/.
Link: http://arxiv.org/abs/2507.13019v1

21: Formalizing Attack Scenario Description: A Proposed Model
Authors: ['Quentin Goux', 'Nadira Lammari']
Summary: Organizations face an ever-changing threat landscape. They must continuouslydedicate significant efforts to protect their assets, making their adoption ofincreased cybersecurity automation inevitable. However, process automationrequires formalization of input data. Through this paper, we address this needfor processes that use attack scenarios as input. Among these processes, onecan mention both the generation of scripts for attack simulation and trainingpurposes, as well as the analysis of attacks. Therefore, the paper's mainresearch contribution is a novel formal model that encompasses the attack'scontext description and its scenario. It is abstracted using UML class model.Once the description of our model done, we will show how it could serve anupstream attack analysis process. We will show also its use for an automaticgeneration of attack scripts in the context of cybersecurity training. Thesetwo uses cases constitute the second contribution of this present researchwork.
Link: http://arxiv.org/abs/2507.13076v1

22: SemCSE: Semantic Contrastive Sentence Embeddings Using LLM-Generated  Summaries For Scientific Abstracts
Authors: ['Marc Brinner', 'Sina Zarriess']
Summary: We introduce SemCSE, an unsupervised method for learning semantic embeddingsof scientific texts. Building on recent advances in contrastive learning fortext embeddings, our approach leverages LLM-generated summaries of scientificabstracts to train a model that positions semantically related summaries closertogether in the embedding space. This resulting objective ensures that themodel captures the true semantic content of a text, in contrast to traditionalcitation-based approaches that do not necessarily reflect semantic similarity.To validate this, we propose a novel benchmark designed to assess a model'sability to understand and encode the semantic content of scientific texts,demonstrating that our method enforces a stronger semantic separation withinthe embedding space. Additionally, we evaluate SemCSE on the comprehensiveSciRepEval benchmark for scientific text embeddings, where it achievesstate-of-the-art performance among models of its size, thus highlighting thebenefits of a semantically focused training approach.
Link: http://arxiv.org/abs/2507.13105v1

23: A Computational Framework to Identify Self-Aspects in Text
Authors: ['Jaya Caporusso', 'Matthew Purver', 'Senja Pollak']
Summary: This Ph.D. proposal introduces a plan to develop a computational framework toidentify Self-aspects in text. The Self is a multifaceted construct and it isreflected in language. While it is described across disciplines like cognitivescience and phenomenology, it remains underexplored in natural languageprocessing (NLP). Many of the aspects of the Self align with psychological andother well-researched phenomena (e.g., those related to mental health),highlighting the need for systematic NLP-based analysis. In line with this, weplan to introduce an ontology of Self-aspects and a gold-standard annotateddataset. Using this foundation, we will develop and evaluate conventionaldiscriminative models, generative large language models, and embedding-basedretrieval approaches against four main criteria: interpretability, ground-truthadherence, accuracy, and computational efficiency. Top-performing models willbe applied in case studies in mental health and empirical phenomenology.
Link: http://arxiv.org/abs/2507.13115v1

24: Assessing the Reliability of LLMs Annotations in the Context of  Demographic Bias and Model Explanation
Authors: ['Hadi Mohammadi', 'Tina Shahedi', 'Pablo Mosteiro', 'Massimo Poesio', 'Ayoub Bagheri', 'Anastasia Giachanou']
Summary: Understanding the sources of variability in annotations is crucial fordeveloping fair NLP systems, especially for tasks like sexism detection wheredemographic bias is a concern. This study investigates the extent to whichannotator demographic features influence labeling decisions compared to textcontent. Using a Generalized Linear Mixed Model, we quantify this inf luence,finding that while statistically present, demographic factors account for aminor fraction ( 8%) of the observed variance, with tweet content being thedominant factor. We then assess the reliability of Generative AI (GenAI) modelsas annotators, specifically evaluating if guiding them with demographicpersonas improves alignment with human judgments. Our results indicate thatsimplistic persona prompting often fails to enhance, and sometimes degrades,performance compared to baseline models. Furthermore, explainable AI (XAI)techniques reveal that model predictions rely heavily on content-specifictokens related to sexism, rather than correlates of demographiccharacteristics. We argue that focusing on content-driven explanations androbust annotation protocols offers a more reliable path towards fairness thanpotentially persona simulation.
Link: http://arxiv.org/abs/2507.13138v1

25: From Roots to Rewards: Dynamic Tree Reasoning with RL
Authors: ['Ahmed Bahloul', 'Simon Malberg']
Summary: Modern language models address complex questions through chain-of-thought(CoT) reasoning (Wei et al., 2023) and retrieval augmentation (Lewis et al.,2021), yet struggle with error propagation and knowledge integration.Tree-structured reasoning methods, particularly the ProbabilisticTree-of-Thought (ProbTree)(Cao et al., 2023) framework, mitigate these issuesby decomposing questions into hierarchical structures and selecting answersthrough confidence-weighted aggregation of parametric and retrieved knowledge(Yao et al., 2023). However, ProbTree's static implementation introduces twokey limitations: (1) the reasoning tree is fixed during the initialconstruction phase, preventing dynamic adaptation to intermediate results, and(2) each node requires exhaustive evaluation of all possible solutionstrategies, creating computational inefficiency. We present a dynamicreinforcement learning (Sutton and Barto, 2018) framework that transformstree-based reasoning into an adaptive process. Our approach incrementallyconstructs the reasoning tree based on real-time confidence estimates, whilelearning optimal policies for action selection (decomposition, retrieval, oraggregation). This maintains ProbTree's probabilistic rigor while improvingboth solution quality and computational efficiency through selective expansionand focused resource allocation. The work establishes a new paradigm fortreestructured reasoning that balances the reliability of probabilisticframeworks with the flexibility required for real-world question answeringsystems.
Link: http://arxiv.org/abs/2507.13142v1

26: Inverse Reinforcement Learning Meets Large Language Model Post-Training:  Basics, Advances, and Opportunities
Authors: ['Hao Sun', 'Mihaela van der Schaar']
Summary: In the era of Large Language Models (LLMs), alignment has emerged as afundamental yet challenging problem in the pursuit of more reliable,controllable, and capable machine intelligence. The recent success of reasoningmodels and conversational AI systems has underscored the critical role ofreinforcement learning (RL) in enhancing these systems, driving increasedresearch interest at the intersection of RL and LLM alignment. This paperprovides a comprehensive review of recent advances in LLM alignment through thelens of inverse reinforcement learning (IRL), emphasizing the distinctionsbetween RL techniques employed in LLM alignment and those in conventional RLtasks. In particular, we highlight the necessity of constructing neural rewardmodels from human data and discuss the formal and practical implications ofthis paradigm shift. We begin by introducing fundamental concepts in RL toprovide a foundation for readers unfamiliar with the field. We then examinerecent advances in this research agenda, discussing key challenges andopportunities in conducting IRL for LLM alignment. Beyond methodologicalconsiderations, we explore practical aspects, including datasets, benchmarks,evaluation metrics, infrastructure, and computationally efficient training andinference techniques. Finally, we draw insights from the literature onsparse-reward RL to identify open questions and potential research directions.By synthesizing findings from diverse studies, we aim to provide a structuredand critical overview of the field, highlight unresolved challenges, andoutline promising future directions for improving LLM alignment through RL andIRL techniques.
Link: http://arxiv.org/abs/2507.13158v1

27: Feature-based analysis of oral narratives from Afrikaans and isiXhosa  children
Authors: ['Emma Sharratt', 'Annelien Smith', 'Retief Louw', 'Daleen Klop', 'Febe de Wet', 'Herman Kamper']
Summary: Oral narrative skills are strong predictors of later literacy development.This study examines the features of oral narratives from children who wereidentified by experts as requiring intervention. Using simple machine learningmethods, we analyse recorded stories from four- and five-year-old Afrikaans-and isiXhosa-speaking children. Consistent with prior research, we identifylexical diversity (unique words) and length-based features (mean utterancelength) as indicators of typical development, but features like articulationrate prove less informative. Despite cross-linguistic variation inpart-of-speech patterns, the use of specific verbs and auxiliaries associatedwith goal-directed storytelling is correlated with a reduced likelihood ofrequiring intervention. Our analysis of two linguistically distinct languagesreveals both language-specific and shared predictors of narrative proficiency,with implications for early assessment in multilingual contexts.
Link: http://arxiv.org/abs/2507.13164v1

28: GEMMAS: Graph-based Evaluation Metrics for Multi Agent Systems
Authors: ['Jisoo Lee', 'Raeyoung Chang', 'Dongwook Kwon', 'Harmanpreet Singh', 'Nikhil Verma']
Summary: Multi-agent systems built on language models have shown strong performance oncollaborative reasoning tasks. However, existing evaluations focus only on thecorrectness of the final output, overlooking how inefficient communication andpoor coordination contribute to redundant reasoning and higher computationalcosts. We introduce GEMMAS, a graph-based evaluation framework that analyzesthe internal collaboration process by modeling agent interactions as a directedacyclic graph. To capture collaboration quality, we propose two process-levelmetrics: Information Diversity Score (IDS) to measure semantic variation ininter-agent messages, and Unnecessary Path Ratio (UPR) to quantify redundantreasoning paths. We evaluate GEMMAS across five benchmarks and highlightresults on GSM8K, where systems with only a 2.1% difference in accuracy differby 12.8% in IDS and 80% in UPR, revealing substantial variation in internalcollaboration. These findings demonstrate that outcome-only metrics areinsufficient for evaluating multi-agent performance and highlight theimportance of process-level diagnostics in designing more interpretable andresource-efficient collaborative AI systems.
Link: http://arxiv.org/abs/2507.13190v1

29: Automatically assessing oral narratives of Afrikaans and isiXhosa  children
Authors: ['R. Louw', 'E. Sharratt', 'F. de Wet', 'C. Jacobs', 'A. Smith', 'H. Kamper']
Summary: Developing narrative and comprehension skills in early childhood is criticalfor later literacy. However, teachers in large preschool classrooms struggle toaccurately identify students who require intervention. We present a system forautomatically assessing oral narratives of preschool children in Afrikaans andisiXhosa. The system uses automatic speech recognition followed by a machinelearning scoring model to predict narrative and comprehension scores. Forscoring predicted transcripts, we compare a linear model to a large languagemodel (LLM). The LLM-based system outperforms the linear model in most cases,but the linear system is competitive despite its simplicity. The LLM-basedsystem is comparable to a human expert in flagging children who requireintervention. We lay the foundation for automatic oral assessments inclassrooms, giving teachers extra capacity to focus on personalised support forchildren's learning.
Link: http://arxiv.org/abs/2507.13205v1

30: Enhancing Cross-task Transfer of Large Language Models via Activation  Steering
Authors: ['Xinyu Tang', 'Zhihao Lv', 'Xiaoxue Cheng', 'Junyi Li', 'Wayne Xin Zhao', 'Zujie Wen', 'Zhiqiang Zhang', 'Jun Zhou']
Summary: Large language models (LLMs) have shown impressive abilities in leveragingpretrained knowledge through prompting, but they often struggle with unseentasks, particularly in data-scarce scenarios. While cross-task in-contextlearning offers a direct solution for transferring knowledge across tasks, itstill faces critical challenges in terms of robustness, scalability, andefficiency. In this paper, we investigate whether cross-task transfer can beachieved via latent space steering without parameter updates or inputexpansion. Through an analysis of activation patterns in the latent space ofLLMs, we observe that the enhanced activations induced by in-context exampleshave consistent patterns across different tasks. Inspired by these findings, wepropose CAST, a novel Cross-task Activation Steering Transfer framework thatenables effective transfer by manipulating the model's internal activationstates. Our approach first selects influential and diverse samples fromhigh-resource tasks, then utilizes their contrastive representation-enhancedactivations to adapt LLMs to low-resource tasks. Extensive experiments acrossboth cross-domain and cross-lingual transfer settings show that our methodoutperforms competitive baselines and demonstrates superior scalability andlower computational costs.
Link: http://arxiv.org/abs/2507.13236v1

31: HATS: Hindi Analogy Test Set for Evaluating Reasoning in Large Language  Models
Authors: ['Ashray Gupta', 'Rohan Joseph', 'Sunny Rai']
Summary: Analogies test a model's ability to infer implicit relationships betweenconcepts, making them a key benchmark for evaluating reasoning capabilities.While large language models (LLMs) are widely evaluated for reasoning inEnglish, their abilities in Indic languages remain understudied, limiting ourunderstanding of whether these models generalize across languages. To addressthis gap, we introduce a new Hindi Analogy Test Set (HATS), comprising 405multiple-choice questions sourced from Indian government exams. We benchmarkstate-of-the-art multilingual LLMs using various prompting strategies andintroduce a grounded Chain of Thought approach that leverages cognitivetheories of analogical reasoning. This approach improves model performance onHindi analogy questions. Our experiments show that models perform best withEnglish prompts, irrespective of the prompting strategy. Our test set addressesthe lack of a critical resource to evaluate LLM reasoning capabilities inHindi.
Link: http://arxiv.org/abs/2507.13238v1

32: Automating Steering for Safe Multimodal Large Language Models
Authors: ['Lyucheng Wu', 'Mengru Wang', 'Ziwen Xu', 'Tri Cao', 'Nay Oo', 'Bryan Hooi', 'Shumin Deng']
Summary: Recent progress in Multimodal Large Language Models (MLLMs) has unlockedpowerful cross-modal reasoning abilities, but also raised new safety concerns,particularly when faced with adversarial multimodal inputs. To improve thesafety of MLLMs during inference, we introduce a modular and adaptiveinference-time intervention technology, AutoSteer, without requiring anyfine-tuning of the underlying model. AutoSteer incorporates three corecomponents: (1) a novel Safety Awareness Score (SAS) that automaticallyidentifies the most safety-relevant distinctions among the model's internallayers; (2) an adaptive safety prober trained to estimate the likelihood oftoxic outputs from intermediate representations; and (3) a lightweight RefusalHead that selectively intervenes to modulate generation when safety risks aredetected. Experiments on LLaVA-OV and Chameleon across diverse safety-criticalbenchmarks demonstrate that AutoSteer significantly reduces the Attack SuccessRate (ASR) for textual, visual, and cross-modal threats, while maintaininggeneral abilities. These findings position AutoSteer as a practical,interpretable, and effective framework for safer deployment of multimodal AIsystems.
Link: http://arxiv.org/abs/2507.13255v1

33: QuestA: Expanding Reasoning Capacity in LLMs via Question Augmentation
Authors: ['Jiazheng Li', 'Hong Lu', 'Kaiyue Wen', 'Zaiwen Yang', 'Jiaxuan Gao', 'Hongzhou Lin', 'Yi Wu', 'Jingzhao Zhang']
Summary: Reinforcement learning (RL) has become a key component in training largelanguage reasoning models (LLMs). However, recent studies questions itseffectiveness in improving multi-step reasoning-particularly on hard problems.To address this challenge, we propose a simple yet effective strategy viaQuestion Augmentation: introduce partial solutions during training to reduceproblem difficulty and provide more informative learning signals. Our method,QuestA, when applied during RL training on math reasoning tasks, not onlyimproves pass@1 but also pass@k-particularly on problems where standard RLstruggles to make progress. This enables continual improvement over strongopen-source models such as DeepScaleR and OpenMath Nemotron, further enhancingtheir reasoning capabilities. We achieve new state-of-the-art results on mathbenchmarks using 1.5B-parameter models: 67.1% (+5.3%) on AIME24, 59.5% (+10.0%)on AIME25, and 35.5% (+4.0%) on HMMT25. Further, we provide theoreticalexplanations that QuestA improves sample efficiency, offering a practical andgeneralizable pathway for expanding reasoning capability through RL.
Link: http://arxiv.org/abs/2507.13266v1

34: Overview of the TalentCLEF 2025: Skill and Job Title Intelligence for  Human Capital Management
Authors: ['Luis Gasco', 'Hermenegildo Fabregat', 'Laura García-Sardiña', 'Paula Estrella', 'Daniel Deniz', 'Alvaro Rodrigo', 'Rabih Zbib']
Summary: Advances in natural language processing and large language models are drivinga major transformation in Human Capital Management, with a growing interest inbuilding smart systems based on language technologies for talent acquisition,upskilling strategies, and workforce planning. However, the adoption andprogress of these technologies critically depend on the development of reliableand fair models, properly evaluated on public data and open benchmarks, whichhave so far been unavailable in this domain.  To address this gap, we present TalentCLEF 2025, the first evaluationcampaign focused on skill and job title intelligence. The lab consists of twotasks: Task A - Multilingual Job Title Matching, covering English, Spanish,German, and Chinese; and Task B - Job Title-Based Skill Prediction, in English.Both corpora were built from real job applications, carefully anonymized, andmanually annotated to reflect the complexity and diversity of real-world labormarket data, including linguistic variability and gender-marked expressions.  The evaluations included monolingual and cross-lingual scenarios and coveredthe evaluation of gender bias.  TalentCLEF attracted 76 registered teams with more than 280 submissions. Mostsystems relied on information retrieval techniques built with multilingualencoder-based models fine-tuned with contrastive learning, and several of themincorporated large language models for data augmentation or re-ranking. Theresults show that the training strategies have a larger effect than the size ofthe model alone. TalentCLEF provides the first public benchmark in this fieldand encourages the development of robust, fair, and transferable languagetechnologies for the labor market.
Link: http://arxiv.org/abs/2507.13275v1

35: Multi-Agent Synergy-Driven Iterative Visual Narrative Synthesis
Authors: ['Wang Xi', 'Quan Shi', 'Tian Yu', 'Yujie Peng', 'Jiayi Sun', 'Mengxing Ren', 'Zenghui Ding', 'Ningguang Yao']
Summary: Automated generation of high-quality media presentations is challenging,requiring robust content extraction, narrative planning, visual design, andoverall quality optimization. Existing methods often produce presentations withlogical inconsistencies and suboptimal layouts, thereby struggling to meetprofessional standards. To address these challenges, we introduce RCPS(Reflective Coherent Presentation Synthesis), a novel framework integratingthree key components: (1) Deep Structured Narrative Planning; (2) AdaptiveLayout Generation; (3) an Iterative Optimization Loop. Additionally, we proposePREVAL, a preference-based evaluation framework employing rationale-enhancedmulti-dimensional models to assess presentation quality across Content,Coherence, and Design. Experimental results demonstrate that RCPS significantlyoutperforms baseline methods across all quality dimensions, producingpresentations that closely approximate human expert standards. PREVAL showsstrong correlation with human judgments, validating it as a reliable automatedtool for assessing presentation quality.
Link: http://arxiv.org/abs/2507.13285v1

36: AbGen: Evaluating Large Language Models in Ablation Study Design and  Evaluation for Scientific Research
Authors: ['Yilun Zhao', 'Weiyuan Chen', 'Zhijian Xu', 'Manasi Patwardhan', 'Yixin Liu', 'Chengye Wang', 'Lovekesh Vig', 'Arman Cohan']
Summary: We introduce AbGen, the first benchmark designed to evaluate the capabilitiesof LLMs in designing ablation studies for scientific research. AbGen consistsof 1,500 expert-annotated examples derived from 807 NLP papers. In thisbenchmark, LLMs are tasked with generating detailed ablation study designs fora specified module or process based on the given research context. Ourevaluation of leading LLMs, such as DeepSeek-R1-0528 and o4-mini, highlights asignificant performance gap between these models and human experts in terms ofthe importance, faithfulness, and soundness of the ablation study designs.Moreover, we demonstrate that current automated evaluation methods are notreliable for our task, as they show a significant discrepancy when compared tohuman assessment. To better investigate this, we develop AbGen-Eval, ameta-evaluation benchmark designed to assess the reliability of commonly usedautomated evaluation systems in measuring LLM performance on our task. Weinvestigate various LLM-as-Judge systems on AbGen-Eval, providing insights forfuture research on developing more effective and reliable LLM-based evaluationsystems for complex scientific tasks.
Link: http://arxiv.org/abs/2507.13300v1

37: The Generative Energy Arena (GEA): Incorporating Energy Awareness in  Large Language Model (LLM) Human Evaluations
Authors: ['Carlos Arriaga', 'Gonzalo Martínez', 'Eneko Sendin', 'Javier Conde', 'Pedro Reviriego']
Summary: The evaluation of large language models is a complex task, in which severalapproaches have been proposed. The most common is the use of automatedbenchmarks in which LLMs have to answer multiple-choice questions of differenttopics. However, this method has certain limitations, being the mostconcerning, the poor correlation with the humans. An alternative approach, isto have humans evaluate the LLMs. This poses scalability issues as there is alarge and growing number of models to evaluate making it impractical (andcostly) to run traditional studies based on recruiting a number of evaluatorsand having them rank the responses of the models. An alternative approach isthe use of public arenas, such as the popular LM arena, on which any user canfreely evaluate models on any question and rank the responses of two models.The results are then elaborated into a model ranking. An increasingly importantaspect of LLMs is their energy consumption and, therefore, evaluating howenergy awareness influences the decisions of humans in selecting a model is ofinterest. In this paper, we present GEA, the Generative Energy Arena, an arenathat incorporates information on the energy consumption of the model in theevaluation process. Preliminary results obtained with GEA are also presented,showing that for most questions, when users are aware of the energyconsumption, they favor smaller and more energy efficient models. This suggeststhat for most user interactions, the extra cost and energy incurred by the morecomplex and top-performing models do not provide an increase in the perceivedquality of the responses that justifies their use.
Link: http://arxiv.org/abs/2507.13302v1

38: HapticCap: A Multimodal Dataset and Task for Understanding User  Experience of Vibration Haptic Signals
Authors: ['Guimin Hu', 'Daniel Hershcovich', 'Hasti Seifi']
Summary: Haptic signals, from smartphone vibrations to virtual reality touch feedback,can effectively convey information and enhance realism, but designing signalsthat resonate meaningfully with users is challenging. To facilitate this, weintroduce a multimodal dataset and task, of matching user descriptions tovibration haptic signals, and highlight two primary challenges: (1) lack oflarge haptic vibration datasets annotated with textual descriptions ascollecting haptic descriptions is time-consuming, and (2) limited capability ofexisting tasks and models to describe vibration signals in text. To advancethis area, we create HapticCap, the first fully human-annotatedhaptic-captioned dataset, containing 92,070 haptic-text pairs for userdescriptions of sensory, emotional, and associative attributes of vibrations.Based on HapticCap, we propose the haptic-caption retrieval task and presentthe results of this task from a supervised contrastive learning framework thatbrings together text representations within specific categories and vibrations.Overall, the combination of language model T5 and audio model AST yields thebest performance in the haptic-caption retrieval task, especially whenseparately trained for each description category.
Link: http://arxiv.org/abs/2507.13318v1

39: Social and Political Framing in Search Engine Results
Authors: ['Amrit Poudel', 'Tim Weninger']
Summary: Search engines play a crucial role in shaping public discourse by influencinghow information is accessed and framed. While prior research has extensivelyexamined various dimensions of search bias -- such as content prioritization,indexical bias, political polarization, and sources of bias -- an importantquestion remains underexplored: how do search engines andideologically-motivated user queries contribute to bias in search results. Thisstudy analyzes the outputs of major search engines using a dataset of politicaland social topics. The findings reveal that search engines not only prioritizecontent in ways that reflect underlying biases but also thatideologically-driven user queries exacerbate these biases, resulting in theamplification of specific narratives. Moreover, significant differences wereobserved across search engines in terms of the sources they prioritize. Theseresults suggest that search engines may play a pivotal role in shaping publicperceptions by reinforcing ideological divides, thereby contributing to thebroader issue of information polarization.
Link: http://arxiv.org/abs/2507.13325v1

40: Vision-and-Language Training Helps Deploy Taxonomic Knowledge but Does  Not Fundamentally Alter It
Authors: ['Yulu Qin', 'Dheeraj Varghese', 'Adam Dahlgren Lindström', 'Lucia Donatelli', 'Kanishka Misra', 'Najoung Kim']
Summary: Does vision-and-language (VL) training change the linguistic representationsof language models in meaningful ways? Most results in the literature haveshown inconsistent or marginal differences, both behaviorally andrepresentationally. In this work, we start from the hypothesis that the domainin which VL training could have a significant effect is lexical-conceptualknowledge, in particular its taxonomic organization. Through comparing minimalpairs of text-only LMs and their VL-trained counterparts, we first show thatthe VL models often outperform their text-only counterparts on a text-onlyquestion-answering task that requires taxonomic understanding of conceptsmentioned in the questions. Using an array of targeted behavioral andrepresentational analyses, we show that the LMs and VLMs do not differsignificantly in terms of their taxonomic knowledge itself, but they differ inhow they represent questions that contain concepts in a taxonomic relation vs.a non-taxonomic relation. This implies that the taxonomic knowledge itself doesnot change substantially through additional VL training, but VL training doesimprove the deployment of this knowledge in the context of a specific task,even when the presentation of the task is purely linguistic.
Link: http://arxiv.org/abs/2507.13328v1

41: The Imitation Game: Turing Machine Imitator is Length Generalizable  Reasoner
Authors: ['Zhouqi Hua', 'Wenwei Zhang', 'Chengqi Lyu', 'Yuzhe Gu', 'Songyang Gao', 'Kuikun Liu', 'Kai Chen']
Summary: Length generalization, the ability to solve problems of longer sequences thanthose observed during training, poses a core challenge of Transformer-basedlarge language models (LLM). Although existing studies have predominantlyfocused on data-driven approaches for arithmetic operations and symbolicmanipulation tasks, these approaches tend to be task-specific with limitedoverall performance. To pursue a more general solution, this paper focuses on abroader case of reasoning problems that are computable, i.e., problems thatalgorithms can solve, thus can be solved by the Turing Machine. From thisperspective, this paper proposes Turing MAchine Imitation Learning (TAIL) toimprove the length generalization ability of LLMs. TAIL synthesizeschain-of-thoughts (CoT) data that imitate the execution process of a TuringMachine by computer programs, which linearly expands the reasoning steps intoatomic states to alleviate shortcut learning and explicit memory fetchmechanism to reduce the difficulties of dynamic and long-range data access inelementary operations. To validate the reliability and universality of TAIL, weconstruct a challenging synthetic dataset covering 8 classes of algorithms and18 tasks. Without bells and whistles, TAIL significantly improves the lengthgeneralization ability as well as the performance of Qwen2.5-7B on varioustasks using only synthetic data, surpassing previous methods and DeepSeek-R1.The experimental results reveal that the key concepts in the Turing Machine,instead of the thinking styles, are indispensable for TAIL for lengthgeneralization, through which the model exhibits read-and-write behaviorsconsistent with the properties of the Turing Machine in their attention layers.This work provides a promising direction for future research in the learning ofLLM reasoning from synthetic data.
Link: http://arxiv.org/abs/2507.13332v1

42: A Survey of Context Engineering for Large Language Models
Authors: ['Lingrui Mei', 'Jiayu Yao', 'Yuyao Ge', 'Yiwei Wang', 'Baolong Bi', 'Yujun Cai', 'Jiazhi Liu', 'Mingyu Li', 'Zhong-Zhi Li', 'Duzhen Zhang', 'Chenlin Zhou', 'Jiayi Mao', 'Tianze Xia', 'Jiafeng Guo', 'Shenghua Liu']
Summary: The performance of Large Language Models (LLMs) is fundamentally determinedby the contextual information provided during inference. This survey introducesContext Engineering, a formal discipline that transcends simple prompt designto encompass the systematic optimization of information payloads for LLMs. Wepresent a comprehensive taxonomy decomposing Context Engineering into itsfoundational components and the sophisticated implementations that integratethem into intelligent systems. We first examine the foundational components:context retrieval and generation, context processing and context management. Wethen explore how these components are architecturally integrated to createsophisticated system implementations: retrieval-augmented generation (RAG),memory systems and tool-integrated reasoning, and multi-agent systems. Throughthis systematic analysis of over 1300 research papers, our survey not onlyestablishes a technical roadmap for the field but also reveals a criticalresearch gap: a fundamental asymmetry exists between model capabilities. Whilecurrent models, augmented by advanced context engineering, demonstrateremarkable proficiency in understanding complex contexts, they exhibitpronounced limitations in generating equally sophisticated, long-form outputs.Addressing this gap is a defining priority for future research. Ultimately,this survey provides a unified framework for both researchers and engineersadvancing context-aware AI.
Link: http://arxiv.org/abs/2507.13334v1

43: Comparing Apples to Oranges: A Dataset & Analysis of LLM Humour  Understanding from Traditional Puns to Topical Jokes
Authors: ['Tyler Loakman', 'William Thorne', 'Chenghua Lin']
Summary: Humour, as a complex language form, is derived from myriad aspects of life,whilst existing work on computational humour has focussed almost exclusively onshort pun-based jokes. In this work, we investigate whether the ability ofLarge Language Models (LLMs) to explain humour depends on the particular humourform. We compare models on simple puns and more complex topical humour thatrequires knowledge of real-world entities and events. In doing so, we curate adataset of 600 jokes split across 4 joke types and manually write high-qualityexplanations. These jokes include heterographic and homographic puns,contemporary internet humour, and topical jokes, where understanding relies onreasoning beyond "common sense", rooted instead in world knowledge regardingnews events and pop culture. Using this dataset, we compare the zero-shotabilities of a range of LLMs to accurately and comprehensively explain jokes ofdifferent types, identifying key research gaps in the task of humourexplanation. We find that none of the tested models (inc. reasoning models) arecapable of reliably generating adequate explanations of all joke types, furtherhighlighting the narrow focus of most works in computational humour on overlysimple joke forms.
Link: http://arxiv.org/abs/2507.13335v1

44: VisionThink: Smart and Efficient Vision Language Model via Reinforcement  Learning
Authors: ['Senqiao Yang', 'Junyi Li', 'Xin Lai', 'Bei Yu', 'Hengshuang Zhao', 'Jiaya Jia']
Summary: Recent advancements in vision-language models (VLMs) have improvedperformance by increasing the number of visual tokens, which are oftensignificantly longer than text tokens. However, we observe that most real-worldscenarios do not require such an extensive number of visual tokens. While theperformance drops significantly in a small subset of OCR-related tasks, modelsstill perform accurately in most other general VQA tasks with only 1/4resolution. Therefore, we propose to dynamically process distinct samples withdifferent resolutions, and present a new paradigm for visual token compression,namely, VisionThink. It starts with a downsampled image and smartly decideswhether it is sufficient for problem solving. Otherwise, the model could outputa special token to request the higher-resolution image. Compared to existingEfficient VLM methods that compress tokens using fixed pruning ratios orthresholds, VisionThink autonomously decides whether to compress tokens case bycase. As a result, it demonstrates strong fine-grained visual understandingcapability on OCR-related tasks, and meanwhile saves substantial visual tokenson simpler tasks. We adopt reinforcement learning and propose the LLM-as-Judgestrategy to successfully apply RL to general VQA tasks. Moreover, we carefullydesign a reward function and penalty mechanism to achieve a stable andreasonable image resize call ratio. Extensive experiments demonstrate thesuperiority, efficiency, and effectiveness of our method. Our code is availableat https://github.com/dvlab-research/VisionThink.
Link: http://arxiv.org/abs/2507.13348v1

