1: Towards Interpretable and Inference-Optimal COT Reasoning with Sparse  Autoencoder-Guided Generation
Authors: ['Daniel Zhao', 'Abhilash Shankarampeta', 'Lanxiang Hu', 'Tajana Rosing', 'Hao Zhang']
Summary: We propose a novel method that leverages sparse autoencoders (SAEs) andclustering techniques to analyze the internal token representations of largelanguage models (LLMs) and guide generations in mathematical reasoning tasks.Our approach first trains an SAE to generate sparse vector representations fortraining tokens, then applies k-means clustering to construct a graph wherevertices represent token clusters and weighted edges capture sequential tokentransitions. Using this graph, we define an edge-weight based reward functionto quantify adherence to established reasoning traces, thereby identifyingexploitative reasoning trajectories. Additionally, we measure generationdiversity from clustering to assess the extent of exploration. Our findingsindicate that balancing both exploitation and exploration is crucial forachieving high accuracy in mathematical reasoning tasks. During generation, theSAE can serve as a scalable reward model to guide generations, ensuring abalanced trade-off between exploitation and exploration. This prevents extremebehaviors in either direction, ultimately fostering a higher-quality reasoningprocess in LLMs.
Link: http://arxiv.org/abs/2510.01528v1
Updated: 2025-10-02T00:01:08Z

2: LOGicalThought: Logic-Based Ontological Grounding of LLMs for  High-Assurance Reasoning
Authors: ['Navapat Nananukul', 'Yue Zhang', 'Ryan Lee', 'Eric Boxer', 'Jonathan May', 'Vibhav Giridhar Gogate', 'Jay Pujara', 'Mayank Kejriwal']
Summary: High-assurance reasoning, particularly in critical domains such as law andmedicine, requires conclusions that are accurate, verifiable, and explicitlygrounded in evidence. This reasoning relies on premises codified from rules,statutes, and contracts, inherently involving defeasible or non-monotonic logicdue to numerous exceptions, where the introduction of a single fact caninvalidate general rules, posing significant challenges. While large languagemodels (LLMs) excel at processing natural language, their capabilities instandard inference tasks do not translate to the rigorous reasoning requiredover high-assurance text guidelines. Core reasoning challenges within suchtexts often manifest specific logical structures involving negation,implication, and, most critically, defeasible rules and exceptions. In thispaper, we propose a novel neurosymbolically-grounded architecture calledLOGicalThought (LogT) that uses an advanced logical language and reasoner inconjunction with an LLM to construct a dual symbolic graph context andlogic-based context. These two context representations transform the problemfrom inference over long-form guidelines into a compact grounded evaluation.Evaluated on four multi-domain benchmarks against four baselines, LogT improvesoverall performance by 11.84% across all LLMs. Performance improvessignificantly across all three modes of reasoning: by up to +10.2% on negation,+13.2% on implication, and +5.5% on defeasible reasoning compared to thestrongest baseline.
Link: http://arxiv.org/abs/2510.01530v1
Updated: 2025-10-02T00:06:23Z

3: Information Seeking for Robust Decision Making under Partial  Observability
Authors: ['Djengo Cyun-Jyun Fang', 'Tsung-Wei Ke']
Summary: Explicit information seeking is essential to human problem-solving inpractical environments characterized by incomplete information and noisydynamics. When the true environmental state is not directly observable, humansseek information to update their internal dynamics and inform futuredecision-making. Although existing Large Language Model (LLM) planning agentshave addressed observational uncertainty, they often overlook discrepanciesbetween their internal dynamics and the actual environment. We introduceInformation Seeking Decision Planner (InfoSeeker), an LLM decision-makingframework that integrates task-oriented planning with information seeking toalign internal dynamics and make optimal decisions under uncertainty in bothagent observations and environmental dynamics. InfoSeeker prompts an LLM toactively gather information by planning actions to validate its understanding,detect environmental changes, or test hypotheses before generating or revisingtask-oriented plans. To evaluate InfoSeeker, we introduce a novel benchmarksuite featuring partially observable environments with incomplete observationsand uncertain dynamics. Experiments demonstrate that InfoSeeker achieves a 74%absolute performance gain over prior methods without sacrificing sampleefficiency. Moreover, InfoSeeker generalizes across LLMs and outperformsbaselines on established benchmarks such as robotic manipulation and webnavigation. These findings underscore the importance of tightly integratingplanning and information seeking for robust behavior in partially observableenvironments. The project page is available at https://infoseekerllm.github.io
Link: http://arxiv.org/abs/2510.01531v1
Updated: 2025-10-02T00:06:32Z

4: Step-Aware Policy Optimization for Reasoning in Diffusion Large Language  Models
Authors: ['Shaoan Xie', 'Lingjing Kong', 'Xiangchen Song', 'Xinshuai Dong', 'Guangyi Chen', 'Eric P. Xing', 'Kun Zhang']
Summary: Diffusion language models (dLLMs) offer a promising, non-autoregressiveparadigm for text generation, yet training them for complex reasoning remains akey challenge. Current reinforcement learning approaches often rely on sparse,outcome-based rewards, which can reinforce flawed reasoning paths that lead tocoincidentally correct answers. We argue that this stems from a fundamentalmismatch with the natural structure of reasoning. We first propose atheoretical framework that formalizes complex problem solving as a hierarchicalselection process, where an intractable global constraint is decomposed into aseries of simpler, localized logical steps. This framework provides aprincipled foundation for algorithm design, including theoretical insights intothe identifiability of this latent reasoning structure. Motivated by thistheory, we identify unstructured refinement -- a failure mode where a model'siterative steps do not contribute meaningfully to the solution -- as a coredeficiency in existing methods. We then introduce Step-Aware PolicyOptimization (SAPO), a novel RL algorithm that aligns the dLLM's denoisingprocess with the latent reasoning hierarchy. By using a process-based rewardfunction that encourages incremental progress, SAPO guides the model to learnstructured, coherent reasoning paths. Our empirical results show that thisprincipled approach significantly improves performance on challenging reasoningbenchmarks and enhances the interpretability of the generation process.
Link: http://arxiv.org/abs/2510.01544v1
Updated: 2025-10-02T00:34:15Z

5: Predictive Preference Learning from Human Interventions
Authors: ['Haoyuan Cai', 'Zhenghao Peng', 'Bolei Zhou']
Summary: Learning from human involvement aims to incorporate the human subject tomonitor and correct agent behavior errors. Although most interactive imitationlearning methods focus on correcting the agent's action at the current state,they do not adjust its actions in future states, which may be potentially morehazardous. To address this, we introduce Predictive Preference Learning fromHuman Interventions (PPL), which leverages the implicit preference signalscontained in human interventions to inform predictions of future rollouts. Thekey idea of PPL is to bootstrap each human intervention into L future timesteps, called the preference horizon, with the assumption that the agentfollows the same action and the human makes the same intervention in thepreference horizon. By applying preference optimization on these future states,expert corrections are propagated into the safety-critical regions where theagent is expected to explore, significantly improving learning efficiency andreducing human demonstrations needed. We evaluate our approach with experimentson both autonomous driving and robotic manipulation benchmarks and demonstrateits efficiency and generality. Our theoretical analysis further shows thatselecting an appropriate preference horizon L balances coverage of risky stateswith label correctness, thereby bounding the algorithmic optimality gap. Demoand code are available at: https://metadriverse.github.io/ppl
Link: http://arxiv.org/abs/2510.01545v1
Updated: 2025-10-02T00:38:18Z

6: POLAR: Automating Cyber Threat Prioritization through LLM-Powered  Assessment
Authors: ['Luoxi Tang', 'Yuqiao Meng', 'Ankita Patra', 'Weicheng Ma', 'Muchao Ye', 'Zhaohan Xi']
Summary: Large Language Models (LLMs) are intensively used to assist security analystsin counteracting the rapid exploitation of cyber threats, wherein LLMs offercyber threat intelligence (CTI) to support vulnerability assessment andincident response. While recent work has shown that LLMs can support a widerange of CTI tasks such as threat analysis, vulnerability detection, andintrusion defense, significant performance gaps persist in practicaldeployments. In this paper, we investigate the intrinsic vulnerabilities ofLLMs in CTI, focusing on challenges that arise from the nature of the threatlandscape itself rather than the model architecture. Using large-scaleevaluations across multiple CTI benchmarks and real-world threat reports, weintroduce a novel categorization methodology that integrates stratification,autoregressive refinement, and human-in-the-loop supervision to reliablyanalyze failure instances. Through extensive experiments and human inspections,we reveal three fundamental vulnerabilities: spurious correlations,contradictory knowledge, and constrained generalization, that limit LLMs ineffectively supporting CTI. Subsequently, we provide actionable insights fordesigning more robust LLM-powered CTI systems to facilitate future research.
Link: http://arxiv.org/abs/2510.01552v1
Updated: 2025-10-02T00:49:20Z

7: Rethinking KL Regularization in RLHF: From Value Estimation to Gradient  Optimization
Authors: ['Kezhao Liu', 'Jason Klein Liu', 'Mingtao Chen', 'Yiming Liu']
Summary: Reinforcement Learning from Human Feedback (RLHF) leverages aKullback-Leibler (KL) divergence loss to stabilize training and preventoverfitting. However, in methods such as GRPO, its implementation may be guidedby principles from numerical value estimation-a practice that overlooks theterm's functional role as an optimization loss. To analyze this issue, weestablish a unified framework that connects two seemingly distinctimplementation styles: using the mathematical term $k_n$ as a detachedcoefficient for the policy's score function ('$k_n$ in reward') or as a directloss function through which gradients are propagated ('$k_n$ as loss'). We showthat the latter can always be analyzed via an equivalent gradient coefficientin the former, unifying the two perspectives. Through this framework, we provethat the conventional '$k_1$ in reward' (like in PPO) is the principled lossfor Reverse KL (RKL) regularization. We further establish a key finding: underon-policy conditions, the '$k_2$ as loss' formulation is, in fact,gradient-equivalent to '$k_1$ in reward'. This equivalence, first proven in ourwork, identifies both as the theoretically sound implementations of the RKLobjective. In contrast, we show that the recently adopted '$k_3$ as loss' (likein GRPO) is merely a first-order, biased approximation of the principled loss.Furthermore, we argue that common off-policy implementations of '$k_n$ as loss'methods are biased due to neglected importance sampling, and we propose aprincipled correction. Our findings provide a comprehensive, gradient-basedrationale for choosing and correctly implementing KL regularization, paving theway for more robust and effective RLHF systems.
Link: http://arxiv.org/abs/2510.01555v1
Updated: 2025-10-02T01:00:02Z

8: InvThink: Towards AI Safety via Inverse Reasoning
Authors: ['Yubin Kim', 'Taehan Kim', 'Eugene Park', 'Chunjong Park', 'Cynthia Breazeal', 'Daniel McDuff', 'Hae Won Park']
Summary: We present InvThink, a simple yet powerful approach that gives large languagemodels (LLMs) the capability of inverse thinking: reasoning through failuremodes before generating responses. Unlike existing safety alignment methodsthat optimize directly for safe response, InvThink instructs models to 1)enumerate potential harms, 2) analyze their consequences, and 3) generate safeoutputs that proactively avoid these risks. Our method reveals three keyfindings: (i) safety improvements show stronger scaling with model sizecompared to existing safety methods. (ii) InvThink mitigates safety tax; bytraining models to systematically consider failure modes, it preserves generalreasoning capabilities on standard benchmarks. (iii) beyond general safetytasks, InvThink excels in high-stakes domains including external-facing(medicine, finance, law) and agentic (blackmail, murder) risk scenarios,achieving up to 15.7% reduction in harmful responses compared to baselinemethods like SafetyPrompt. We further implement InvThink via supervisedfine-tuning, and reinforcement learning across three LLM families. Theseresults suggest that inverse reasoning provides a scalable and generalizablepath toward safer, more capable language models.
Link: http://arxiv.org/abs/2510.01569v1
Updated: 2025-10-02T01:26:53Z

9: From Supervision to Exploration: What Does Protein Language Model Learn  During Reinforcement Learning?
Authors: ['Hanqun Cao', 'Hongrui Zhang', 'Junde Xu', 'Zhou Zhang', 'Lingdong Shen', 'Minghao Sun', 'Ge Liu', 'Jinbo Xu', 'Wu-Jun Li', 'Jinren Ni', 'Cesar de la Fuente-Nunez', 'Tianfan Fu', 'Yejin Choi', 'Pheng-Ann Heng', 'Fang Wu']
Summary: Protein language models (PLMs) have advanced computational protein sciencethrough large-scale pretraining and scalable architectures. In parallel,reinforcement learning (RL) has broadened exploration and enabled precisemulti-objective optimization in protein design. Yet whether RL can push PLMsbeyond their pretraining priors to uncover latent sequence-structure-functionrules remains unclear. We address this by pairing RL with PLMs across fourdomains: antimicrobial peptide design, kinase variant optimization, antibodyengineering, and inverse folding. Using diverse RL algorithms and modelclasses, we ask if RL improves sampling efficiency and, more importantly, if itreveals capabilities not captured by supervised learning. Across benchmarks, RLconsistently boosts success rates and sample efficiency. Performance follows athree-factor interaction: task headroom, reward fidelity, and policy capacityjointly determine gains. When rewards are accurate and informative, policieshave sufficient capacity, and tasks leave room beyond supervised baselines,improvements scale; when rewards are noisy or capacity is constrained, gainssaturate despite exploration. This view yields practical guidance for RL inprotein design: prioritize reward modeling and calibration before scalingpolicy size, match algorithm and regularization strength to task difficulty,and allocate capacity where marginal gains are largest. Implementation isavailable at https://github.com/chq1155/RL-PLM.
Link: http://arxiv.org/abs/2510.01571v1
Updated: 2025-10-02T01:31:10Z

10: Synthetic Prefixes to Mitigate Bias in Real-Time Neural Query  Autocomplete
Authors: ['Adithya Rajan', 'Xiaoyu Liu', 'Prateek Verma', 'Vibhu Arora']
Summary: We introduce a data-centric approach for mitigating presentation bias inreal-time neural query autocomplete systems through the use of syntheticprefixes. These prefixes are generated from complete user queries collectedduring regular search sessions where autocomplete was not active. This allowsus to enrich the training data for learning to rank models with more diverseand less biased examples. This method addresses the inherent bias in engagementsignals collected from live query autocomplete interactions, where modelsuggestions influence user behavior. Our neural ranker is optimized forreal-time deployment under strict latency constraints and incorporates a richset of features, including query popularity, seasonality, fuzzy match scores,and contextual signals such as department affinity, device type, and verticalalignment with previous user queries. To support efficient training, weintroduce a task-specific simplification of the listwise loss, reducingcomputational complexity from $O(n^2)$ to $O(n)$ by leveraging the queryautocomplete structure of having only one ground-truth selection per prefix.Deployed in a large-scale e-commerce setting, our system demonstratesstatistically significant improvements in user engagement, as measured by meanreciprocal rank and related metrics. Our findings show that synthetic prefixesnot only improve generalization but also provide a scalable path toward biasmitigation in other low-latency ranking tasks, including related searches andquery recommendations.
Link: http://arxiv.org/abs/2510.01574v1
Updated: 2025-10-02T01:44:44Z

11: Guiding Multimodal Large Language Models with Blind and Low Vision  People Visual Questions for Proactive Visual Interpretations
Authors: ['Ricardo Gonzalez Penuela', 'Felipe Arias-Russi', 'Victor Capriles']
Summary: Multimodal large language models (MLLMs) have been integrated into visualinterpretation applications to support Blind and Low Vision (BLV) users becauseof their accuracy and ability to provide rich, human-like interpretations.However, these applications often default to comprehensive, lengthydescriptions regardless of context. This leads to inefficient exchanges, asusers must go through irrelevant details rather than receiving the specificinformation they are likely to seek. To deliver more contextually-relevantinformation, we developed a system that draws on historical BLV usersquestions. When given an image, our system identifies similar past visualcontexts from the VizWiz-LF dataset and uses the associated questions to guidethe MLLM generate descriptions more relevant to BLV users. An evaluation withthree human labelers who revised 92 context-aware and context-free descriptionsshowed that context-aware descriptions anticipated and answered users'questions in 76.1% of cases (70 out of 92) and were preferred in 54.4% ofcomparisons (50 out of 92). Our paper reviews, and data analysis are publiclyavailable in a Github repository athttps://github.com/rgonzalezp/guiding-multimodal-large-language-models-with-blind-and-low-vision-people-visual-questions .
Link: http://arxiv.org/abs/2510.01576v1
Updated: 2025-10-02T01:48:51Z

12: Think Right: Learning to Mitigate Under-Over Thinking via Adaptive,  Attentive Compression
Authors: ['Joykirat Singh', 'Justin Chih-Yao Chen', 'Archiki Prasad', 'Elias Stengel-Eskin', 'Akshay Nambi', 'Mohit Bansal']
Summary: Recent thinking models solve complex reasoning tasks by scaling test-timecompute, but this scaling must be allocated in line with task difficulty. Onone hand, short reasoning (underthinking) leads to errors on harder problemsthat require extended reasoning steps; but, excessively long reasoning(overthinking) can be token-inefficient, generating unnecessary steps evenafter reaching a correct intermediate solution. We refer to this asunder-adaptivity, where the model fails to modulate its response lengthappropriately given problems of varying difficulty. To address under-adaptivityand strike a balance between under- and overthinking, we propose TRAAC (ThinkRight with Adaptive, Attentive Compression), an online post-training RL methodthat leverages the model's self-attention over a long reasoning trajectory toidentify important steps and prune redundant ones. TRAAC also estimatesdifficulty and incorporates it into training rewards, thereby learning toallocate reasoning budget commensurate with example difficulty. Our approachimproves accuracy, reduces reasoning steps, and enables adaptive thinkingcompared to base models and other RL baselines. Across a variety of tasks(AIME, AMC, GPQA-D, BBEH), TRAAC (Qwen3-4B) achieves an average absoluteaccuracy gain of 8.4% with a relative reduction in reasoning length of 36.8%compared to the base model, and a 7.9% accuracy gain paired with a 29.4% lengthdrop compared to the best RL baseline. TRAAC also shows strong generalization:although our models are trained on math datasets, they show accuracy andefficiency gains on out-of-distribution non-math datasets like GPQA-D, BBEH,and OptimalThinkingBench. Our analysis further verifies that TRAAC providesfine-grained adjustments to thinking budget based on difficulty and that acombination of task-difficulty calibration and attention-based compressionyields gains across diverse tasks.
Link: http://arxiv.org/abs/2510.01581v1
Updated: 2025-10-02T02:00:20Z

13: AdvEvo-MARL: Shaping Internalized Safety through Adversarial  Co-Evolution in Multi-Agent Reinforcement Learning
Authors: ['Zhenyu Pan', 'Yiting Zhang', 'Zhuo Liu', 'Yolo Yunlong Tang', 'Zeliang Zhang', 'Haozheng Luo', 'Yuwei Han', 'Jianshu Zhang', 'Dennis Wu', 'Hong-Yu Chen', 'Haoran Lu', 'Haoyang Fang', 'Manling Li', 'Chenliang Xu', 'Philip S. Yu', 'Han Liu']
Summary: LLM-based multi-agent systems excel at planning, tool use, and rolecoordination, but their openness and interaction complexity also expose them tojailbreak, prompt-injection, and adversarial collaboration. Existing defensesfall into two lines: (i) self-verification that asks each agent to pre-filterunsafe instructions before execution, and (ii) external guard modules thatpolice behaviors. The former often underperforms because a standalone agentlacks sufficient capacity to detect cross-agent unsafe chains anddelegation-induced risks; the latter increases system overhead and creates asingle-point-of-failure-once compromised, system-wide safety collapses, andadding more guards worsens cost and complexity. To solve these challenges, wepropose AdvEvo-MARL, a co-evolutionary multi-agent reinforcement learningframework that internalizes safety into task agents. Rather than relying onexternal guards, AdvEvo-MARL jointly optimizes attackers (which synthesizeevolving jailbreak prompts) and defenders (task agents trained to bothaccomplish their duties and resist attacks) in adversarial learningenvironments. To stabilize learning and foster cooperation, we introduce apublic baseline for advantage estimation: agents within the same functionalgroup share a group-level mean-return baseline, enabling lower-variance updatesand stronger intra-group coordination. Across representative attack scenarios,AdvEvo-MARL consistently keeps attack-success rate (ASR) below 20%, whereasbaselines reach up to 38.33%, while preserving-and sometimes improving-taskaccuracy (up to +3.67% on reasoning tasks). These results show that safety andutility can be jointly improved without relying on extra guard agents or addedsystem overhead.
Link: http://arxiv.org/abs/2510.01586v1
Updated: 2025-10-02T02:06:30Z

14: Enhancing Noise Robustness of Parkinson's Disease Telemonitoring via  Contrastive Feature Augmentation
Authors: ['Ziming Tang', 'Chengbin Hou', 'Tianyu Zhang', 'Bangxu Tian', 'Jinbao Wang', 'Hairong Lv']
Summary: Parkinson's disease (PD) is one of the most common neurodegenerativedisorder. PD telemonitoring emerges as a novel assessment modality enablingself-administered at-home tests of Unified Parkinson's Disease Rating Scale(UPDRS) scores, enhancing accessibility for PD patients. However, three typesof noise would occur during measurements: (1) patient-induced measurementinaccuracies, (2) environmental noise, and (3) data packet loss duringtransmission, resulting in higher prediction errors. To address thesechallenges, NoRo, a noise-robust UPDRS prediction framework is proposed. First,the original speech features are grouped into ordered bins, based on thecontinuous values of a selected feature, to construct contrastive pairs.Second, the contrastive pairs are employed to train a multilayer perceptronencoder for generating noise-robust features. Finally, these features areconcatenated with the original features as the augmented features, which arethen fed into the UPDRS prediction models. Notably, we further introduces anovel evaluation approach with customizable noise injection module, andextensive experiments show that NoRo can successfully enhance the noiserobustness of UPDRS prediction across various downstream prediction modelsunder different noisy environments.
Link: http://arxiv.org/abs/2510.01588v1
Updated: 2025-10-02T02:07:41Z

15: A Comparison of Independent and Joint Fine-tuning Strategies for  Retrieval-Augmented Generation
Authors: ['Neal Gregory Lawton', 'Alfy Samuel', 'Anoop Kumar', 'Daben Liu']
Summary: A Comparison of Independent and Joint Fine-tuning Strategies forRetrieval-Augmented Generation Download PDF Neal Gregory Lawton, Alfy Samuel,Anoop Kumar, Daben Liu Published: 20 Aug 2025, Last Modified: 17 Sept 2025EMNLP2025 FindingsConference, Publication Chairs, AuthorsRevisionsBibTeXCC BY 4.0Keywords: Retrieval-Augmented Generation (RAG), Large Language Models (LLMs),Fine-tuning, Question Answering, Joint fine-tuning TL;DR: We evaluate andcompare strategies for fine-tuning Retrieval Augmented Generation (RAG)pipelines, including independent fine-tuning, joint fine-tuning, and two-phasefine-tuning. Abstract: Retrieval augmented generation (RAG) is a popularframework for question answering that is powered by two large language models(LLMs): an embedding model that retrieves context documents from a databasethat are relevant to a given question, and a generator model that uses theretrieved context to generate an answer to the question. Both the embedding andgenerator models can be fine-tuned to increase performance of a RAG pipeline ona new task, but multiple fine-tuning strategies exist with different costs andbenefits. In this paper, we evaluate and compare several RAG fine-tuningstrategies, including independent, joint, and two-phase fine-tuning. In ourexperiments, we observe that all of these strategies achieve about equalimprovement in EM and F1 generation quality metrics, although they havesignificantly different computational costs. We conclude the optimalfine-tuning strategy to use depends on whether the training dataset includescontext labels and whether a grid search over the learning rates for theembedding and generator models is required.
Link: http://arxiv.org/abs/2510.01600v1
Updated: 2025-10-02T02:30:28Z

16: Bridging Collaborative Filtering and Large Language Models with Dynamic  Alignment, Multimodal Fusion and Evidence-grounded Explanations
Authors: ['Bo Ma', 'LuYao Liu', 'Simon Lau', 'Chandler Yuan', 'and XueY Cui', 'Rosie Zhang']
Summary: Recent research has explored using Large Language Models for recommendationtasks by transforming user interaction histories and item metadata into textprompts, then having the LLM produce rankings or recommendations. A promisingapproach involves connecting collaborative filtering knowledge to LLMrepresentations through compact adapter networks, which avoids expensivefine-tuning while preserving the strengths of both components. Yet severalchallenges persist in practice: collaborative filtering models often use staticsnapshots that miss rapidly changing user preferences; many real-world itemscontain rich visual and audio content beyond textual descriptions; and currentsystems struggle to provide trustworthy explanations backed by concreteevidence. Our work introduces \model{}, a framework that tackles theselimitations through three key innovations. We develop an online adaptationmechanism that continuously incorporates new user interactions throughlightweight modules, avoiding the need to retrain large models. We create aunified representation that seamlessly combines collaborative signals withvisual and audio features, handling cases where some modalities may beunavailable. Finally, we design an explanation system that groundsrecommendations in specific collaborative patterns and item attributes,producing natural language rationales users can verify. Our approach maintainsthe efficiency of frozen base models while adding minimal computationaloverhead, making it practical for real-world deployment.
Link: http://arxiv.org/abs/2510.01606v1
Updated: 2025-10-02T02:43:24Z

17: AgentRec: Next-Generation LLM-Powered Multi-Agent Collaborative  Recommendation with Adaptive Intelligence
Authors: ['Bo Ma', 'Hang Li', 'ZeHua Hu', 'XiaoFan Gui', 'LuYao Liu', 'Simon Lau']
Summary: Interactive conversational recommender systems have gained significantattention for their ability to capture user preferences through naturallanguage interactions. However, existing approaches face substantial challengesin handling dynamic user preferences, maintaining conversation coherence, andbalancing multiple ranking objectives simultaneously. This paper introducesAgentRec, a next-generation LLM-powered multi-agent collaborativerecommendation framework that addresses these limitations through hierarchicalagent networks with adaptive intelligence. Our approach employs specializedLLM-powered agents for conversation understanding, preference modeling, contextawareness, and dynamic ranking, coordinated through an adaptive weightingmechanism that learns from interaction patterns. We propose a three-tierlearning strategy combining rapid response for simple queries, intelligentreasoning for complex preferences, and deep collaboration for challengingscenarios. Extensive experiments on three real-world datasets demonstrate thatAgentRec achieves consistent improvements over state-of-the-art baselines, with2.8\% enhancement in conversation success rate, 1.9\% improvement inrecommendation accuracy (NDCG@10), and 3.2\% better conversation efficiencywhile maintaining comparable computational costs through intelligent agentcoordination.
Link: http://arxiv.org/abs/2510.01609v1
Updated: 2025-10-02T02:47:11Z

18: PychoBench: Evaluating the Psychology Intelligence of Large Language  Models
Authors: ['Min Zeng']
Summary: Large Language Models (LLMs) have demonstrated remarkable success across awide range of industries, primarily due to their impressive generativeabilities. Yet, their potential in applications requiring cognitive abilities,such as psychological counseling, remains largely untapped. This paperinvestigates the key question: Can LLMs be effectively applied to psychologicalcounseling? To determine whether an LLM can effectively take on the role of apsychological counselor, the first step is to assess whether it meets thequalifications required for such a role, namely the ability to pass the U.S.National Counselor Certification Exam (NCE). This is because, just as a humancounselor must pass a certification exam to practice, an LLM must demonstratesufficient psychological knowledge to meet the standards required for such arole. To address this, we introduce PsychoBench, a benchmark grounded inU.S.national counselor examinations, a licensure test for professionalcounselors that requires about 70% accuracy to pass. PsychoBench comprisesapproximately 2,252 carefully curated single-choice questions, crafted torequire deep understanding and broad enough to cover various sub-disciplines ofpsychology. This benchmark provides a comprehensive assessment of an LLM'sability to function as a counselor. Our evaluation shows that advanced modelssuch as GPT-4o, Llama3.3-70B, and Gemma3-27B achieve well above the passingthreshold, while smaller open-source models (e.g., Qwen2.5-7B, Mistral-7B)remain far below it. These results suggest that only frontier LLMs arecurrently capable of meeting counseling exam standards, highlighting both thepromise and the challenges of developing psychology-oriented LLMs.
Link: http://arxiv.org/abs/2510.01611v1
Updated: 2025-10-02T02:49:06Z

19: RAG-BioQA Retrieval-Augmented Generation for Long-Form Biomedical  Question Answering
Authors: ['Lovely Yeswanth Panchumarthi', 'Sai Prasad Gudari', 'Atharva Negi', 'Praveen Raj Budime', 'Harsit Upadhya']
Summary: The exponential growth of biomedical literature creates significantchallenges for accessing precise medical information. Current biomedicalquestion-answering systems primarily focus on short-form answers, failing toprovide the comprehensive explanations necessary for clinical decision-making.We present RAG-BioQA, a novel framework combining retrieval-augmentedgeneration with domain-specific fine-tuning to produce evidence-based,long-form biomedical answers. Our approach integrates BioBERT embeddings withFAISS indexing and compares various re-ranking strategies (BM25, ColBERT,MonoT5) to optimize context selection before synthesizing evidence through afine-tuned T5 model. Experimental results on the PubMedQA dataset showsignificant improvements over baselines, with our best model achievingsubstantial gains across BLEU, ROUGE, and METEOR metrics, advancing the stateof accessible, evidence-based biomedical knowledge retrieval.
Link: http://arxiv.org/abs/2510.01612v1
Updated: 2025-10-02T02:49:09Z

20: Learning to Decide with Just Enough: Information-Theoretic Context  Summarization for CDMPs
Authors: ['Peidong Liu', 'Junjiang Lin', 'Shaowen Wang', 'Yao Xu', 'Haiqing Li', 'Xuhao Xie', 'Siyi Wu', 'Hao Li']
Summary: Contextual Markov Decision Processes (CMDPs) offer a framework for sequentialdecision-making under external signals, but existing methods often fail togeneralize in high-dimensional or unstructured contexts, resulting in excessivecomputation and unstable performance. We propose an information-theoreticsummarization approach that uses large language models (LLMs) to compresscontextual inputs into low-dimensional, semantically rich summaries. Thesesummaries augment states by preserving decision-critical cues while reducingredundancy. Building on the notion of approximate context sufficiency, weprovide, to our knowledge, the first regret bounds and a latency-entropytrade-off characterization for CMDPs. Our analysis clarifies howinformativeness impacts computational cost. Experiments across discrete,continuous, visual, and recommendation benchmarks show that our methodoutperforms raw-context and non-context baselines, improving reward, successrate, and sample efficiency, while reducing latency and memory usage. Thesefindings demonstrate that LLM-based summarization offers a scalable andinterpretable solution for efficient decision-making in context-rich,resource-constrained environments.
Link: http://arxiv.org/abs/2510.01620v1
Updated: 2025-10-02T02:52:24Z

21: LLM4Rec: Large Language Models for Multimodal Generative Recommendation  with Causal Debiasing
Authors: ['Bo Ma', 'Hang Li', 'ZeHua Hu', 'XiaoFan Gui', 'LuYao Liu', 'Simon Lau']
Summary: Contemporary generative recommendation systems face significant challenges inhandling multimodal data, eliminating algorithmic biases, and providingtransparent decision-making processes. This paper introduces an enhancedgenerative recommendation framework that addresses these limitations throughfive key innovations: multimodal fusion architecture, retrieval-augmentedgeneration mechanisms, causal inference-based debiasing, explainablerecommendation generation, and real-time adaptive learning capabilities. Ourframework leverages advanced large language models as the backbone whileincorporating specialized modules for cross-modal understanding, contextualknowledge integration, bias mitigation, explanation synthesis, and continuousmodel adaptation. Extensive experiments on three benchmark datasets(MovieLens-25M, Amazon-Electronics, Yelp-2023) demonstrate consistentimprovements in recommendation accuracy, fairness, and diversity compared toexisting approaches. The proposed framework achieves up to 2.3% improvement inNDCG@10 and 1.4% enhancement in diversity metrics while maintainingcomputational efficiency through optimized inference strategies.
Link: http://arxiv.org/abs/2510.01622v1
Updated: 2025-10-02T02:53:05Z

22: Quagmires in SFT-RL Post-Training: When High SFT Scores Mislead and What  to Use Instead
Authors: ['Feiyang Kang', 'Michael Kuchnik', 'Karthik Padthe', 'Marin Vlastelica', 'Ruoxi Jia', 'Carole-Jean Wu', 'Newsha Ardalani']
Summary: In post-training for reasoning Large Language Models (LLMs), the currentstate of practice trains LLMs in two independent stages: Supervised Fine-Tuning(SFT) and Reinforcement Learning with Verifiable Rewards (RLVR, shortened as``RL'' below). In this work, we challenge whether high SFT scores translate toimproved performance after RL. We provide extensive counter-examples where thisis not true. We find high SFT scores can be biased toward simpler or morehomogeneous data and are not reliably predictive of subsequent RL gains orscaled-up post-training effectiveness. In some cases, RL training on modelswith improved SFT performance could lead to substantially worse outcomecompared to RL on the base model without SFT. We study alternative metrics andidentify generalization loss on held-out reasoning examples and Pass@large kperformance to provide strong proxies for the RL outcome. We trained hundredsof models up to 12B-parameter with SFT and RLVR via GRPO and ran extensiveevaluations on 7 math benchmarks with up to 256 repetitions, spending $>$1M GPUhours. Experiments include models from Llama3, Mistral-Nemo, Qwen3 and multiplestate-of-the-art SFT/RL datasets. Compared to directly predicting from pre-RLperformance, prediction based on generalization loss and Pass@large k achievessubstantial higher precision, improving $R^2$ coefficient and Spearman's rankcorrelation coefficient by up to 0.5 (2x). This provides strong utility forbroad use cases. For example, in most experiments, we find SFT training onunique examples for a one epoch underperforms training on half examples for twoepochs, either after SFT or SFT-then-RL; With the same SFT budget, trainingonly on short examples may lead to better SFT performance, though, it oftenleads to worse outcome after RL compared to training on examples with varyinglengths. Evaluation tool will be open-sourced.
Link: http://arxiv.org/abs/2510.01624v1
Updated: 2025-10-02T02:57:00Z

23: Demystifying Synthetic Data in LLM Pre-training: A Systematic Study of  Scaling Laws, Benefits, and Pitfalls
Authors: ['Feiyang Kang', 'Newsha Ardalani', 'Michael Kuchnik', 'Youssef Emad', 'Mostafa Elhoushi', 'Shubhabrata Sengupta', 'Shang-Wen Li', 'Ramya Raghavendra', 'Ruoxi Jia', 'Carole-Jean Wu']
Summary: Training data plays a crucial role in Large Language Models (LLM) scaling,yet high quality data is of limited supply. Synthetic data techniques offer apotential path toward sidestepping these limitations. We conduct a large-scaleempirical investigation (>1000 LLMs with >100k GPU hours) using a unifiedprotocol and scaling laws, comparing natural web data, diverse synthetic types(rephrased text, generated textbooks), and mixtures of natural and syntheticdata. Specifically, we found pre-training on rephrased synthetic data\textit{alone} is not faster than pre-training on natural web texts; whilepre-training on 1/3 rephrased synthetic data mixed with 2/3 natural web textscan speed up 5-10x (to reach the same validation loss) at larger data budgets.Pre-training on textbook-style synthetic data \textit{alone} results in notablyhigher loss on many downstream domains especially at small data budgets. "Good"ratios of synthetic data in training data mixtures depend on the model size anddata budget, empirically converging to ~30% for rephrased synthetic data.Larger generator models do not necessarily yield better pre-training data than~8B-param models. These results contribute mixed evidence on "model collapse"during large-scale single-round (n=1) model training on syntheticdata--training on rephrased synthetic data shows no degradation in performancein foreseeable scales whereas training on mixtures of textbook-stylepure-generated synthetic data shows patterns predicted by "model collapse". Ourwork demystifies synthetic data in pre-training, validates its conditionalbenefits, and offers practical guidance.
Link: http://arxiv.org/abs/2510.01631v1
Updated: 2025-10-02T03:24:42Z

24: BioBlobs: Differentiable Graph Partitioning for Protein Representation  Learning
Authors: ['Xin Wang', 'Carlos Oliver']
Summary: Protein function is driven by coherent substructures which vary in size andtopology, yet current protein representation learning models (PRL) distortthese signals by relying on rigid substructures such as k-hop and fixed radiusneighbourhoods. We introduce BioBlobs, a plug-and-play, fully differentiablemodule that represents proteins by dynamically partitioning structures intoflexibly-sized, non-overlapping substructures ("blobs"). The resulting blobsare quantized into a shared and interpretable codebook, yielding a discretevocabulary of function-relevant protein substructures used to compute proteinembeddings. We show that BioBlobs representations improve the performance ofwidely used protein encoders such as GVP-GNN across various PRL tasks. Ourapproach highlights the value of architectures that directly capturefunction-relevant protein substructures, enabling both improved predictiveperformance and mechanistic insight into protein function.
Link: http://arxiv.org/abs/2510.01632v1
Updated: 2025-10-02T03:25:02Z

25: Towards Human-Centered RegTech: Unpacking Professionals' Strategies and  Needs for Using LLMs Safely
Authors: ['Siying Hu', 'Yaxing Yao', 'Zhicong Lu']
Summary: Large Language Models are profoundly changing work patterns in high-riskprofessional domains, yet their application also introduces severe andunderexplored compliance risks. To investigate this issue, we conductedsemi-structured interviews with 24 highly-skilled knowledge workers fromindustries such as law, healthcare, and finance. The study found that theseexperts are commonly concerned about sensitive information leakage,intellectual property infringement, and uncertainty regarding the quality ofmodel outputs. In response, they spontaneously adopt various mitigationstrategies, such as actively distorting input data and limiting the details intheir prompts. However, the effectiveness of these spontaneous efforts islimited due to a lack of specific compliance guidance and training for LargeLanguage Models. Our research reveals a significant gap between current NLPtools and the actual compliance needs of experts. This paper positions thesevaluable empirical findings as foundational work for building the nextgeneration of Human-Centered, Compliance-Driven Natural Language Processing forRegulatory Technology (RegTech), providing a critical human-centeredperspective and design requirements for engineering NLP systems that canproactively support expert compliance workflows.
Link: http://arxiv.org/abs/2510.01638v1
Updated: 2025-10-02T03:35:46Z

26: Understanding the Geospatial Reasoning Capabilities of LLMs: A  Trajectory Recovery Perspective
Authors: ['Thinh Hung Truong', 'Jey Han Lau', 'Jianzhong Qi']
Summary: We explore the geospatial reasoning capabilities of Large Language Models(LLMs), specifically, whether LLMs can read road network maps and performnavigation. We frame trajectory recovery as a proxy task, which requires modelsto reconstruct masked GPS traces, and introduce GLOBALTRACE, a dataset withover 4,000 real-world trajectories across diverse regions and transportationmodes. Using road network as context, our prompting framework enables LLMs togenerate valid paths without accessing any external navigation tools.Experiments show that LLMs outperform off-the-shelf baselines and specializedtrajectory recovery models, with strong zero-shot generalization. Fine-grainedanalysis shows that LLMs have strong comprehension of the road network andcoordinate systems, but also pose systematic biases with respect to regions andtransportation modes. Finally, we demonstrate how LLMs can enhance navigationexperiences by reasoning over maps in flexible ways to incorporate userpreferences.
Link: http://arxiv.org/abs/2510.01639v1
Updated: 2025-10-02T03:37:41Z

27: NLP Methods for Detecting Novel LLM Jailbreaks and Keyword Analysis with  BERT
Authors: ['John Hawkins', 'Aditya Pramar', 'Rodney Beard', 'Rohitash Chandra']
Summary: Large Language Models (LLMs) suffer from a range of vulnerabilities thatallow malicious users to solicit undesirable responses through manipulation ofthe input text. These so-called jailbreak prompts are designed to trick the LLMinto circumventing the safety guardrails put in place to keep responsesacceptable to the developer's policies. In this study, we analyse the abilityof different machine learning models to distinguish jailbreak prompts fromgenuine uses, including looking at our ability to identify jailbreaks that usepreviously unseen strategies. Our results indicate that using current datasetsthe best performance is achieved by fine tuning a Bidirectional EncoderRepresentations from Transformers (BERT) model end-to-end for identifyingjailbreaks. We visualise the keywords that distinguish jailbreak from genuineprompts and conclude that explicit reflexivity in prompt structure could be asignal of jailbreak intention.
Link: http://arxiv.org/abs/2510.01644v1
Updated: 2025-10-02T03:55:29Z

28: Position: Privacy Is Not Just Memorization!
Authors: ['Niloofar Mireshghallah', 'Tianshi Li']
Summary: The discourse on privacy risks in Large Language Models (LLMs) hasdisproportionately focused on verbatim memorization of training data, while aconstellation of more immediate and scalable privacy threats remainunderexplored. This position paper argues that the privacy landscape of LLMsystems extends far beyond training data extraction, encompassing risks fromdata collection practices, inference-time context leakage, autonomous agentcapabilities, and the democratization of surveillance through deep inferenceattacks. We present a comprehensive taxonomy of privacy risks across the LLMlifecycle -- from data collection through deployment -- and demonstrate throughcase studies how current privacy frameworks fail to address these multifacetedthreats. Through a longitudinal analysis of 1,322 AI/ML privacy paperspublished at leading conferences over the past decade (2016--2025), we revealthat while memorization receives outsized attention in technical research, themost pressing privacy harms lie elsewhere, where current technical approachesoffer little traction and viable paths forward remain unclear. We call for afundamental shift in how the research community approaches LLM privacy, movingbeyond the narrow focus of current technical solutions and embracinginterdisciplinary approaches that address the sociotechnical nature of theseemerging threats.
Link: http://arxiv.org/abs/2510.01645v1
Updated: 2025-10-02T04:02:06Z

29: Source-Free Cross-Domain Continual Learning
Authors: ['Muhammad Tanzil Furqon', 'Mahardhika Pratama', 'Igor Škrjanc', 'Lin Liu', 'Habibullah Habibullah', 'Kutluyil Dogancay']
Summary: Although existing cross-domain continual learning approaches successfullyaddress many streaming tasks having domain shifts, they call for a fullylabeled source domain hindering their feasibility in the privacy constrainedenvironments. This paper goes one step ahead with the problem of source-freecross-domain continual learning where the use of source-domain samples arecompletely prohibited. We propose the idea of rehearsal-free frequency-awaredynamic prompt collaborations (REFEREE) to cope with the absence of labeledsource-domain samples in realm of cross-domain continual learning. REFEREE isbuilt upon a synergy between a source-pre-trained model and a large-scalevision-language model, thus overcoming the problem of sub-optimalgeneralizations when relying only on a source pre-trained model. The domainshift problem between the source domain and the target domain is handled by afrequency-aware prompting technique encouraging low-frequency components whilesuppressing high-frequency components. This strategy generates frequency-awareaugmented samples, robust against noisy pseudo labels. The noisy pseudo-labelproblem is further addressed with the uncertainty-aware weighting strategywhere the mean and covariance matrix are weighted by prediction uncertainties,thus mitigating the adverse effects of the noisy pseudo label. Besides, theissue of catastrophic forgetting (CF) is overcome by kernel linear discriminantanalysis (KLDA) where the backbone network is frozen while the classificationis performed using the linear discriminant analysis approach guided by therandom kernel method. Our rigorous numerical studies confirm the advantage ofour approach where it beats prior arts having access to source domain sampleswith significant margins.
Link: http://arxiv.org/abs/2510.01649v1
Updated: 2025-10-02T04:09:25Z

30: The Unseen Frontier: Pushing the Limits of LLM Sparsity with  Surrogate-Free ADMM
Authors: ['Kwanhee Lee', 'Hyeondo Jang', 'Dongyeop Lee', 'Dan Alistarh', 'Namhoon Lee']
Summary: Neural network pruning is a promising technique to mitigate the excessivecomputational and memory requirements of large language models (LLMs). Despiteits promise, however, progress in this area has diminished, as conventionalmethods are seemingly unable to surpass moderate sparsity levels (50-60%)without severely degrading model accuracy. This work breaks through the currentimpasse, presenting a principled and effective method called $\texttt{Elsa}$,which achieves extreme sparsity levels of up to 90% while retaining high modelfidelity. This is done by identifying several limitations in current practice,all of which can be traced back to their reliance on a surrogate objectiveformulation. $\texttt{Elsa}$ tackles this issue directly and effectively viastandard and well-established constrained optimization techniques based onADMM. Our extensive experiments across a wide range of models and scales showthat $\texttt{Elsa}$ achieves substantial improvements over existing methods;e.g., it achieves 7.8$\times$ less perplexity than the best existing method onLLaMA-2-7B at 90% sparsity. Furthermore, we present$\texttt{Elsa}_{\text{-L}}$, a quantized variant that scales to extremely largemodels (27B), and establish its theoretical convergence guarantees. Theseresults highlight meaningful progress in advancing the frontier of LLMsparsity, while promising that significant opportunities for furtheradvancement may remain in directions that have so far attracted limitedexploration.
Link: http://arxiv.org/abs/2510.01650v1
Updated: 2025-10-02T04:10:17Z

31: SoK: Measuring What Matters for Closed-Loop Security Agents
Authors: ['Mudita Khurana', 'Raunak Jain']
Summary: Cybersecurity is a relentless arms race, with AI driven offensive systemsevolving faster than traditional defenses can adapt. Research and toolingremain fragmented across isolated defensive functions, creating blind spotsthat adversaries exploit. Autonomous agents capable of integrating, exploitconfirmation, remediation, and validation into a single closed loop offerpromise, but the field lacks three essentials: a framework defining the agenticcapabilities of security systems across security life cycle, a principledmethod for evaluating closed loop agents, and a benchmark for measuring theirperformance in practice. We introduce CLASP: the Closed-Loop AutonomousSecurity Performance framework which aligns the security lifecycle(reconnaissance, exploitation, root cause analysis, patch synthesis,validation) with core agentic capabilities (planning, tool use, memory,reasoning, reflection & perception) providing a common vocabulary and rubricfor assessing agentic capabilities in security tasks. By applying CLASP to 21representative works, we map where systems demonstrate strengths, and wherecapability gaps persist. We then define the Closed-Loop Capability (CLC) Score,a composite metric quantifying both degree of loop closure and operationaleffectiveness, and outline the requirements for a closed loop benchmark.Together, CLASP and the CLC Score, provide the vocabulary, diagnostics, andmeasurements needed to advance both function level performance and measureclosed loop security agents.
Link: http://arxiv.org/abs/2510.01654v1
Updated: 2025-10-02T04:20:35Z

32: Asymmetric Proximal Policy Optimization: mini-critics boost LLM  reasoning
Authors: ['Jiashun Liu', 'Johan Obando-Ceron', 'Han Lu', 'Yancheng He', 'Weixun Wang', 'Wenbo Su', 'Bo Zheng', 'Pablo Samuel Castro', 'Aaron Courville', 'Ling Pan']
Summary: Most recent RL for LLMs (RL4LLM) methods avoid explicit critics, replacingthem with average advantage baselines. This shift is largely pragmatic:conventional value functions are computationally expensive to train at LLMscale and often fail under sparse rewards and long reasoning horizons. Werevisit this bottleneck from an architectural perspective and introduceAsymmetric Proximal Policy Optimization (AsyPPO), a simple and scalableframework that restores the critics role while remaining efficient inlarge-model settings. AsyPPO employs a set of lightweight mini-critics, eachtrained on disjoint prompt shards. This design encourages diversity whilepreserving calibration, reducing value-estimation bias. Beyond robustestimation, AsyPPO leverages inter-critic uncertainty to refine the policyupdate: (i) masking advantages in states where critics agree and gradients addlittle learning signal, and (ii) filtering high-divergence states from entropyregularization, suppressing spurious exploration. After training on open-sourcedata with only 5,000 samples, AsyPPO consistently improves learning stabilityand performance across multiple benchmarks over strong baselines, such as GRPO,achieving performance gains of more than six percent on Qwen3-4b-Base and aboutthree percent on Qwen3-8b-Base and Qwen3-14b-Base over classic PPO, withoutadditional tricks. These results highlight the importance of architecturalinnovations for scalable, efficient algorithms.
Link: http://arxiv.org/abs/2510.01656v1
Updated: 2025-10-02T04:24:27Z

33: Learning Time-Series Representations by Hierarchical  Uniformity-Tolerance Latent Balancing
Authors: ['Amin Jalali', 'Milad Soltany', 'Michael Greenspan', 'Ali Etemad']
Summary: We propose TimeHUT, a novel method for learning time-series representationsby hierarchical uniformity-tolerance balancing of contrastive representations.Our method uses two distinct losses to learn strong representations with theaim of striking an effective balance between uniformity and tolerance in theembedding space. First, TimeHUT uses a hierarchical setup to learn bothinstance-wise and temporal information from input time-series. Next, weintegrate a temperature scheduler within the vanilla contrastive loss tobalance the uniformity and tolerance characteristics of the embeddings.Additionally, a hierarchical angular margin loss enforces instance-wise andtemporal contrast losses, creating geometric margins between positive andnegative pairs of temporal sequences. This approach improves the coherence ofpositive pairs and their separation from the negatives, enhancing the captureof temporal dependencies within a time-series sample. We evaluate our approachon a wide range of tasks, namely 128 UCR and 30 UAE datasets for univariate andmultivariate classification, as well as Yahoo and KPI datasets for anomalydetection. The results demonstrate that TimeHUT outperforms prior methods byconsiderable margins on classification, while obtaining competitive results foranomaly detection. Finally, detailed sensitivity and ablation studies areperformed to evaluate different components and hyperparameters of our method.
Link: http://arxiv.org/abs/2510.01658v1
Updated: 2025-10-02T04:30:13Z

34: MDSEval: A Meta-Evaluation Benchmark for Multimodal Dialogue  Summarization
Authors: ['Yinhong Liu', 'Jianfeng He', 'Hang Su', 'Ruixue Lian', 'Yi Nian', 'Jake Vincent', 'Srikanth Vishnubhotla', 'Robinson Piramuthu', 'Saab Mansour']
Summary: Multimodal Dialogue Summarization (MDS) is a critical task with wide-rangingapplications. To support the development of effective MDS models, robustautomatic evaluation methods are essential for reducing both cost and humaneffort. However, such methods require a strong meta-evaluation benchmarkgrounded in human annotations. In this work, we introduce MDSEval, the firstmeta-evaluation benchmark for MDS, consisting image-sharing dialogues,corresponding summaries, and human judgments across eight well-defined qualityaspects. To ensure data quality and richfulness, we propose a novel filteringframework leveraging Mutually Exclusive Key Information (MEKI) acrossmodalities. Our work is the first to identify and formalize key evaluationdimensions specific to MDS. We benchmark state-of-the-art modal evaluationmethods, revealing their limitations in distinguishing summaries from advancedMLLMs and their susceptibility to various bias.
Link: http://arxiv.org/abs/2510.01659v1
Updated: 2025-10-02T04:38:27Z

35: Shift-Invariant Attribute Scoring for Kolmogorov-Arnold Networks via  Shapley Value
Authors: ['Wangxuan Fan', 'Ching Wang', 'Siqi Li', 'Nan Liu']
Summary: For many real-world applications, understanding feature-outcome relationshipsis as crucial as achieving high predictive accuracy. While traditional neuralnetworks excel at prediction, their black-box nature obscures underlyingfunctional relationships. Kolmogorov--Arnold Networks (KANs) address this byemploying learnable spline-based activation functions on edges, enablingrecovery of symbolic representations while maintaining competitive performance.However, KAN's architecture presents unique challenges for network pruning.Conventional magnitude-based methods become unreliable due to sensitivity toinput coordinate shifts. We propose \textbf{ShapKAN}, a pruning framework usingShapley value attribution to assess node importance in a shift-invariantmanner. Unlike magnitude-based approaches, ShapKAN quantifies each node'sactual contribution, ensuring consistent importance rankings regardless ofinput parameterization. Extensive experiments on synthetic and real-worlddatasets demonstrate that ShapKAN preserves true node importance while enablingeffective network compression. Our approach improves KAN's interpretabilityadvantages, facilitating deployment in resource-constrained environments.
Link: http://arxiv.org/abs/2510.01663v1
Updated: 2025-10-02T04:45:02Z

36: GuruAgents: Emulating Wise Investors with Prompt-Guided LLM Agents
Authors: ['Yejin Kim', 'Youngbin Lee', 'Juhyeong Kim', 'Yongjae Lee']
Summary: This study demonstrates that GuruAgents, prompt-guided AI agents, cansystematically operationalize the strategies of legendary investment gurus. Wedevelop five distinct GuruAgents, each designed to emulate an iconic investor,by encoding their distinct philosophies into LLM prompts that integratefinancial tools and a deterministic reasoning pipeline. In a backtest onNASDAQ-100 constituents from Q4 2023 to Q2 2025, the GuruAgents exhibit uniquebehaviors driven by their prompted personas. The Buffett GuruAgent achieves thehighest performance, delivering a 42.2\% CAGR that significantly outperformsbenchmarks, while other agents show varied results. These findings confirm thatprompt engineering can successfully translate the qualitative philosophies ofinvestment gurus into reproducible, quantitative strategies, highlighting anovel direction for automated systematic investing. The source code and dataare available at https://github.com/yejining99/GuruAgents.
Link: http://arxiv.org/abs/2510.01664v1
Updated: 2025-10-02T04:45:27Z

37: Just Do It!? Computer-Use Agents Exhibit Blind Goal-Directedness
Authors: ['Erfan Shayegani', 'Keegan Hines', 'Yue Dong', 'Nael Abu-Ghazaleh', 'Roman Lutz', 'Spencer Whitehead', 'Vidhisha Balachandran', 'Besmira Nushi', 'Vibhav Vineet']
Summary: Computer-Use Agents (CUAs) are an increasingly deployed class of agents thattake actions on GUIs to accomplish user goals. In this paper, we show that CUAsconsistently exhibit Blind Goal-Directedness (BGD): a bias to pursue goalsregardless of feasibility, safety, reliability, or context. We characterizethree prevalent patterns of BGD: (i) lack of contextual reasoning, (ii)assumptions and decisions under ambiguity, and (iii) contradictory orinfeasible goals. We develop BLIND-ACT, a benchmark of 90 tasks capturing thesethree patterns. Built on OSWorld, BLIND-ACT provides realistic environments andemploys LLM-based judges to evaluate agent behavior, achieving 93.75% agreementwith human annotations. We use BLIND-ACT to evaluate nine frontier models,including Claude Sonnet and Opus 4, Computer-Use-Preview, and GPT-5, observinghigh average BGD rates (80.8%) across them. We show that BGD exposes subtlerisks that arise even when inputs are not directly harmful. Whileprompting-based interventions lower BGD levels, substantial risk persists,highlighting the need for stronger training- or inference-time interventions.Qualitative analysis reveals observed failure modes: execution-first bias(focusing on how to act over whether to act), thought-action disconnect(execution diverging from reasoning), and request-primacy (justifying actionsdue to user request). Identifying BGD and introducing BLIND-ACT establishes afoundation for future research on studying and mitigating this fundamental riskand ensuring safe CUA deployment.
Link: http://arxiv.org/abs/2510.01670v1
Updated: 2025-10-02T04:52:15Z

38: A Locally Executable AI System for Improving Preoperative Patient  Communication: A Multi-Domain Clinical Evaluation
Authors: ['Motoki Sato', 'Yuki Matsushita', 'Hidekazu Takahashi', 'Tomoaki Kakazu', 'Sou Nagata', 'Mizuho Ohnuma', 'Atsushi Yoshikawa', 'Masayuki Yamamura']
Summary: Patients awaiting invasive procedures often have unanswered pre-proceduralquestions; however, time-pressured workflows and privacy constraints limitpersonalized counseling. We present LENOHA (Low Energy, No Hallucination, LeaveNo One Behind Architecture), a safety-first, local-first system that routesinputs with a high-precision sentence-transformer classifier and returnsverbatim answers from a clinician-curated FAQ for clinical queries, eliminatingfree-text generation in the clinical path. We evaluated two domains (toothextraction and gastroscopy) using expert-reviewed validation sets(n=400/domain) for thresholding and independent test sets (n=200/domain). Amongthe four encoders, E5-large-instruct (560M) achieved an overall accuracy of0.983 (95% CI 0.964-0.991), AUC 0.996, and seven total errors, which werestatistically indistinguishable from GPT-4o on this task; Gemini made no errorson this test set. Energy logging shows that the non-generative clinical pathconsumes ~1.0 mWh per input versus ~168 mWh per small-talk reply from a local8B SLM, a ~170x difference, while maintaining ~0.10 s latency on a singleon-prem GPU. These results indicate that near-frontier discrimination andgeneration-induced errors are structurally avoided in the clinical path byreturning vetted FAQ answers verbatim, supporting privacy, sustainability, andequitable deployment in bandwidth-limited environments.
Link: http://arxiv.org/abs/2510.01671v1
Updated: 2025-10-02T04:53:11Z

39: FOR-Prompting: From Objection to Revision via an Asymmetric Prompting  Protocol
Authors: ['He Zhang', 'Anzhou Zhang', 'Jian Dai']
Summary: Reasoning protocols such as Chain of Thought (CoT) and Tree of Thought (ToT)organize internal deliberation but lack an explicit mechanism for externalquestioning that elicits self-revision. We present FOR-Prompting (FromObjection to Revision Prompting), an asymmetric protocol where a Defenderproposes an answer, an Objectioner raises question-style objections with nodirect fixes, and a Host enforces consistency and closure. On GSM8K we observeabout a 22% point gain over single-prompt and accuracy on par with CoT, withmore than 10% higher ratings in reasoning and coherence from a uniform GPT 4.1judge. FOR-Prompting also corrects mistakes without tools or human supervisionon tricky queries, and improves performance for small-scale model (approx. 19%accuracy improved on Llama3.2:1b for GSM8K task), highlighting promise forsmall models and on personal device use. Beyond factual QA, qualitativeanalyses on open-ended tasks show enhanced exploration and refinement, withdialogue traces that make assumptions and trade-offs explicit. The protocol ismodel agnostic and operates purely at the prompt level through role-structuredturns, so it works with hosted and local models of different sizes withoutretraining, and it supports large-scale study of objection-guided reasoning.
Link: http://arxiv.org/abs/2510.01674v1
Updated: 2025-10-02T04:57:58Z

40: Look Less, Reason More: Rollout-Guided Adaptive Pixel-Space Reasoning
Authors: ['Xuchen Li', 'Xuzhao Li', 'Jiahui Gao', 'Renjie Pi', 'Shiyu Hu', 'Wentao Zhang']
Summary: Vision-Language Models (VLMs) excel at many multimodal tasks, yet theyfrequently struggle with tasks requiring precise understanding and handling offine-grained visual elements. This is mainly due to information loss duringimage encoding or insufficient attention to critical regions. Recent work hasshown promise by incorporating pixel-level visual information into thereasoning process, enabling VLMs to access high-resolution visual detailsduring their thought process. However, this pixel-level information is oftenoverused, leading to inefficiency and distraction from irrelevant visualdetails. To address these challenges, we propose the first framework foradaptive pixel reasoning that dynamically determines necessary pixel-leveloperations based on the input query. Specifically, we first applyoperation-aware supervised fine-tuning to establish baseline competence intextual reasoning and visual operations, then design a novel rollout-guidedreinforcement learning framework relying on feedback of the model's ownresponses, which enables the VLM to determine when pixel operations should beinvoked based on query difficulty. Experiments on extensive multimodalreasoning benchmarks show that our model achieves superior performance whilesignificantly reducing unnecessary visual operations. Impressively, our modelachieves 73.4\% accuracy on HR-Bench 4K while maintaining a tool usage ratio ofonly 20.1\%, improving accuracy and simultaneously reducing tool usage by66.5\% compared to the previous methods.
Link: http://arxiv.org/abs/2510.01681v1
Updated: 2025-10-02T05:14:52Z

41: How Do Language Models Compose Functions?
Authors: ['Apoorv Khandelwal', 'Ellie Pavlick']
Summary: While large language models (LLMs) appear to be increasingly capable ofsolving compositional tasks, it is an open question whether they do so usingcompositional mechanisms. In this work, we investigate how feedforward LLMssolve two-hop factual recall tasks, which can be expressed compositionally as$g(f(x))$. We first confirm that modern LLMs continue to suffer from the"compositionality gap": i.e. their ability to compute both $z = f(x)$ and $y =g(z)$ does not entail their ability to compute the composition $y = g(f(x))$.Then, using logit lens on their residual stream activations, we identify twoprocessing mechanisms, one which solves tasks $\textit{compositionally}$,computing $f(x)$ along the way to computing $g(f(x))$, and one which solvesthem $\textit{directly}$, without any detectable signature of the intermediatevariable $f(x)$. Finally, we find that which mechanism is employed appears tobe related to the embedding space geometry, with the idiomatic mechanism beingdominant in cases where there exists a linear mapping from $x$ to $g(f(x))$ inthe embedding spaces. We fully release our data and code at:https://github.com/apoorvkh/composing-functions .
Link: http://arxiv.org/abs/2510.01685v1
Updated: 2025-10-02T05:21:34Z

42: Improving AGI Evaluation: A Data Science Perspective
Authors: ['John Hawkins']
Summary: Evaluation of potential AGI systems and methods is difficult due to thebreadth of the engineering goal. We have no methods for perfect evaluation ofthe end state, and instead measure performance on small tests designed toprovide directional indication that we are approaching AGI. In this work weargue that AGI evaluation methods have been dominated by a design philosophythat uses our intuitions of what intelligence is to create synthetic tasks,that have performed poorly in the history of AI. Instead we argue for analternative design philosophy focused on evaluating robust task execution thatseeks to demonstrate AGI through competence. This perspective is developed fromcommon practices in data science that are used to show that a system can bereliably deployed. We provide practical examples of what this would mean forAGI evaluation.
Link: http://arxiv.org/abs/2510.01687v1
Updated: 2025-10-02T05:27:29Z

43: Format Inertia: A Failure Mechanism of LLMs in Medical Pre-Consultation
Authors: ['Seungseop Lim', 'Gibaeg Kim', 'Wooseok Han', 'Jean Seo', 'Hyunkyung Lee', 'Jaehyo Yoo', 'Eunho Yang']
Summary: Recent advances in Large Language Models (LLMs) have brought significantimprovements to various service domains, including chatbots and medicalpre-consultation applications. In the healthcare domain, the most commonapproach for adapting LLMs to multi-turn dialogue generation is SupervisedFine-Tuning (SFT). However, datasets for SFT in tasks like medicalpre-consultation typically exhibit a skewed turn-count distribution. Trainingon such data induces a novel failure mechanism we term **Format Inertia**,where models tend to generate repetitive, format-correct, but diagnosticallyuninformative questions in long medical dialogues. To mitigate this observedfailure mechanism, we adopt a simple, data-centric method that rebalances theturn-count distribution of the training dataset. Experimental results show thatour approach substantially alleviates Format Inertia in medicalpre-consultation.
Link: http://arxiv.org/abs/2510.01688v1
Updated: 2025-10-02T05:29:38Z

44: VaPR -- Vision-language Preference alignment for Reasoning
Authors: ['Rohan Wadhawan', 'Fabrice Y Harel-Canada', 'Zi-Yi Dou', 'Suhaila Shakiah', 'Robinson Piramuthu', 'Nanyun Peng']
Summary: Preference finetuning methods like Direct Preference Optimization (DPO) withAI-generated feedback have shown promise in aligning Large Vision-LanguageModels (LVLMs) with human preferences. However, existing techniques overlookthe prevalence of noise in synthetic preference annotations in the form ofstylistic and length biases. To this end, we introduce a hard-negative responsegeneration framework based on LLM-guided response editing, that producesrejected responses with targeted errors, maintaining stylistic and lengthsimilarity to the accepted ones. Using this framework, we develop the VaPRdataset, comprising 30K high-quality samples, to finetune three LVLM families:LLaVA-V1.5, Qwen2VL & Qwen2.5VL (2B-13B sizes). Our VaPR models deliversignificant performance improvements across ten benchmarks, achieving averagegains of 6.5% (LLaVA), 4.0% (Qwen2VL), and 1.5% (Qwen2.5VL), with notableimprovements on reasoning tasks. A scaling analysis shows that performanceconsistently improves with data size, with LLaVA models benefiting even atsmaller scales. Moreover, VaPR reduces the tendency to answer "Yes" in binaryquestions - addressing a common failure mode in LVLMs like LLaVA. Lastly, weshow that the framework generalizes to open-source LLMs as editors, with modelstrained on VaPR-OS achieving ~99% of the performance of models trained on\name, which is synthesized using GPT-4o. Our data, models, and code can befound on the project page https://vap-r.github.io
Link: http://arxiv.org/abs/2510.01700v1
Updated: 2025-10-02T06:10:43Z

45: Holistic Order Prediction in Natural Scenes
Authors: ['Pierre Musacchio', 'Hyunmin Lee', 'Jaesik Park']
Summary: Even in controlled settings, understanding instance-wise geometries is achallenging task for a wide range of visual models. Although specializedsystems exist, modern arts rely on expensive input formats (category labels,binary segmentation masks) and inference costs (a quadratic amount of forwardpasses). We mitigate these limitations by proposing InstaFormer, a networkcapable of holistic order prediction. That is, solely given an input RGB image,InstaFormer returns the full occlusion and depth orderings for all theinstances in the scene in a single forward pass. At its core, InstaFormerrelies on interactions between object queries and latent mask descriptors thatsemantically represent the same objects while carrying complementaryinformation. We comprehensively benchmark and ablate our approach to highlightits effectiveness. Our code and models are open-source and available at thisURL: https://github.com/SNU-VGILab/InstaOrder.
Link: http://arxiv.org/abs/2510.01704v1
Updated: 2025-10-02T06:24:12Z

46: Representational Alignment Across Model Layers and Brain Regions with  Hierarchical Optimal Transport
Authors: ['Shaan Shah', 'Meenakshi Khosla']
Summary: Standard representational similarity methods align each layer of a network toits best match in another independently, producing asymmetric results, lackinga global alignment score, and struggling with networks of different depths.These limitations arise from ignoring global activation structure andrestricting mappings to rigid one-to-one layer correspondences. We proposeHierarchical Optimal Transport (HOT), a unified framework that jointly inferssoft, globally consistent layer-to-layer couplings and neuron-level transportplans. HOT allows source neurons to distribute mass across multiple targetlayers while minimizing total transport cost under marginal constraints. Thisyields both a single alignment score for the entire network comparison and asoft transport plan that naturally handles depth mismatches through massdistribution. We evaluate HOT on vision models, large language models, andhuman visual cortex recordings. Across all domains, HOT matches or surpassesstandard pairwise matching in alignment quality. Moreover, it reveals smooth,fine-grained hierarchical correspondences: early layers map to early layers,deeper layers maintain relative positions, and depth mismatches are resolved bydistributing representations across multiple layers. These structured patternsemerge naturally from global optimization without being imposed, yet are absentin greedy layer-wise methods. HOT thus enables richer, more interpretablecomparisons between representations, particularly when networks differ inarchitecture or depth.
Link: http://arxiv.org/abs/2510.01706v1
Updated: 2025-10-02T06:25:06Z

47: PolySim: Bridging the Sim-to-Real Gap for Humanoid Control via  Multi-Simulator Dynamics Randomization
Authors: ['Zixing Lei', 'Zibo Zhou', 'Sheng Yin', 'Yueru Chen', 'Qingyao Xu', 'Weixin Li', 'Yunhong Wang', 'Bowei Tang', 'Wei Jing', 'Siheng Chen']
Summary: Humanoid whole-body control (WBC) policies trained in simulation often sufferfrom the sim-to-real gap, which fundamentally arises from simulator inductivebias, the inherent assumptions and limitations of any single simulator. Thesebiases lead to nontrivial discrepancies both across simulators and betweensimulation and the real world. To mitigate the effect of simulator inductivebias, the key idea is to train policies jointly across multiple simulators,encouraging the learned controller to capture dynamics that generalize beyondany single simulator's assumptions. We thus introduce PolySim, a WBC trainingplatform that integrates multiple heterogeneous simulators. PolySim can launchparallel environments from different engines simultaneously within a singletraining run, thereby realizing dynamics-level domain randomization.Theoretically, we show that PolySim yields a tighter upper bound on simulatorinductive bias than single-simulator training. In experiments, PolySimsubstantially reduces motion-tracking error in sim-to-sim evaluations; forexample, on MuJoCo, it improves execution success by 52.8 over an IsaacSimbaseline. PolySim further enables zero-shot deployment on a real Unitree G1without additional fine-tuning, showing effective transfer from simulation tothe real world. We will release the PolySim code upon acceptance of this work.
Link: http://arxiv.org/abs/2510.01708v1
Updated: 2025-10-02T06:31:42Z

48: PyramidStyler: Transformer-Based Neural Style Transfer with Pyramidal  Positional Encoding and Reinforcement Learning
Authors: ['Raahul Krishna Durairaju', 'K. Saruladha']
Summary: Neural Style Transfer (NST) has evolved from Gatys et al.'s (2015) CNN-basedalgorithm, enabling AI-driven artistic image synthesis. However, existing CNNand transformer-based models struggle to scale efficiently to complex stylesand high-resolution inputs. We introduce PyramidStyler, a transformer frameworkwith Pyramidal Positional Encoding (PPE): a hierarchical, multi-scale encodingthat captures both local details and global context while reducingcomputational load. We further incorporate reinforcement learning todynamically optimize stylization, accelerating convergence. Trained onMicrosoft COCO and WikiArt, PyramidStyler reduces content loss by 62.6% (to2.07) and style loss by 57.4% (to 0.86) after 4000 epochs--achieving 1.39 sinference--and yields further improvements (content 2.03; style 0.75) withminimal speed penalty (1.40 s) when using RL. These results demonstratereal-time, high-quality artistic rendering, with broad applications in mediaand design.
Link: http://arxiv.org/abs/2510.01715v1
Updated: 2025-10-02T06:54:52Z

49: Latency-aware Multimodal Federated Learning over UAV Networks
Authors: ['Shaba Shaon', 'Dinh C. Nguyen']
Summary: This paper investigates federated multimodal learning (FML) assisted byunmanned aerial vehicles (UAVs) with a focus on minimizing system latency andproviding convergence analysis. In this framework, UAVs are distributedthroughout the network to collect data, participate in model training, andcollaborate with a base station (BS) to build a global model. By utilizingmultimodal sensing, the UAVs overcome the limitations of unimodal systems,enhancing model accuracy, generalization, and offering a more comprehensiveunderstanding of the environment. The primary objective is to optimize FMLsystem latency in UAV networks by jointly addressing UAV sensing scheduling,power control, trajectory planning, resource allocation, and BS resourcemanagement. To address the computational complexity of our latency minimizationproblem, we propose an efficient iterative optimization algorithm combiningblock coordinate descent and successive convex approximation techniques, whichprovides high-quality approximate solutions. We also present a theoreticalconvergence analysis for the UAV-assisted FML framework under a non-convex lossfunction. Numerical experiments demonstrate that our FML framework outperformsexisting approaches in terms of system latency and model training performanceunder different data settings.
Link: http://arxiv.org/abs/2510.01717v1
Updated: 2025-10-02T06:57:44Z

50: Emotional Text-To-Speech Based on Mutual-Information-Guided  Emotion-Timbre Disentanglement
Authors: ['Jianing Yang', 'Sheng Li', 'Takahiro Shinozaki', 'Yuki Saito', 'Hiroshi Saruwatari']
Summary: Current emotional Text-To-Speech (TTS) and style transfer methods rely onreference encoders to control global style or emotion vectors, but do notcapture nuanced acoustic details of the reference speech. To this end, wepropose a novel emotional TTS method that enables fine-grained phoneme-levelemotion embedding prediction while disentangling intrinsic attributes of thereference speech. The proposed method employs a style disentanglement method toguide two feature extractors, reducing mutual information between timbre andemotion features, and effectively separating distinct style components from thereference speech. Experimental results demonstrate that our method outperformsbaseline TTS systems in generating natural and emotionally rich speech. Thiswork highlights the potential of disentangled and fine-grained representationsin advancing the quality and flexibility of emotional TTS systems.
Link: http://arxiv.org/abs/2510.01722v1
Updated: 2025-10-02T07:03:50Z

51: MetaboT: AI-based agent for natural language-based interaction with  metabolomics knowledge graphs
Authors: ['Madina Bekbergenova', 'Lucas Pradi', 'Benjamin Navet', 'Emma Tysinger', 'Franck Michel', 'Matthieu Feraud', 'Yousouf Taghzouti', 'Yan Zhou Chen', 'Olivier Kirchhoffer', 'Florence Mehl', 'Martin Legrand', 'Tao Jiang', 'Marco Pagni', 'Soha Hassoun', 'Jean-Luc Wolfender', 'Wout Bittremieux', 'Fabien Gandon', 'Louis-Félix Nothias']
Summary: Mass spectrometry metabolomics generates vast amounts of data requiringadvanced methods for interpretation. Knowledge graphs address these challengesby structuring mass spectrometry data, metabolite information, and theirrelationships into a connected network (Gaudry et al. 2024). However, effectiveuse of a knowledge graph demands an in-depth understanding of its ontology andits query language syntax. To overcome this, we designed MetaboT, an AI systemutilizing large language models (LLMs) to translate user questions into SPARQLsemantic query language for operating on knowledge graphs (Steve Harris 2013).We demonstrate its effectiveness using the Experimental Natural ProductsKnowledge Graph (ENPKG), a large-scale public knowledge graph for plant naturalproducts (Gaudry et al. 2024).MetaboT employs specialized AI agents forhandling user queries and interacting with the knowledge graph by breaking downcomplex tasks into discrete components, each managed by a specialised agent(Fig. 1a). The multi-agent system is constructed using the LangChain andLangGraph libraries, which facilitate the integration of LLMs with externaltools and information sources (LangChain, n.d.). The query generation processfollows a structured workflow. First, the Entry Agent determines if thequestion is new or a follow-up to previous interactions. New questions areforwarded to the Validator Agent, which verifies if the question is related tothe knowledge graph. Then, the valid question is sent to the Supervisor Agent,which identifies if the question requires chemical conversions or standardizedidentifiers. In this case it delegates the question to the Knowledge GraphAgent, which can use tools to extract necessary details, such as URIs ortaxonomies of chemical names, from the user query. Finally, an agentresponsible for crafting the SPARQL queries equipped with the ontology of theknowledge graph uses the provided identifiers to generate the query. Then, thesystem executes the generated query against the metabolomics knowledge graphand returns structured results to the user (Fig. 1b). To assess the performanceof MetaboT we have curated 50 metabolomics-related questions and their expectedanswers. In addition to submitting these questions to MetaboT, we evaluated abaseline by submitting them to a standard LLM (GPT-4o) with a prompt thatincorporated the knowledge graph ontology but did not provide specific entityIDs. This baseline achieved only 8.16% accuracy, compared to MetaboT's 83.67%,underscoring the necessity of our multi-agent system for accurately retrievingentities and generating correct SPARQL queries. MetaboT demonstrates promisingperformance as a conversational question-answering assistant, enablingresearchers to retrieve structured metabolomics data through natural languagequeries. By automating the generation and execution of SPARQL queries, itremoves technical barriers that have traditionally hindered access to knowledgegraphs. Importantly, MetaboT leverages the capabilities of LLMs whilemaintaining experimentally grounded query generation, ensuring that outputsremain aligned with domain-specific standards and data structures. Thisapproach facilitates data-driven discoveries by bridging the gap betweencomplex semantic technologies and user-friendly interaction. MetaboT isaccessible at [https://metabot.holobiomicslab.eu/], and its source code isavailable at [https://github.com/HolobiomicsLab/MetaboT].
Link: http://arxiv.org/abs/2510.01724v1
Updated: 2025-10-02T07:05:29Z

52: Machine-interpretable Engineering Design Standards for Valve  Specification
Authors: ['Anders Gjerver', 'Rune Frostad', 'Vedrana Barisic', 'Melinda Hodkiewicz', 'Caitlin Woods', 'Mihaly Fekete', 'Arild Braathen Torjusen', 'Johan Wilhelm Kluwer']
Summary: Engineering design processes use technical specifications and must complywith standards. Product specifications, product type data sheets, and designstandards are still mainly document-centric despite the ambition to digitalizeindustrial work. In this paper, we demonstrate how to transform informationheld in engineering design standards into modular, reusable,machine-interpretable ontologies and use the ontologies in quality assurance ofthe plant design and equipment selection process. We use modelling patterns tocreate modular ontologies for knowledge captured in the text and in frequentlyreferenced tables in International Standards for piping, material and valvedesign. These modules are exchangeable, as stored in a W3C compliant format,and interoperable as they are aligned with the top-level ontology ISO DIS23726-3: Industrial Data Ontology (IDO).  We test these ontologies, created based on international material and pipingstandards and industry norms, on a valve selection process. Valves areinstantiated in semantic asset models as individuals along with a semanticrepresentation of the environmental condition at their location on the asset.We create "functional location tags" as OWL individuals that become instancesof OWL class Valve Data Sheet (VDS) specified valves. Similarly we createinstances of manufacturer product type. Our approach enables automatedvalidation that a specific VDS is compliant with relevant industry standards.Using semantic reasoning and executable design rules, we also determine whetherthe product type meets the valve specification. Creation of shared, reusableIDO-based modular ontologies for design standards enables semantic reasoning tobe applied to equipment selection processes and demonstrates the potential ofthis approach for Standards Bodies wanting to transition to digitized SmartStandards.
Link: http://arxiv.org/abs/2510.01736v1
Updated: 2025-10-02T07:20:37Z

53: A cybersecurity AI agent selection and decision support framework
Authors: ['Masike Malatji']
Summary: This paper presents a novel, structured decision support framework thatsystematically aligns diverse artificial intelligence (AI) agent architectures,reactive, cognitive, hybrid, and learning, with the comprehensive NationalInstitute of Standards and Technology (NIST) Cybersecurity Framework (CSF) 2.0.By integrating agent theory with industry guidelines, this framework provides atransparent and stepwise methodology for selecting and deploying AI solutionsto address contemporary cyber threats. Employing a granular decomposition ofNIST CSF 2.0 functions into specific tasks, the study links essential AI agentproperties such as autonomy, adaptive learning, and real-time responsiveness toeach subcategory's security requirements. In addition, it outlines graduatedlevels of autonomy (assisted, augmented, and fully autonomous) to accommodateorganisations at varying stages of cybersecurity maturity. This holisticapproach transcends isolated AI applications, providing a unified detection,incident response, and governance strategy. Through conceptual validation, theframework demonstrates how tailored AI agent deployments can align withreal-world constraints and risk profiles, enhancing situational awareness,accelerating response times, and fortifying long-term resilience via adaptiverisk management. Ultimately, this research bridges the gap between theoreticalAI constructs and operational cybersecurity demands, establishing a foundationfor robust, empirically validated multi-agent systems that adhere to industrystandards.
Link: http://arxiv.org/abs/2510.01751v1
Updated: 2025-10-02T07:38:21Z

54: Unsupervised Dynamic Feature Selection for Robust Latent Spaces in  Vision Tasks
Authors: ['Bruno Corcuera', 'Carlos Eiras-Franco', 'Brais Cancela']
Summary: Latent representations are critical for the performance and robustness ofmachine learning models, as they encode the essential features of data in acompact and informative manner. However, in vision tasks, these representationsare often affected by noisy or irrelevant features, which can degrade themodel's performance and generalization capabilities. This paper presents anovel approach for enhancing latent representations using unsupervised DynamicFeature Selection (DFS). For each instance, the proposed method identifies andremoves misleading or redundant information in images, ensuring that only themost relevant features contribute to the latent space. By leveraging anunsupervised framework, our approach avoids reliance on labeled data, making itbroadly applicable across various domains and datasets. Experiments conductedon image datasets demonstrate that models equipped with unsupervised DFSachieve significant improvements in generalization performance across varioustasks, including clustering and image generation, while incurring a minimalincrease in the computational cost.
Link: http://arxiv.org/abs/2510.01758v1
Updated: 2025-10-02T07:46:59Z

55: Secure Multi-Modal Data Fusion in Federated Digital Health Systems via  MCP
Authors: ['Aueaphum Aueawatthanaphisut']
Summary: Secure and interoperable integration of heterogeneous medical data remains agrand challenge in digital health. Current federated learning (FL) frameworksoffer privacy-preserving model training but lack standardized mechanisms toorchestrate multi-modal data fusion across distributed and resource-constrainedenvironments. This study introduces a novel framework that leverages the ModelContext Protocol (MCP) as an interoperability layer for secure, cross-agentcommunication in multi-modal federated healthcare systems. The proposedarchitecture unifies three pillars: (i) multi-modal feature alignment forclinical imaging, electronic medical records, and wearable IoT data; (ii)secure aggregation with differential privacy to protect patient-sensitiveupdates; and (iii) energy-aware scheduling to mitigate dropouts in mobileclients. By employing MCP as a schema-driven interface, the framework enablesadaptive orchestration of AI agents and toolchains while ensuring compliancewith privacy regulations. Experimental evaluation on benchmark datasets andpilot clinical cohorts demonstrates up to 9.8\% improvement in diagnosticaccuracy compared with baseline FL, a 54\% reduction in client dropout rates,and clinically acceptable privacy--utility trade-offs. These results highlightMCP-enabled multi-modal fusion as a scalable and trustworthy pathway towardequitable, next-generation federated health infrastructures.
Link: http://arxiv.org/abs/2510.01780v1
Updated: 2025-10-02T08:19:56Z

56: Can LLMs Refuse Questions They Do Not Know? Measuring Knowledge-Aware  Refusal in Factual Tasks
Authors: ['Wenbo Pan', 'Jie Xu', 'Qiguang Chen', 'Junhao Dong', 'Libo Qin', 'Xinfeng Li', 'Haining Yu', 'Xiaohua Jia']
Summary: Large Language Models (LLMs) should refuse to answer questions beyond theirknowledge. This capability, which we term knowledge-aware refusal, is crucialfor factual reliability. However, existing metrics fail to faithfully measurethis ability. On the one hand, simple refusal-based metrics are biased byrefusal rates and yield inconsistent scores when models exhibit differentrefusal tendencies. On the other hand, existing calibration metrics areproxy-based, capturing the performance of auxiliary calibration processesrather than the model's actual refusal behavior. In this work, we propose theRefusal Index (RI), a principled metric that measures how accurately LLMsrefuse questions they do not know. We define RI as Spearman's rank correlationbetween refusal probability and error probability. To make RI practicallymeasurable, we design a lightweight two-pass evaluation method that efficientlyestimates RI from observed refusal rates across two standard evaluation runs.Extensive experiments across 16 models and 5 datasets demonstrate that RIaccurately quantifies a model's intrinsic knowledge-aware refusal capability infactual tasks. Notably, RI remains stable across different refusal rates andprovides consistent model rankings independent of a model's overall accuracyand refusal rates. More importantly, RI provides insight into an important butpreviously overlooked aspect of LLM factuality: while LLMs achieve highaccuracy on factual tasks, their refusal behavior can be unreliable andfragile. This finding highlights the need to complement traditional accuracymetrics with the Refusal Index for comprehensive factuality evaluation.
Link: http://arxiv.org/abs/2510.01782v1
Updated: 2025-10-02T08:20:36Z

57: Pack and Force Your Memory: Long-form and Consistent Video Generation
Authors: ['Xiaofei Wu', 'Guozhen Zhang', 'Zhiyong Xu', 'Yuan Zhou', 'Qinglin Lu', 'Xuming He']
Summary: Long-form video generation presents a dual challenge: models must capturelong-range dependencies while preventing the error accumulation inherent inautoregressive decoding. To address these challenges, we make twocontributions. First, for dynamic context modeling, we propose MemoryPack, alearnable context-retrieval mechanism that leverages both textual and imageinformation as global guidance to jointly model short- and long-termdependencies, achieving minute-level temporal consistency. This design scalesgracefully with video length, preserves computational efficiency, and maintainslinear complexity. Second, to mitigate error accumulation, we introduce DirectForcing, an efficient single-step approximating strategy that improvestraining-inference alignment and thereby curtails error propagation duringinference. Together, MemoryPack and Direct Forcing substantially enhance thecontext consistency and reliability of long-form video generation, advancingthe practical usability of autoregressive video models.
Link: http://arxiv.org/abs/2510.01784v1
Updated: 2025-10-02T08:22:46Z

58: Comparison of Unsupervised Metrics for Evaluating Judicial Decision  Extraction
Authors: ['Ivan Leonidovich Litvak', 'Anton Kostin', 'Fedor Lashkin', 'Tatiana Maksiyan', 'Sergey Lagutin']
Summary: The rapid advancement of artificial intelligence in legal natural languageprocessing demands scalable methods for evaluating text extraction fromjudicial decisions. This study evaluates 16 unsupervised metrics, includingnovel formulations, to assess the quality of extracting seven semantic blocksfrom 1,000 anonymized Russian judicial decisions, validated against 7,168expert reviews on a 1--5 Likert scale. These metrics, spanning document-based,semantic, structural, pseudo-ground truth, and legal-specific categories,operate without pre-annotated ground truth. Bootstrapped correlations, Lin'sconcordance correlation coefficient (CCC), and mean absolute error (MAE) revealthat Term Frequency Coherence (Pearson $r = 0.540$, Lin CCC = 0.512, MAE =0.127) and Coverage Ratio/Block Completeness (Pearson $r = 0.513$, Lin CCC =0.443, MAE = 0.139) best align with expert ratings, while Legal Term Density(Pearson $r = -0.479$, Lin CCC = -0.079, MAE = 0.394) show strong negativecorrelations. The LLM Evaluation Score (mean = 0.849, Pearson $r = 0.382$, LinCCC = 0.325, MAE = 0.197) showed moderate alignment, but its performance, usinggpt-4.1-mini via g4f, suggests limited specialization for legal textse. Thesefindings highlight that unsupervised metrics, including LLM-based approaches,enable scalable screening but, with moderate correlations and low CCC values,cannot fully replace human judgment in high-stakes legal contexts. This workadvances legal NLP by providing annotation-free evaluation tools, withimplications for judicial analytics and ethical AI deployment.
Link: http://arxiv.org/abs/2510.01792v1
Updated: 2025-10-02T08:32:16Z

59: Nav-EE: Navigation-Guided Early Exiting for Efficient Vision-Language  Models in Autonomous Driving
Authors: ['Haibo Hu', 'Lianming Huang', 'Xinyu Wang', 'Yufei Cui', 'Nan Guan', 'Chun Jason Xue']
Summary: Vision-Language Models (VLMs) are increasingly applied in autonomous drivingfor unified perception and reasoning, but high inference latency hindersreal-time deployment. Early-exit reduces latency by terminating inference atintermediate layers, yet its task-dependent nature limits generalization acrossdiverse scenarios. We observe that this limitation aligns with autonomousdriving: navigation systems can anticipate upcoming contexts (e.g.,intersections, traffic lights), indicating which tasks will be required. Wepropose Nav-EE, a navigation-guided early-exit framework that precomputestask-specific exit layers offline and dynamically applies them online based onnavigation priors. Experiments on CODA, Waymo, and BOSCH show that Nav-EEachieves accuracy comparable to full inference while reducing latency by up to63.9%. Real-vehicle integration with Autoware Universe further demonstratesreduced inference latency (600ms to 300ms), supporting faster decision-makingin complex scenarios. These results suggest that coupling navigation foresightwith early-exit offers a viable path toward efficient deployment of largemodels in autonomous systems. Code and data are available at our anonymousrepository: https://anonymous.4open.science/r/Nav-EE-BBC4
Link: http://arxiv.org/abs/2510.01795v1
Updated: 2025-10-02T08:37:58Z

60: Rethinking the shape convention of an MLP
Authors: ['Meng-Hsi Chen', 'Yu-Ang Lee', 'Feng-Ting Liao', 'Da-shan Shiu']
Summary: Multi-layer perceptrons (MLPs) conventionally follow a narrow-wide-narrowdesign where skip connections operate at the input/output dimensions whileprocessing occurs in expanded hidden spaces. We challenge this convention byproposing wide-narrow-wide (Hourglass) MLP blocks where skip connectionsoperate at expanded dimensions while residual computation flows through narrowbottlenecks. This inversion leverages higher-dimensional spaces for incrementalrefinement while maintaining computational efficiency through parameter-matcheddesigns. Implementing Hourglass MLPs requires an initial projection to liftinput signals to expanded dimensions. We propose that this projection canremain fixed at random initialization throughout training, enabling efficienttraining and inference implementations. We evaluate both architectures ongenerative tasks over popular image datasets, characterizingperformance-parameter Pareto frontiers through systematic architectural search.Results show that Hourglass architectures consistently achieve superior Paretofrontiers compared to conventional designs. As parameter budgets increase,optimal Hourglass configurations favor deeper networks with wider skipconnections and narrower bottlenecks-a scaling pattern distinct fromconventional MLPs. Our findings suggest reconsidering skip connection placementin modern architectures, with potential applications extending to Transformersand other residual networks.
Link: http://arxiv.org/abs/2510.01796v1
Updated: 2025-10-02T08:38:15Z

61: REBot: From RAG to CatRAG with Semantic Enrichment and Graph Routing
Authors: ['Thanh Ma', 'Tri-Tam La', 'Lam-Thu Le Huu', 'Minh-Nghi Nguyen', 'Khanh-Van Pham Luu', 'Huu-Hoa Nguyen']
Summary: Academic regulation advising is essential for helping students interpret andcomply with institutional policies, yet building effective systems requiresdomain specific regulatory resources. To address this challenge, we proposeREBot, an LLM enhanced advisory chatbot powered by CatRAG, a hybrid retrievalreasoning framework that integrates retrieval augmented generation with graphbased reasoning. CatRAG unifies dense retrieval and graph reasoning, supportedby a hierarchical, category labeled knowledge graph enriched with semanticfeatures for domain alignment. A lightweight intent classifier routes queriesto the appropriate retrieval modules, ensuring both factual accuracy andcontextual depth. We construct a regulation specific dataset and evaluate REBoton classification and question answering tasks, achieving state of the artperformance with an F1 score of 98.89%. Finally, we implement a web applicationthat demonstrates the practical value of REBot in real world academic advisingscenarios.
Link: http://arxiv.org/abs/2510.01800v1
Updated: 2025-10-02T08:40:55Z

62: SingMOS-Pro: An Comprehensive Benchmark for Singing Quality Assessment
Authors: ['Yuxun Tang', 'Lan Liu', 'Wenhao Feng', 'Yiwen Zhao', 'Jionghao Han', 'Yifeng Yu', 'Jiatong Shi', 'Qin Jin']
Summary: Singing voice generation progresses rapidly, yet evaluating singing qualityremains a critical challenge. Human subjective assessment, typically in theform of listening tests, is costly and time consuming, while existing objectivemetrics capture only limited perceptual aspects. In this work, we introduceSingMOS-Pro, a dataset for automatic singing quality assessment. Building onour preview version SingMOS, which provides only overall ratings, SingMOS-Proexpands annotations of the additional part to include lyrics, melody, andoverall quality, offering broader coverage and greater diversity. The datasetcontains 7,981 singing clips generated by 41 models across 12 datasets,spanning from early systems to recent advances. Each clip receives at leastfive ratings from professional annotators, ensuring reliability andconsistency. Furthermore, we explore how to effectively utilize MOS dataannotated under different standards and benchmark several widely usedevaluation methods from related tasks on SingMOS-Pro, establishing strongbaselines and practical references for future research. The dataset can beaccessed at https://huggingface.co/datasets/TangRain/SingMOS-Pro.
Link: http://arxiv.org/abs/2510.01812v1
Updated: 2025-10-02T08:53:49Z

63: Human-AI Teaming Co-Learning in Military Operations
Authors: ['Clara Maathuis', 'Kasper Cools']
Summary: In a time of rapidly evolving military threats and increasingly complexoperational environments, the integration of AI into military operations provessignificant advantages. At the same time, this implies various challenges andrisks regarding building and deploying human-AI teaming systems in an effectiveand ethical manner. Currently, understanding and coping with them are oftentackled from an external perspective considering the human-AI teaming system asa collective agent. Nevertheless, zooming into the dynamics involved inside thesystem assures dealing with a broader palette of relevant multidimensionalresponsibility, safety, and robustness aspects. To this end, this researchproposes the design of a trustworthy co-learning model for human-AI teaming inmilitary operations that encompasses a continuous and bidirectional exchange ofinsights between the human and AI agents as they jointly adapt to evolvingbattlefield conditions. It does that by integrating four dimensions. First,adjustable autonomy for dynamically calibrating the autonomy levels of agentsdepending on aspects like mission state, system confidence, and environmentaluncertainty. Second, multi-layered control which accounts continuous oversight,monitoring of activities, and accountability. Third, bidirectional feedbackwith explicit and implicit feedback loops between the agents to assure a propercommunication of reasoning, uncertainties, and learned adaptations that each ofthe agents has. And fourth, collaborative decision-making which implies thegeneration, evaluation, and proposal of decisions associated with confidencelevels and rationale behind them. The model proposed is accompanied by concreteexemplifications and recommendations that contribute to further developingresponsible and trustworthy human-AI teaming systems in military operations.
Link: http://arxiv.org/abs/2510.01815v1
Updated: 2025-10-02T09:01:01Z

64: Plan Then Action:High-Level Planning Guidance Reinforcement Learning for  LLM Reasoning
Authors: ['Zhihao Dou', 'Qinjian Zhao', 'Zhongwei Wan', 'Dinggen Zhang', 'Weida Wang', 'Towsif Raiyan', 'Benteng Chen', 'Qingtao Pan', 'Yang Ouyang', 'Zhiqiang Gao', 'Shufei Zhang', 'Sumon Biswas']
Summary: Large language models (LLMs) have demonstrated remarkable reasoning abilitiesin complex tasks, often relying on Chain-of-Thought (CoT) reasoning. However,due to their autoregressive token-level generation, the reasoning process islargely constrained to local decision-making and lacks global planning. Thislimitation frequently results in redundant, incoherent, or inaccuratereasoning, which significantly degrades overall performance. Existingapproaches, such as tree-based algorithms and reinforcement learning (RL),attempt to address this issue but suffer from high computational costs andoften fail to produce optimal reasoning trajectories. To tackle this challenge,we propose Plan-Then-Action Enhanced Reasoning with Group Relative PolicyOptimization PTA-GRPO, a two-stage framework designed to improve bothhigh-level planning and fine-grained CoT reasoning. In the first stage, weleverage advanced LLMs to distill CoT into compact high-level guidance, whichis then used for supervised fine-tuning (SFT). In the second stage, weintroduce a guidance-aware RL method that jointly optimizes the final outputand the quality of high-level guidance, thereby enhancing reasoningeffectiveness. We conduct extensive experiments on multiple mathematicalreasoning benchmarks, including MATH, AIME2024, AIME2025, and AMC, acrossdiverse base models such as Qwen2.5-7B-Instruct, Qwen3-8B, Qwen3-14B, andLLaMA3.2-3B. Experimental results demonstrate that PTA-GRPO consistentlyachieves stable and significant improvements across different models and tasks,validating its effectiveness and generalization.
Link: http://arxiv.org/abs/2510.01833v1
Updated: 2025-10-02T09:28:13Z

65: Pre-Hoc Predictions in AutoML: Leveraging LLMs to Enhance Model  Selection and Benchmarking for Tabular datasets
Authors: ['Yannis Belkhiter', 'Seshu Tirupathi', 'Giulio Zizzo', 'Sachin Sharma', 'John D. Kelleher']
Summary: The field of AutoML has made remarkable progress in post-hoc model selection,with libraries capable of automatically identifying the most performing modelsfor a given dataset. Nevertheless, these methods often rely on exhaustivehyperparameter searches, where methods automatically train and test differenttypes of models on the target dataset. Contrastingly, pre-hoc predictionemerges as a promising alternative, capable of bypassing exhaustive searchthrough intelligent pre-selection of models. Despite its potential, pre-hocprediction remains under-explored in the literature. This paper explores theintersection of AutoML and pre-hoc model selection by leveraging traditionalmodels and Large Language Model (LLM) agents to reduce the search space ofAutoML libraries. By relying on dataset descriptions and statisticalinformation, we reduce the AutoML search space. Our methodology is applied tothe AWS AutoGluon portfolio dataset, a state-of-the-art AutoML benchmarkcontaining 175 tabular classification datasets available on OpenML. Theproposed approach offers a shift in AutoML workflows, significantly reducingcomputational overhead, while still selecting the best model for the givendataset.
Link: http://arxiv.org/abs/2510.01842v1
Updated: 2025-10-02T09:37:12Z

66: NGGAN: Noise Generation GAN Based on the Practical Measurement Dataset  for Narrowband Powerline Communications
Authors: ['Ying-Ren Chien', 'Po-Heng Chou', 'You-Jie Peng', 'Chun-Yuan Huang', 'Hen-Wai Tsao', 'Yu Tsao']
Summary: Capturing comprehensive statistics of nonperiodic asynchronous impulsivenoise is a critical issue in enhancing impulse noise processing for narrowbandpowerline communication (NB-PLC) transceivers. However, existing mathematicalnoise generative models capture only some of the characteristics of additivenoise. Therefore, we propose a generative adversarial network (GAN), called thenoise-generation GAN (NGGAN), that learns the complicated characteristics ofpractically measured noise samples for data augmentation. To closely match thestatistics of complicated noise in NB-PLC systems, we measured the NB-PLC noisevia the analog coupling and bandpass filtering circuits of a commercial NB-PLCmodem to build a realistic dataset. Specifically, the NGGAN design approachesbased on the practically measured dataset are as follows: (i) we design thelength of input signals that the NGGAN model can fit to facilitatecyclo-stationary noise generation. (ii) Wasserstein distance is used as a lossfunction to enhance the similarity between the generated noise and the trainingdataset and ensure that the sample diversity is sufficient for variousapplications. (iii) To measure the similarity performance of the GAN-basedmodels based on mathematical and practically measured datasets, we performquantitative and qualitative analyses. The training datasets include (1) apiecewise spectral cyclo-stationary Gaussian model (PSCGM), (2) afrequency-shift (FRESH) filter, and (3) practical measurements from NB-PLCsystems. Simulation results demonstrate that the proposed NGGAN trained usingwaveform characteristics is closer to the practically measured dataset in termsof the quality of the generated noise.
Link: http://dx.doi.org/10.1109/TIM.2024.3523361
Updated: 2025-10-02T09:47:56Z

67: Learning a Dense Reasoning Reward Model from Expert Demonstration via  Inverse Reinforcement Learning
Authors: ['Claudio Fanconi', 'Nicolás Astorga', 'Mihaela van der Schaar']
Summary: We reframe and operationalise adversarial inverse reinforcement learning(IRL) to large language model reasoning, learning a dense, token-level rewardmodel for process supervision directly from expert demonstrations rather thanimitating style via supervised fine-tuning. The learned reasoning reward servestwo complementary roles: (i) it provides step-level feedback to optimise areasoning policy during training; and (ii) it functions at inference as acritic to rerank sampled traces under fixed compute budgets. We demonstratethat our approach prioritises correctness over surface form, yielding scoresthat correlate with eventual answer validity and enabling interpretablelocalisation of errors within a trace. Empirically, on GSM8K with Llama3 andQwen2.5 backbones, we demonstrate: (i) dense reasoning rewards can be used as alearning signal to elicit reasoning, and (ii) predictive performance isimproved from reward-guided reranking (notably for Llama-based policies). Byunifying training signals, inference-time selection, and token-leveldiagnostics into a single reasoning reward, this work suggests reusableprocess-level rewards with broad potential to enhance multi-step reasoning inlanguage models.
Link: http://arxiv.org/abs/2510.01857v1
Updated: 2025-10-02T09:55:26Z

68: A Modular Theory of Subjective Consciousness for Natural and Artificial  Minds
Authors: ['Michaël Gillon']
Summary: Understanding how subjective experience arises from information processingremains a central challenge in neuroscience, cognitive science, and AIresearch. The Modular Consciousness Theory (MCT) proposes a biologicallygrounded and computationally explicit framework in which consciousness is adiscrete sequence of Integrated Informational States (IISs). Each IIS is apacket of integrated information tagged with a multidimensional density vectorthat quantifies informational richness. Its magnitude correlates withsubjective intensity, shaping memory, behavior, and continuity of experience.Inputs from body and environment are adaptively filtered, processed by modules(abstraction, narration, evaluation, self-evaluation), and integrated into anIIS. The resulting packet, tagged with its density vector, is transmitted tobehavioral readiness, memory, and decision-making modules, closing the loop.This explains why strongly tagged states exert greater influence on long-termmemory and action. Unlike Global Workspace Theory, Integrated InformationTheory, or Higher-Order Thought, MCT specifies a full computational pipelineproducing discrete informational units with quantifiable internal structure.Subjectivity is reframed as a correlate of the density-tagging signal withfunctional consequences. MCT generates testable predictions, such as stressenhancing memory encoding, and provides a naturalistic blueprint for bothbiological and artificial architectures. Consciousness, in this view, is not anirreducible essence but an evolvable, quantifiable, and constructible featureof complex information processing.
Link: http://arxiv.org/abs/2510.01864v1
Updated: 2025-10-02T10:11:56Z

69: TACOS: Task Agnostic COordinator of a multi-drone System
Authors: ['Alessandro Nazzari', 'Roberto Rubinacci', 'Marco Lovera']
Summary: When a single pilot is responsible for managing a multi-drone system, thetask demands varying levels of autonomy, from direct control of individualUAVs, to group-level coordination, to fully autonomous swarm behaviors foraccomplishing high-level tasks. Enabling such flexible interaction requires aframework that supports multiple modes of shared autonomy. As language modelscontinue to improve in reasoning and planning, they provide a naturalfoundation for such systems, reducing pilot workload by enabling high-leveltask delegation through intuitive, language-based interfaces. In this paper wepresent TACOS (Task-Agnostic COordinator of a multi-drone System), a unifiedframework that enables high-level natural language control of multi-UAV systemsthrough Large Language Models (LLMs). TACOS integrates three key capabilitiesinto a single architecture: a one-to-many natural language interface forintuitive user interaction, an intelligent coordinator for translating userintent into structured task plans, and an autonomous agent that executes plansinteracting with the real-world. TACOS allows a LLM to interact with a libraryof executable APIs, bridging semantic reasoning with real-time multi-robotcoordination. We demonstrate the system in real-world multi-drone system andconduct an ablation study to assess the contribution of each module.
Link: http://arxiv.org/abs/2510.01869v1
Updated: 2025-10-02T10:21:35Z

70: REPAIR: Robust Editing via Progressive Adaptive Intervention and  Reintegration
Authors: ['Yisu Wang', 'Ming Wang', 'Haoyuan Song', 'Wenjie Huang', 'Chaozheng Wang', 'Yi Xie', 'Xuming Ran']
Summary: Post-training for large language models (LLMs) is constrained by the highcost of acquiring new knowledge or correcting errors and by the unintended sideeffects that frequently arise from retraining. To address these issues, weintroduce REPAIR (Robust Editing via Progressive Adaptive Intervention andReintegration), a lifelong editing framework designed to support precise andlow-cost model updates while preserving non-target knowledge. REPAIR mitigatesthe instability and conflicts of large-scale sequential edits through aclosed-loop feedback mechanism coupled with dynamic memory management.Furthermore, by incorporating frequent knowledge fusion and enforcing stronglocality guards, REPAIR effectively addresses the shortcomings of traditionaldistribution-agnostic approaches that often overlook unintended ripple effects.Our experiments demonstrate that REPAIR boosts editing accuracy by 10%-30%across multiple model families and significantly reduces knowledge forgetting.This work introduces a robust framework for developing reliable, scalable, andcontinually evolving LLMs.
Link: http://arxiv.org/abs/2510.01879v1
Updated: 2025-10-02T10:35:39Z

71: FINCH: Financial Intelligence using Natural language for Contextualized  SQL Handling
Authors: ['Avinash Kumar Singh', 'Bhaskarjit Sarmah', 'Stefano Pasquali']
Summary: Text-to-SQL, the task of translating natural language questions into SQLqueries, has long been a central challenge in NLP. While progress has beensignificant, applying it to the financial domain remains especially difficultdue to complex schema, domain-specific terminology, and high stakes of error.Despite this, there is no dedicated large-scale financial dataset to advanceresearch, creating a critical gap. To address this, we introduce a curatedfinancial dataset (FINCH) comprising 292 tables and 75,725 natural language-SQLpairs, enabling both fine-tuning and rigorous evaluation. Building on thisresource, we benchmark reasoning models and language models of varying scales,providing a systematic analysis of their strengths and limitations in financialText-to-SQL tasks. Finally, we propose a finance-oriented evaluation metric(FINCH Score) that captures nuances overlooked by existing measures, offering amore faithful assessment of model performance.
Link: http://arxiv.org/abs/2510.01887v1
Updated: 2025-10-02T10:55:11Z

72: Small is Sufficient: Reducing the World AI Energy Consumption Through  Model Selection
Authors: ['Tiago da Silva Barros', 'Frédéric Giroire', 'Ramon Aparicio-Pardo', 'Joanna Moulierac']
Summary: The energy consumption and carbon footprint of Artificial Intelligence (AI)have become critical concerns due to rising costs and environmental impacts. Inresponse, a new trend in green AI is emerging, shifting from the "bigger isbetter" paradigm, which prioritizes large models, to "small is sufficient",emphasizing energy sobriety through smaller, more efficient models.  We explore how the AI community can adopt energy sobriety today by focusingon model selection during inference. Model selection consists of choosing themost appropriate model for a given task, a simple and readily applicablemethod, unlike approaches requiring new hardware or architectures. Ourhypothesis is that, as in many industrial activities, marginal utility gainsdecrease with increasing model size. Thus, applying model selection cansignificantly reduce energy consumption while maintaining good utility for AIinference.  We conduct a systematic study of AI tasks, analyzing their popularity, modelsize, and efficiency. We examine how the maturity of different tasks and modeladoption patterns impact the achievable energy savings, ranging from 1% to 98%for different tasks. Our estimates indicate that applying model selection couldreduce AI energy consumption by 27.8%, saving 31.9 TWh worldwide in 2025 -equivalent to the annual output of five nuclear power reactors.
Link: http://arxiv.org/abs/2510.01889v1
Updated: 2025-10-02T10:58:13Z

73: HRTFformer: A Spatially-Aware Transformer for Personalized HRTF  Upsampling in Immersive Audio Rendering
Authors: ['Xuyi Hu', 'Jian Li', 'Shaojie Zhang', 'Stefan Goetz', 'Lorenzo Picinali', 'Ozgur B. Akan', 'Aidan O. T. Hogg']
Summary: Personalized Head-Related Transfer Functions (HRTFs) are starting to beintroduced in many commercial immersive audio applications and are crucial forrealistic spatial audio rendering. However, one of the main hesitationsregarding their introduction is that creating personalized HRTFs is impracticalat scale due to the complexities of the HRTF measurement process. To mitigatethis drawback, HRTF spatial upsampling has been proposed with the aim ofreducing measurements required. While prior work has seen success withdifferent machine learning (ML) approaches, these models often struggle withlong-range spatial consistency and generalization at high upsampling factors.In this paper, we propose a novel transformer-based architecture for HRTFupsampling, leveraging the attention mechanism to better capture spatialcorrelations across the HRTF sphere. Working in the spherical harmonic (SH)domain, our model learns to reconstruct high-resolution HRTFs from sparse inputmeasurements with significantly improved accuracy. To enhance spatialcoherence, we introduce a neighbor dissimilarity loss that promotes magnitudesmoothness, yielding more realistic upsampling. We evaluate our method usingboth perceptual localization models and objective spectral distortion metrics.Experiments show that our model surpasses leading methods by a substantialmargin in generating realistic, high-fidelity HRTFs.
Link: http://arxiv.org/abs/2510.01891v1
Updated: 2025-10-02T10:59:21Z

74: Multimodal Foundation Models for Early Disease Detection
Authors: ['Md Talha Mohsin', 'Ismail Abdulrashid']
Summary: Healthcare generates diverse streams of data, including electronic healthrecords (EHR), medical imaging, genetics, and ongoing monitoring from wearabledevices. Traditional diagnostic models frequently analyze these sources inisolation, which constrains their capacity to identify cross-modal correlationsessential for early disease diagnosis. Our research presents a multimodalfoundation model that consolidates diverse patient data through anattention-based transformer framework. At first, dedicated encoders put eachmodality into a shared latent space. Then, they combine them using multi-headattention and residual normalization. The architecture is made for pretrainingon many tasks, which makes it easy to adapt to new diseases and datasets withlittle extra work. We provide an experimental strategy that uses benchmarkdatasets in oncology, cardiology, and neurology, with the goal of testing earlydetection tasks. The framework includes data governance and model managementtools in addition to technological performance to improve transparency,reliability, and clinical interpretability. The suggested method works toward asingle foundation model for precision diagnostics, which could improve theaccuracy of predictions and help doctors make decisions.
Link: http://arxiv.org/abs/2510.01899v1
Updated: 2025-10-02T11:12:57Z

75: Constrained Adaptive Rejection Sampling
Authors: ['Paweł Parys', 'Sairam Vaidya', 'Taylor Berg-Kirkpatrick', "Loris D'Antoni"]
Summary: Language Models (LMs) are increasingly used in applications where generatedoutputs must satisfy strict semantic or syntactic constraints. Existingapproaches to constrained generation fall along a spectrum: greedy constraineddecoding methods enforce validity during decoding but distort the LM'sdistribution, while rejection sampling (RS) preserves fidelity but wastescomputation by discarding invalid outputs. Both extremes are problematic indomains such as program fuzzing, where both validity and diversity of samplesare essential. We present Constrained Adaptive Rejection Sampling (CARS), anapproach that strictly improves the sample-efficiency of RS withoutdistributional distortion. CARS begins with unconstrained LM sampling andadaptively rules out constraint-violating continuations by recording them in atrie and subtracting their probability mass from future draws. This adaptivepruning ensures that prefixes proven invalid are never revisited, acceptancerates improve monotonically, and the resulting samples exactly follow theconstrained distribution. In experiments on a variety of domains -- e.g.,program fuzzing and molecular generation -- CARS consistently achieves higherefficiency -- measured in the number of LM forward passes per valid sample --while also producing stronger sample diversity than both GCD and methods thatapproximate the LM's distribution.
Link: http://arxiv.org/abs/2510.01902v1
Updated: 2025-10-02T11:17:26Z

76: Are LLMs Better GNN Helpers? Rethinking Robust Graph Learning under  Deficiencies with Iterative Refinement
Authors: ['Zhaoyan Wang', 'Zheng Gao', 'Arogya Kharel', 'In-Young Ko']
Summary: Graph Neural Networks (GNNs) are widely adopted in Web-related applications,serving as a core technique for learning from graph-structured data, such astext-attributed graphs. Yet in real-world scenarios, such graphs exhibitdeficiencies that substantially undermine GNN performance. While priorGNN-based augmentation studies have explored robustness against individualimperfections, a systematic understanding of how graph-native and LargeLanguage Models (LLMs) enhanced methods behave under compound deficiencies isstill missing. Specifically, there has been no comprehensive investigationcomparing conventional approaches and recent LLM-on-graph frameworks, leavingtheir merits unclear. To fill this gap, we conduct the first empirical studythat benchmarks these two lines of methods across diverse graph deficiencies,revealing overlooked vulnerabilities and challenging the assumption that LLMaugmentation is consistently superior. Building on empirical findings, wepropose Robust Graph Learning via Retrieval-Augmented Contrastive Refinement(RoGRAD) framework. Unlike prior one-shot LLM-as-Enhancer designs, RoGRAD isthe first iterative paradigm that leverages Retrieval-Augmented Generation(RAG) to inject retrieval-grounded augmentations by supplying class-consistent,diverse augmentations and enforcing discriminative representations throughiterative graph contrastive learning. It transforms LLM augmentation for graphsfrom static signal injection into dynamic refinement. Extensive experimentsdemonstrate RoGRAD's superiority over both conventional GNN- and LLM-enhancedbaselines, achieving up to 82.43% average improvement.
Link: http://arxiv.org/abs/2510.01910v1
Updated: 2025-10-02T11:30:51Z

77: Automated Defect Detection for Mass-Produced Electronic Components Based  on YOLO Object Detection Models
Authors: ['Wei-Lung Mao', 'Chun-Chi Wang', 'Po-Heng Chou', 'Yen-Ting Liu']
Summary: Since the defect detection of conventional industry components istime-consuming and labor-intensive, it leads to a significant burden on qualityinspection personnel and makes it difficult to manage product quality. In thispaper, we propose an automated defect detection system for the dual in-linepackage (DIP) that is widely used in industry, using digital camera optics anda deep learning (DL)-based model. The two most common defect categories of DIPare examined: (1) surface defects, and (2) pin-leg defects. However, the lackof defective component images leads to a challenge for detection tasks. Tosolve this problem, the ConSinGAN is used to generate a suitable-sized datasetfor training and testing. Four varieties of the YOLO model are investigated(v3, v4, v7, and v9), both in isolation and with the ConSinGAN augmentation.The proposed YOLOv7 with ConSinGAN is superior to the other YOLO versions inaccuracy of 95.50\%, detection time of 285 ms, and is far superior tothreshold-based approaches. In addition, the supervisory control and dataacquisition (SCADA) system is developed, and the associated sensor architectureis described. The proposed automated defect detection can be easily establishedwith numerous types of defects or insufficient defect data.
Link: http://dx.doi.org/10.1109/JSEN.2024.3418618
Updated: 2025-10-02T11:33:16Z

78: To Mask or to Mirror: Human-AI Alignment in Collective Reasoning
Authors: ['Crystal Qian', 'Aaron Parisi', 'Clémentine Bouleau', 'Vivian Tsai', 'Maël Lebreton', 'Lucas Dixon']
Summary: As large language models (LLMs) are increasingly used to model and augmentcollective decision-making, it is critical to examine their alignment withhuman social reasoning. We present an empirical framework for assessingcollective alignment, in contrast to prior work on the individual level. Usingthe Lost at Sea social psychology task, we conduct a large-scale onlineexperiment (N=748), randomly assigning groups to leader elections with eithervisible demographic attributes (e.g. name, gender) or pseudonymous aliases. Wethen simulate matched LLM groups conditioned on the human data, benchmarkingGemini 2.5, GPT 4.1, Claude Haiku 3.5, and Gemma 3. LLM behaviors diverge: somemirror human biases; others mask these biases and attempt to compensate forthem. We empirically demonstrate that human-AI alignment in collectivereasoning depends on context, cues, and model-specific inductive biases.Understanding how LLMs align with collective human behavior is critical toadvancing socially-aligned AI, and demands dynamic benchmarks that capture thecomplexities of collective reasoning.
Link: http://arxiv.org/abs/2510.01924v1
Updated: 2025-10-02T11:41:30Z

79: Foundation Visual Encoders Are Secretly Few-Shot Anomaly Detectors
Authors: ['Guangyao Zhai', 'Yue Zhou', 'Xinyan Deng', 'Lars Heckler', 'Nassir Navab', 'Benjamin Busam']
Summary: Few-shot anomaly detection streamlines and simplifies industrial safetyinspection. However, limited samples make accurate differentiation betweennormal and abnormal features challenging, and even more so undercategory-agnostic conditions. Large-scale pre-training of foundation visualencoders has advanced many fields, as the enormous quantity of data helps tolearn the general distribution of normal images. We observe that the anomalyamount in an image directly correlates with the difference in the learntembeddings and utilize this to design a few-shot anomaly detector termedFoundAD. This is done by learning a nonlinear projection operator onto thenatural image manifold. The simple operator acts as an effective tool foranomaly detection to characterize and identify out-of-distribution regions inan image. Extensive experiments show that our approach supports multi-classdetection and achieves competitive performance while using substantially fewerparameters than prior methods. Backed up by evaluations with multiplefoundation encoders, including fresh DINOv3, we believe this idea broadens theperspective on foundation features and advances the field of few-shot anomalydetection.
Link: http://arxiv.org/abs/2510.01934v1
Updated: 2025-10-02T11:53:20Z

80: Exploring Resolution-Wise Shared Attention in Hybrid Mamba-U-Nets for  Improved Cross-Corpus Speech Enhancement
Authors: ['Nikolai Lund Kühne', 'Jesper Jensen', 'Jan Østergaard', 'Zheng-Hua Tan']
Summary: Recent advances in speech enhancement have shown that models combining Mambaand attention mechanisms yield superior cross-corpus generalizationperformance. At the same time, integrating Mamba in a U-Net structure hasyielded state-of-the-art enhancement performance, while reducing both modelsize and computational complexity. Inspired by these insights, we proposeRWSA-MambaUNet, a novel and efficient hybrid model combining Mamba andmulti-head attention in a U-Net structure for improved cross-corpusperformance. Resolution-wise shared attention (RWSA) refers to layerwiseattention-sharing across corresponding time- and frequency resolutions. Ourbest-performing RWSA-MambaUNet model achieves state-of-the-art generalizationperformance on two out-of-domain test sets. Notably, our smallest modelsurpasses all baselines on the out-of-domain DNS 2020 test set in terms ofPESQ, SSNR, and ESTOI, and on the out-of-domain EARS-WHAM_v2 test set in termsof SSNR, ESTOI, and SI-SDR, while using less than half the model parameters anda fraction of the FLOPs.
Link: http://arxiv.org/abs/2510.01958v1
Updated: 2025-10-02T12:27:29Z

81: ZK-WAGON: Imperceptible Watermark for Image Generation Models using  ZK-SNARKs
Authors: ['Aadarsh Anantha Ramakrishnan', 'Shubham Agarwal', 'Selvanayagam S', 'Kunwar Singh']
Summary: As image generation models grow increasingly powerful and accessible,concerns around authenticity, ownership, and misuse of synthetic media havebecome critical. The ability to generate lifelike images indistinguishable fromreal ones introduces risks such as misinformation, deepfakes, and intellectualproperty violations. Traditional watermarking methods either degrade imagequality, are easily removed, or require access to confidential model internals- making them unsuitable for secure and scalable deployment. We are the firstto introduce ZK-WAGON, a novel system for watermarking image generation modelsusing the Zero-Knowledge Succinct Non Interactive Argument of Knowledge(ZK-SNARKs). Our approach enables verifiable proof of origin without exposingmodel weights, generation prompts, or any sensitive internal information. Wepropose Selective Layer ZK-Circuit Creation (SL-ZKCC), a method to selectivelyconvert key layers of an image generation model into a circuit, reducing proofgeneration time significantly. Generated ZK-SNARK proofs are imperceptiblyembedded into a generated image via Least Significant Bit (LSB) steganography.We demonstrate this system on both GAN and Diffusion models, providing asecure, model-agnostic pipeline for trustworthy AI image generation.
Link: http://arxiv.org/abs/2510.01967v1
Updated: 2025-10-02T12:39:57Z

82: Clarifying Semantics of In-Context Examples for Unit Test Generation
Authors: ['Chen Yang', 'Lin Yang', 'Ziqi Wang', 'Dong Wang', 'Jianyi Zhou', 'Junjie Chen']
Summary: Recent advances in large language models (LLMs) have enabled promisingperformance in unit test generation through in-context learning (ICL). However,the quality of in-context examples significantly influences the effectivenessof generated tests-poorly structured or semantically unclear test examplesoften lead to suboptimal outputs. In this paper, we propose CLAST, a noveltechnique that systematically refines unit tests to improve their semanticclarity, thereby enhancing their utility as in-context examples. The approachdecomposes complex tests into logically clearer ones and improves semanticclarity through a combination of program analysis and LLM-based rewriting. Weevaluated CLAST on four open-source and three industrial projects. The resultsdemonstrate that CLAST largely outperforms UTgen, the state-of-the-artrefinement technique, in both preserving test effectiveness and enhancingsemantic clarity. Specifically, CLAST fully retains the original effectivenessof unit tests, while UTgen reduces compilation success rate (CSR), pass rate(PR), test coverage (Cov), and mutation score (MS) by an average of 12.90%,35.82%, 4.65%, and 5.07%, respectively. Over 85.33% of participants in our userstudy preferred the semantic clarity of CLAST-refined tests. Notably,incorporating CLAST-refined tests as examples effectively improves ICL-basedunit test generation approaches such as RAGGen and TELPA, resulting in anaverage increase of 25.97% in CSR, 28.22% in PR, and 45.99% in Cov forgenerated tests, compared to incorporating UTgen-refined tests. The insightsfrom the follow-up user study not only reinforce CLAST's potential impact insoftware testing practice but also illuminate avenues for future research.
Link: http://arxiv.org/abs/2510.01994v1
Updated: 2025-10-02T13:15:40Z

83: Generating Findings for Jaw Cysts in Dental Panoramic Radiographs Using  GPT-4o: Building a Two-Stage Self-Correction Loop with Structured Output  (SLSO) Framework
Authors: ['Nanaka Hosokawa', 'Ryo Takahashi', 'Tomoya Kitano', 'Yukihiro Iida', 'Chisako Muramatsu', 'Tatsuro Hayashi', 'Yuta Seino', 'Xiangrong Zhou', 'Takeshi Hara', 'Akitoshi Katsumata', 'Hiroshi Fujita']
Summary: In this study, we utilized the multimodal capabilities of OpenAI GPT-4o toautomatically generate jaw cyst findings on dental panoramic radiographs. Toimprove accuracy, we constructed a Self-correction Loop with Structured Output(SLSO) framework and verified its effectiveness. A 10-step process wasimplemented for 22 cases of jaw cysts, including image input and analysis,structured data generation, tooth number extraction and consistency checking,iterative regeneration when inconsistencies were detected, and findinggeneration with subsequent restructuring and consistency verification. Acomparative experiment was conducted using the conventional Chain-of-Thought(CoT) method across seven evaluation items: transparency, internal structure,borders, root resorption, tooth movement, relationships with other structures,and tooth number. The results showed that the proposed SLSO framework improvedoutput accuracy for many items, with 66.9%, 33.3%, and 28.6% improvement ratesfor tooth number, tooth movement, and root resorption, respectively. In thesuccessful cases, a consistently structured output was achieved after up tofive regenerations. Although statistical significance was not reached becauseof the small size of the dataset, the overall SLSO framework enforced negativefinding descriptions, suppressed hallucinations, and improved tooth numberidentification accuracy. However, the accurate identification of extensivelesions spanning multiple teeth is limited. Nevertheless, further refinement isrequired to enhance overall performance and move toward a practical findinggeneration system.
Link: http://arxiv.org/abs/2510.02001v1
Updated: 2025-10-02T13:22:13Z

84: Zero-shot reasoning for simulating scholarly peer-review
Authors: ['Khalid M. Saqr']
Summary: The scholarly publishing ecosystem faces a dual crisis of unmanageablesubmission volumes and unregulated AI, creating an urgent need for newgovernance models to safeguard scientific integrity. The traditional human-onlypeer review regime lacks a scalable, objective benchmark, making editorialprocesses opaque and difficult to audit. Here we investigate a deterministicsimulation framework that provides the first stable, evidence-based standardfor evaluating AI-generated peer review reports. Analyzing 352 peer-reviewsimulation reports, we identify consistent system state indicators thatdemonstrate its reliability. First, the system is able to simulate calibratededitorial judgment, with 'Revise' decisions consistently forming the majorityoutcome (>50%) across all disciplines, while 'Reject' rates dynamically adaptto field-specific norms, rising to 45% in Health Sciences. Second, it maintainsunwavering procedural integrity, enforcing a stable 29% evidence-anchoringcompliance rate that remains invariant across diverse review tasks andscientific domains. These findings demonstrate a system that is predictablyrule-bound, mitigating the stochasticity of generative AI. For the scientificcommunity, this provides a transparent tool to ensure fairness; for publishingstrategists, it offers a scalable instrument for auditing workflows, managingintegrity risks, and implementing evidence-based governance. The frameworkrepositions AI as an essential component of institutional accountability,providing the critical infrastructure to maintain trust in scholarlycommunication.
Link: http://arxiv.org/abs/2510.02027v1
Updated: 2025-10-02T13:59:14Z

85: LiLa-Net: Lightweight Latent LiDAR Autoencoder for 3D Point Cloud  Reconstruction
Authors: ['Mario Resino', 'Borja Pérez', 'Jaime Godoy', 'Abdulla Al-Kaff', 'Fernando García']
Summary: This work proposed a 3D autoencoder architecture, named LiLa-Net, whichencodes efficient features from real traffic environments, employing only theLiDAR's point clouds. For this purpose, we have real semi-autonomous vehicle,equipped with Velodyne LiDAR. The system leverage skip connections concept toimprove the performance without using extensive resources as thestate-of-the-art architectures. Key changes include reducing the number ofencoder layers and simplifying the skip connections, while still producing anefficient and representative latent space which allows to accuratelyreconstruct the original point cloud. Furthermore, an effective balance hasbeen achieved between the information carried by the skip connections and thelatent encoding, leading to improved reconstruction quality withoutcompromising performance. Finally, the model demonstrates strong generalizationcapabilities, successfully reconstructing objects unrelated to the originaltraffic environment.
Link: http://arxiv.org/abs/2510.02028v1
Updated: 2025-10-02T14:00:20Z

86: The Current State of AI Bias Bounties: An Overview of Existing  Programmes and Research
Authors: ['Sergej Kucenko', 'Nathaniel Dennler', 'Fengxiang He']
Summary: Current bias evaluation methods rarely engage with communities impacted by AIsystems. Inspired by bug bounties, bias bounties have been proposed as areward-based method that involves communities in AI bias detection by askingusers of AI systems to report biases they encounter when interacting with suchsystems. In the absence of a state-of-the-art review, this survey aimed toidentify and analyse existing AI bias bounty programmes and to present academicliterature on bias bounties. Google, Google Scholar, PhilPapers, and IEEEXplore were searched, and five bias bounty programmes, as well as five researchpublications, were identified. All bias bounties were organised by U.S.-basedorganisations as time-limited contests, with public participation in fourprogrammes and prize pools ranging from 7,000 to 24,000 USD. The five researchpublications included a report on the application of bug bounties toalgorithmic harms, an article addressing Twitter's bias bounty, a proposal forbias bounties as an institutional mechanism to increase AI scrutiny, a workshopdiscussing bias bounties from queer perspectives, and an algorithmic frameworkfor bias bounties. We argue that reducing the technical requirements to enterbounty programmes is important to include those without coding experience.Given the limited adoption of bias bounties, future efforts should explore thetransferability of the best practices from bug bounties and examine how suchprogrammes can be designed to be sensitive to underrepresented groups whilelowering adoption barriers for organisations.
Link: http://arxiv.org/abs/2510.02036v1
Updated: 2025-10-02T14:09:11Z

87: ReTabAD: A Benchmark for Restoring Semantic Context in Tabular Anomaly  Detection
Authors: ['Sanghyu Yoon', 'Dongmin Kim', 'Suhee Yoon', 'Ye Seul Sim', 'Seungdong Yoa', 'Hye-Seung Cho', 'Soonyoung Lee', 'Hankook Lee', 'Woohyung Lim']
Summary: In tabular anomaly detection (AD), textual semantics often carry criticalsignals, as the definition of an anomaly is closely tied to domain-specificcontext. However, existing benchmarks provide only raw data points withoutsemantic context, overlooking rich textual metadata such as featuredescriptions and domain knowledge that experts rely on in practice. Thislimitation restricts research flexibility and prevents models from fullyleveraging domain knowledge for detection. ReTabAD addresses this gap byrestoring textual semantics to enable context-aware tabular AD research. Weprovide (1) 20 carefully curated tabular datasets enriched with structuredtextual metadata, together with implementations of state-of-the-art ADalgorithms including classical, deep learning, and LLM-based approaches, and(2) a zero-shot LLM framework that leverages semantic context withouttask-specific training, establishing a strong baseline for future research.Furthermore, this work provides insights into the role and utility of textualmetadata in AD through experiments and analysis. Results show that semanticcontext improves detection performance and enhances interpretability bysupporting domain-aware reasoning. These findings establish ReTabAD as abenchmark for systematic exploration of context-aware AD.
Link: http://arxiv.org/abs/2510.02060v1
Updated: 2025-10-02T14:28:45Z

88: KAIROS: Unified Training for Universal Non-Autoregressive Time Series  Forecasting
Authors: ['Kuiye Ding', 'Fanda Fan', 'Zheya Wang', 'Hongxiao Li', 'Yifan Wang', 'Lei Wang', 'Chunjie Luo', 'Jianfeng Zhan']
Summary: In the World Wide Web, reliable time series forecasts provide theforward-looking signals that drive resource planning, cache placement, andanomaly response, enabling platforms to operate efficiently as user behaviorand content distributions evolve. Compared with other domains, time seriesforecasting for Web applications requires much faster responsiveness to supportreal-time decision making. We present KAIROS, a non-autoregressive time seriesforecasting framework that directly models segment-level multi-peakdistributions. Unlike autoregressive approaches, KAIROS avoids erroraccumulation and achieves just-in-time inference, while improving over existingnon-autoregressive models that collapse to over-smoothed predictions. Trainedon the large-scale corpus, KAIROS demonstrates strong zero-shot generalizationon six widely used benchmarks, delivering forecasting performance comparable tostate-of-the-art foundation models with similar scale, at a fraction of theirinference cost. Beyond empirical results, KAIROS highlights the importance ofnon-autoregressive design as a scalable paradigm for foundation models in timeseries.
Link: http://arxiv.org/abs/2510.02084v1
Updated: 2025-10-02T14:50:50Z

89: Demystifying the Roles of LLM Layers in Retrieval, Knowledge, and  Reasoning
Authors: ['Xinyuan Song', 'Keyu Wang', 'PengXiang Li', 'Lu Yin', 'Shiwei Liu']
Summary: Recent studies suggest that the deeper layers of Large Language Models (LLMs)contribute little to representation learning and can often be removed withoutsignificant performance loss. However, such claims are typically drawn fromnarrow evaluations and may overlook important aspects of model behavior. Inthis work, we present a systematic study of depth utilization across diversedimensions, including evaluation protocols, task categories, and modelarchitectures. Our analysis confirms that very deep layers are generally lesseffective than earlier ones, but their contributions vary substantially withthe evaluation setting. Under likelihood-based metrics without generation,pruning most layers preserves performance, with only the initial few beingcritical. By contrast, generation-based evaluation uncovers indispensable rolesfor middle and deeper layers in enabling reasoning and maintaining long-rangecoherence. We further find that knowledge and retrieval are concentrated inshallow components, whereas reasoning accuracy relies heavily on deeper layers-- yet can be reshaped through distillation. These results highlight that depthusage in LLMs is highly heterogeneous and context-dependent, underscoring theneed for task-, metric-, and model-aware perspectives in both interpreting andcompressing large models.
Link: http://arxiv.org/abs/2510.02091v1
Updated: 2025-10-02T14:57:13Z

90: When Tracking Fails: Analyzing Failure Modes of SAM2 for Point-Based  Tracking in Surgical Videos
Authors: ['Woowon Jang', 'Jiwon Im', 'Juseung Choi', 'Niki Rashidian', 'Wesley De Neve', 'Utku Ozbulak']
Summary: Video object segmentation (VOS) models such as SAM2 offer promising zero-shottracking capabilities for surgical videos using minimal user input. Among theavailable input types, point-based tracking offers an efficient and low-costalternative, yet its reliability and failure cases in complex surgicalenvironments are not well understood. In this work, we systematically analyzethe failure modes of point-based tracking in laparoscopic cholecystectomyvideos. Focusing on three surgical targets, the gallbladder, grasper, andL-hook electrocautery, we compare the performance of point-based tracking withsegmentation mask initialization. Our results show that point-based tracking iscompetitive for surgical tools but consistently underperforms for anatomicaltargets, where tissue similarity and ambiguous boundaries lead to failure.Through qualitative analysis, we reveal key factors influencing trackingoutcomes and provide several actionable recommendations for selecting andplacing tracking points to improve performance in surgical video analysis.
Link: http://arxiv.org/abs/2510.02100v1
Updated: 2025-10-02T15:06:49Z

91: Unlocking Symbol-Level Precoding Efficiency Through Tensor Equivariant  Neural Network
Authors: ['Jinshuo Zhang', 'Yafei Wang', 'Xinping Yi', 'Wenjin Wang', 'Shi Jin', 'Symeon Chatzinotas', 'Björn Ottersten']
Summary: Although symbol-level precoding (SLP) based on constructive interference (CI)exploitation offers performance gains, its high complexity remains abottleneck. This paper addresses this challenge with an end-to-end deeplearning (DL) framework with low inference complexity that leverages thestructure of the optimal SLP solution in the closed-form and its inherenttensor equivariance (TE), where TE denotes that a permutation of the inputinduces the corresponding permutation of the output. Building upon thecomputationally efficient model-based formulations, as well as their knownclosed-form solutions, we analyze their relationship with linear precoding (LP)and investigate the corresponding optimality condition. We then construct amapping from the problem formulation to the solution and prove its TE, based onwhich the designed networks reveal a specific parameter-sharing pattern thatdelivers low computational complexity and strong generalization. Leveragingthese, we propose the backbone of the framework with an attention-based TEmodule, achieving linear computational complexity. Furthermore, we demonstratethat such a framework is also applicable to imperfect CSI scenarios, where wedesign a TE-based network to map the CSI, statistics, and symbols to auxiliaryvariables. Simulation results show that the proposed framework capturessubstantial performance gains of optimal SLP, while achieving an approximately80-times speedup over conventional methods and maintaining stronggeneralization across user numbers and symbol block lengths.
Link: http://arxiv.org/abs/2510.02108v1
Updated: 2025-10-02T15:15:50Z

92: SpurBreast: A Curated Dataset for Investigating Spurious Correlations in  Real-world Breast MRI Classification
Authors: ['Jong Bum Won', 'Wesley De Neve', 'Joris Vankerschaver', 'Utku Ozbulak']
Summary: Deep neural networks (DNNs) have demonstrated remarkable success in medicalimaging, yet their real-world deployment remains challenging due to spuriouscorrelations, where models can learn non-clinical features instead ofmeaningful medical patterns. Existing medical imaging datasets are not designedto systematically study this issue, largely due to restrictive licensing andlimited supplementary patient data. To address this gap, we introduceSpurBreast, a curated breast MRI dataset that intentionally incorporatesspurious correlations to evaluate their impact on model performance. Analyzingover 100 features involving patient, device, and imaging protocol, we identifytwo dominant spurious signals: magnetic field strength (a global featureinfluencing the entire image) and image orientation (a local feature affectingspatial alignment). Through controlled dataset splits, we demonstrate that DNNscan exploit these non-clinical signals, achieving high validation accuracywhile failing to generalize to unbiased test data. Alongside these two datasetscontaining spurious correlations, we also provide benchmark datasets withoutspurious correlations, allowing researchers to systematically investigateclinically relevant and irrelevant features, uncertainty estimation,adversarial robustness, and generalization strategies. Models and datasets areavailable at https://github.com/utkuozbulak/spurbreast.
Link: http://arxiv.org/abs/2510.02109v1
Updated: 2025-10-02T15:16:20Z

93: VarCoNet: A variability-aware self-supervised framework for functional  connectome extraction from resting-state fMRI
Authors: ['Charalampos Lamprou', 'Aamna Alshehhi', 'Leontios J. Hadjileontiadis', 'Mohamed L. Seghier']
Summary: Accounting for inter-individual variability in brain function is key toprecision medicine. Here, by considering functional inter-individualvariability as meaningful data rather than noise, we introduce VarCoNet, anenhanced self-supervised framework for robust functional connectome (FC)extraction from resting-state fMRI (rs-fMRI) data. VarCoNet employsself-supervised contrastive learning to exploit inherent functionalinter-individual variability, serving as a brain function encoder thatgenerates FC embeddings readily applicable to downstream tasks even in theabsence of labeled data. Contrastive learning is facilitated by a novelaugmentation strategy based on segmenting rs-fMRI signals. At its core,VarCoNet integrates a 1D-CNN-Transformer encoder for advanced time-seriesprocessing, enhanced with a robust Bayesian hyperparameter optimization. OurVarCoNet framework is evaluated on two downstream tasks: (i) subjectfingerprinting, using rs-fMRI data from the Human Connectome Project, and (ii)autism spectrum disorder (ASD) classification, using rs-fMRI data from theABIDE I and ABIDE II datasets. Using different brain parcellations, ourextensive testing against state-of-the-art methods, including 13 deep learningmethods, demonstrates VarCoNet's superiority, robustness, interpretability, andgeneralizability. Overall, VarCoNet provides a versatile and robust frameworkfor FC analysis in rs-fMRI.
Link: http://arxiv.org/abs/2510.02120v1
Updated: 2025-10-02T15:29:17Z

94: Do AI Models Perform Human-like Abstract Reasoning Across Modalities?
Authors: ['Claas Beger', 'Ryan Yi', 'Shuhao Fu', 'Arseny Moskvichev', 'Sarah W. Tsai', 'Sivasankaran Rajamanickam', 'Melanie Mitchell']
Summary: OpenAI's o3-preview reasoning model exceeded human accuracy on the ARC-AGIbenchmark, but does that mean state-of-the-art models recognize and reason withthe abstractions that the task creators intended? We investigate models'abstraction abilities on ConceptARC. We evaluate models under settings thatvary the input modality (textual vs. visual), whether the model is permitted touse external Python tools, and, for reasoning models, the amount of reasoningeffort. In addition to measuring output accuracy, we perform fine-grainedevaluation of the natural-language rules that models generate to explain theirsolutions. This dual evaluation lets us assess whether models solve tasks usingthe abstractions ConceptARC was designed to elicit, rather than relying onsurface-level patterns. Our results show that, while some models usingtext-based representations match human output accuracy, the best models' rulesare often based on surface-level ``shortcuts'' and capture intendedabstractions far less often than humans. Thus their capabilities for generalabstract reasoning may be overestimated by evaluations based on accuracy alone.In the visual modality, AI models' output accuracy drops sharply, yet ourrule-level analysis reveals that models might be underestimated, as they stillexhibit a substantial share of rules that capture intended abstractions, butare often unable to correctly apply these rules. In short, our results showthat models still lag humans in abstract reasoning, and that using accuracyalone to evaluate abstract reasoning on ARC-like tasks may overestimateabstract-reasoning capabilities in textual modalities and underestimate it invisual modalities. We believe that our evaluation framework offers a morefaithful picture of multimodal models' abstract reasoning abilities and a moreprincipled way to track progress toward human-like, abstraction-centeredintelligence.
Link: http://arxiv.org/abs/2510.02125v1
Updated: 2025-10-02T15:35:10Z

95: The Disparate Impacts of Speculative Decoding
Authors: ['Jameson Sandler', 'Ahmet Üstün', 'Marco Romanelli', 'Sara Hooker', 'Ferdinando Fioretto']
Summary: The practice of speculative decoding, whereby inference is probabilisticallysupported by a smaller, cheaper, ``drafter'' model, has become a standardtechnique for systematically reducing the decoding time of large languagemodels. This paper conducts an analysis of speculative decoding through thelens of its potential disparate speed-up rates across tasks. Crucially, thepaper shows that speed-up gained from speculative decoding is not uniformlydistributed across tasks, consistently diminishing for under-fit, and oftenunderrepresented tasks. To better understand this phenomenon, we derive ananalysis to quantify this observed ``unfairness'' and draw attention to thefactors that motivate such disparate speed-ups to emerge. Further, guided bythese insights, the paper proposes a mitigation strategy designed to reducespeed-up disparities and validates the approach across several model pairs,revealing on average a 12% improvement in our fairness metric.
Link: http://arxiv.org/abs/2510.02128v1
Updated: 2025-10-02T15:38:57Z

96: FlexDoc: Parameterized Sampling for Diverse Multilingual Synthetic  Documents for Training Document Understanding Models
Authors: ['Karan Dua', 'Hitesh Laxmichand Patel', 'Puneet Mittal', 'Ranjeet Gupta', 'Amit Agarwal', 'Praneet Pabolu', 'Srikant Panda', 'Hansa Meghwani', 'Graham Horwood', 'Fahad Shah']
Summary: Developing document understanding models at enterprise scale requires large,diverse, and well-annotated datasets spanning a wide range of document types.However, collecting such data is prohibitively expensive due to privacyconstraints, legal restrictions, and the sheer volume of manual annotationneeded - costs that can scale into millions of dollars. We introduce FlexDoc, ascalable synthetic data generation framework that combines Stochastic Schemasand Parameterized Sampling to produce realistic, multilingual semi-structureddocuments with rich annotations. By probabilistically modeling layout patterns,visual structure, and content variability, FlexDoc enables the controlledgeneration of diverse document variants at scale. Experiments on KeyInformation Extraction (KIE) tasks demonstrate that FlexDoc-generated dataimproves the absolute F1 Score by up to 11% when used to augment real datasets,while reducing annotation effort by over 90% compared to traditionalhard-template methods. The solution is in active deployment, where it hasaccelerated the development of enterprise-grade document understanding modelswhile significantly reducing data acquisition and annotation costs.
Link: http://arxiv.org/abs/2510.02133v1
Updated: 2025-10-02T15:42:35Z

97: BioinfoMCP: A Unified Platform Enabling MCP Interfaces in Agentic  Bioinformatics
Authors: ['Florensia Widjaja', 'Zhangtianyi Chen', 'Juexiao Zhou']
Summary: Bioinformatics tools are essential for complex computational biology tasks,yet their integration with emerging AI-agent frameworks is hindered byincompatible interfaces, heterogeneous input-output formats, and inconsistentparameter conventions. The Model Context Protocol (MCP) provides a standardizedframework for tool-AI communication, but manually converting hundreds ofexisting and rapidly growing specialized bioinformatics tools intoMCP-compliant servers is labor-intensive and unsustainable. Here, we presentBioinfoMCP, a unified platform comprising two components: BioinfoMCP Converter,which automatically generates robust MCP servers from tool documentation usinglarge language models, and BioinfoMCP Benchmark, which systematically validatesthe reliability and versatility of converted tools across diverse computationaltasks. We present a platform of 38 MCP-converted bioinformatics tools,extensively validated to show that 94.7% successfully executed complexworkflows across three widely used AI-agent platforms. By removing technicalbarriers to AI automation, BioinfoMCP enables natural-language interaction withsophisticated bioinformatics analyses without requiring extensive programmingexpertise, offering a scalable path to intelligent, interoperable computationalbiology.
Link: http://arxiv.org/abs/2510.02139v1
Updated: 2025-10-02T15:47:59Z

98: How to Find Fantastic Papers: Self-Rankings as a Powerful Predictor of  Scientific Impact Beyond Peer Review
Authors: ['Buxin Su', 'Natalie Collina', 'Garrett Wen', 'Didong Li', 'Kyunghyun Cho', 'Jianqing Fan', 'Bingxin Zhao', 'Weijie Su']
Summary: Peer review in academic research aims not only to ensure factual correctnessbut also to identify work of high scientific potential that can shape futureresearch directions. This task is especially critical in fast-moving fieldssuch as artificial intelligence (AI), yet it has become increasingly difficultgiven the rapid growth of submissions. In this paper, we investigate anunderexplored measure for identifying high-impact research: authors' ownrankings of their multiple submissions to the same AI conference. Grounded ingame-theoretic reasoning, we hypothesize that self-rankings are informativebecause authors possess unique understanding of their work's conceptual depthand long-term promise. To test this hypothesis, we conducted a large-scaleexperiment at a leading AI conference, where 1,342 researchers self-rankedtheir 2,592 submissions by perceived quality. Tracking outcomes over more thana year, we found that papers ranked highest by their authors received twice asmany citations as their lowest-ranked counterparts; self-rankings wereespecially effective at identifying highly cited papers (those with over 150citations). Moreover, we showed that self-rankings outperformed peer reviewscores in predicting future citation counts. Our results remained robust afteraccounting for confounders such as preprint posting time and self-citations.Together, these findings demonstrate that authors' self-rankings provide areliable and valuable complement to peer review for identifying and elevatinghigh-impact research in AI.
Link: http://arxiv.org/abs/2510.02143v1
Updated: 2025-10-02T15:50:21Z

99: Human-Robo-advisor collaboration in decision-making: Evidence from a  multiphase mixed methods experimental study
Authors: ['Hasan Mahmud', 'Najmul Islam', 'Satish Krishnan']
Summary: Robo-advisors (RAs) are cost-effective, bias-resistant alternatives to humanfinancial advisors, yet adoption remains limited. While prior research hasexamined user interactions with RAs, less is known about how individualsinterpret RA roles and integrate their advice into decision-making. To addressthis gap, this study employs a multiphase mixed methods design integrating abehavioral experiment (N = 334), thematic analysis, and follow-up quantitativetesting. Findings suggest that people tend to rely on RAs, with reliance shapedby information about RA performance and the framing of advice as gains orlosses. Thematic analysis reveals three RA roles in decision-making and fouruser types, each reflecting distinct patterns of advice integration. Inaddition, a 2 x 2 typology categorizes antecedents of acceptance into enablersand inhibitors at both the individual and algorithmic levels. By combiningbehavioral, interpretive, and confirmatory evidence, this study advancesunderstanding of human-RA collaboration and provides actionable insights fordesigning more trustworthy and adaptive RA systems.
Link: http://dx.doi.org/10.1016/j.dss.2025.114541
Updated: 2025-10-02T16:04:31Z

100: Unlocking Vision-Language Models for Video Anomaly Detection via  Fine-Grained Prompting
Authors: ['Shu Zou', 'Xinyu Tian', 'Lukas Wesemann', 'Fabian Waschkowski', 'Zhaoyuan Yang', 'Jing Zhang']
Summary: Prompting has emerged as a practical way to adapt frozen vision-languagemodels (VLMs) for video anomaly detection (VAD). Yet, existing prompts areoften overly abstract, overlooking the fine-grained human-object interactionsor action semantics that define complex anomalies in surveillance videos. Wepropose ASK-Hint, a structured prompting framework that leveragesaction-centric knowledge to elicit more accurate and interpretable reasoningfrom frozen VLMs. Our approach organizes prompts into semantically coherentgroups (e.g. violence, property crimes, public safety) and formulatesfine-grained guiding questions that align model predictions with discriminativevisual cues. Extensive experiments on UCF-Crime and XD-Violence show thatASK-Hint consistently improves AUC over prior baselines, achievingstate-of-the-art performance compared to both fine-tuned and training-freemethods. Beyond accuracy, our framework provides interpretable reasoning tracestowards anomaly and demonstrates strong generalization across datasets and VLMbackbones. These results highlight the critical role of prompt granularity andestablish ASK-Hint as a new training-free and generalizable solution forexplainable video anomaly detection.
Link: http://arxiv.org/abs/2510.02155v1
Updated: 2025-10-02T16:06:31Z

101: Comparing Contrastive and Triplet Loss in Audio-Visual Embedding:  Intra-Class Variance and Greediness Analysis
Authors: ['Donghuo Zeng']
Summary: Contrastive loss and triplet loss are widely used objectives in deep metriclearning, yet their effects on representation quality remain insufficientlyunderstood. We present a theoretical and empirical comparison of these losses,focusing on intra- and inter-class variance and optimization behavior (e.g.,greedy updates). Through task-specific experiments with consistent settings onsynthetic data and real datasets-MNIST, CIFAR-10-it is shown that triplet losspreserves greater variance within and across classes, supporting finer-graineddistinctions in the learned representations. In contrast, contrastive losstends to compact intra-class embeddings, which may obscure subtle semanticdifferences. To better understand their optimization dynamics, By examiningloss-decay rate, active ratio, and gradient norm, we find that contrastive lossdrives many small updates early on, while triplet loss produces fewer butstronger updates that sustain learning on hard examples. Finally, across bothclassification and retrieval tasks on MNIST, CIFAR-10, CUB-200, and CARS196datasets, our results consistently show that triplet loss yields superiorperformance, which suggests using triplet loss for detail retention andhard-sample focus, and contrastive loss for smoother, broad-based embeddingrefinement.
Link: http://arxiv.org/abs/2510.02161v1
Updated: 2025-10-02T16:11:46Z

102: SIEVE: Towards Verifiable Certification for Code-datasets
Authors: ['Fatou Ndiaye Mbodji', 'El-hacen Diallo', 'Jordan Samhi', 'Kui Liu', 'Jacques Klein', 'Tegawendé F. Bissyande']
Summary: Code agents and empirical software engineering rely on public code datasets,yet these datasets lack verifiable quality guarantees. Static 'dataset cards'inform, but they are neither auditable nor do they offer statisticalguarantees, making it difficult to attest to dataset quality. Teams buildisolated, ad-hoc cleaning pipelines. This fragments effort and raises cost. Wepresent SIEVE, a community-driven framework. It turns per-property checks intoConfidence Cards-machine-readable, verifiable certificates with anytime-validstatistical bounds. We outline a research plan to bring SIEVE to maturity,replacing narrative cards with anytime-verifiable certification. This shift isexpected to lower quality-assurance costs and increase trust in code-datasets.
Link: http://arxiv.org/abs/2510.02166v1
Updated: 2025-10-02T16:14:23Z

103: Go witheFlow: Real-time Emotion Driven Audio Effects Modulation
Authors: ['Edmund Dervakos', 'Spyridon Kantarelis', 'Vassilis Lyberatos', 'Jason Liartis', 'Giorgos Stamou']
Summary: Music performance is a distinctly human activity, intrinsically linked to theperformer's ability to convey, evoke, or express emotion. Machines cannotperform music in the human sense; they can produce, reproduce, execute, orsynthesize music, but they lack the capacity for affective or emotionalexperience. As such, music performance is an ideal candidate through which toexplore aspects of collaboration between humans and machines. In this paper, weintroduce the witheFlow system, designed to enhance real-time music performanceby automatically modulating audio effects based on features extracted from bothbiosignals and the audio itself. The system, currently in a proof-of-conceptphase, is designed to be lightweight, able to run locally on a laptop, and isopen-source given the availability of a compatible Digital Audio Workstationand sensors.
Link: http://arxiv.org/abs/2510.02171v1
Updated: 2025-10-02T16:23:47Z

104: Learning to Reason for Hallucination Span Detection
Authors: ['Hsuan Su', 'Ting-Yao Hu', 'Hema Swetha Koppula', 'Kundan Krishna', 'Hadi Pouransari', 'Cheng-Yu Hsieh', 'Cem Koc', 'Joseph Yitan Cheng', 'Oncel Tuzel', 'Raviteja Vemulapalli']
Summary: Large language models (LLMs) often generate hallucinations -- unsupportedcontent that undermines reliability. While most prior works frame hallucinationdetection as a binary task, many real-world applications require identifyinghallucinated spans, which is a multi-step decision making process. Thisnaturally raises the question of whether explicit reasoning can help thecomplex task of detecting hallucination spans. To answer this question, wefirst evaluate pretrained models with and without Chain-of-Thought (CoT)reasoning, and show that CoT reasoning has the potential to generate at leastone correct answer when sampled multiple times. Motivated by this, we proposeRL4HS, a reinforcement learning framework that incentivizes reasoning with aspan-level reward function. RL4HS builds on Group Relative Policy Optimizationand introduces Class-Aware Policy Optimization to mitigate reward imbalanceissue. Experiments on the RAGTruth benchmark (summarization, questionanswering, data-to-text) show that RL4HS surpasses pretrained reasoning modelsand supervised fine-tuning, demonstrating the necessity of reinforcementlearning with span-level rewards for detecting hallucination spans.
Link: http://arxiv.org/abs/2510.02173v1
Updated: 2025-10-02T16:24:28Z

105: GRACE: A Language Model Framework for Explainable Inverse Reinforcement  Learning
Authors: ['Silvia Sapora', 'Devon Hjelm', 'Alexander Toshev', 'Omar Attia', 'Bogdan Mazoure']
Summary: Inverse Reinforcement Learning aims to recover reward models from expertdemonstrations, but traditional methods yield "black-box" models that aredifficult to interpret and debug. In this work, we introduce GRACE (GeneratingRewards As CodE), a method for using Large Language Models within anevolutionary search to reverse-engineer an interpretable, code-based rewardfunction directly from expert trajectories. The resulting reward function isexecutable code that can be inspected and verified. We empirically validateGRACE on the BabyAI and AndroidWorld benchmarks, where it efficiently learnshighly accurate rewards, even in complex, multi-task settings. Further, wedemonstrate that the resulting reward leads to strong policies, compared toboth competitive Imitation Learning and online RL approaches with ground-truthrewards. Finally, we show that GRACE is able to build complex reward APIs inmulti-task setups.
Link: http://arxiv.org/abs/2510.02180v1
Updated: 2025-10-02T16:31:39Z

106: EvolveCaptions: Empowering DHH Users Through Real-Time Collaborative  Captioning
Authors: ['Liang-Yuan Wu', 'Dhruv Jain']
Summary: Automatic Speech Recognition (ASR) systems often fail to accuratelytranscribe speech from Deaf and Hard of Hearing (DHH) individuals, especiallyduring real-time conversations. Existing personalization approaches typicallyrequire extensive pre-recorded data and place the burden of adaptation on theDHH speaker. We present EvolveCaptions, a real-time, collaborative ASRadaptation system that supports in-situ personalization with minimal effort.Hearing participants correct ASR errors during live conversations. Based onthese corrections, the system generates short, phonetically targeted promptsfor the DHH speaker to record, which are then used to fine-tune the ASR model.In a study with 12 DHH and six hearing participants, EvolveCaptions reducedWord Error Rate (WER) across all DHH users within one hour of use, using onlyfive minutes of recording time on average. Participants described the system asintuitive, low-effort, and well-integrated into communication. These findingsdemonstrate the promise of collaborative, real-time ASR adaptation for moreequitable communication.
Link: http://arxiv.org/abs/2510.02181v1
Updated: 2025-10-02T16:32:29Z

107: A Rigorous Benchmark with Multidimensional Evaluation for Deep Research  Agents: From Answers to Reports
Authors: ['Yang Yao', 'Yixu Wang', 'Yuxuan Zhang', 'Yi Lu', 'Tianle Gu', 'Lingyu Li', 'Dingyi Zhao', 'Keming Wu', 'Haozhe Wang', 'Ping Nie', 'Yan Teng', 'Yingchun Wang']
Summary: Artificial intelligence is undergoing the paradigm shift from closed languagemodels to interconnected agent systems capable of external perception andinformation integration. As a representative embodiment, Deep Research Agents(DRAs) systematically exhibit the capabilities for task decomposition,cross-source retrieval, multi-stage reasoning, and structured output, whichmarkedly enhance performance on complex and open-ended tasks. However, existingbenchmarks remain deficient in evaluation dimensions, response formatting, andscoring mechanisms, limiting their capacity to assess such systems effectively.This paper introduces a rigorous benchmark and a multidimensional evaluationframework tailored to DRAs and report-style responses. The benchmark comprises214 expert-curated challenging queries distributed across 10 broad thematicdomains, each accompanied by manually constructed reference bundles to supportcomposite evaluation. The framework enables comprehensive evaluation oflong-form reports generated by DRAs, incorporating integrated scoring metricsfor semantic quality, topical focus, and retrieval trustworthiness. Extensiveexperimentation confirms the superior performance of mainstream DRAs overweb-search-tool-augmented reasoning models, yet reveals considerable scope forfurther improvement. This study provides a robust foundation for capabilityassessment, architectural refinement, and paradigm advancement in DRA systems.
Link: http://arxiv.org/abs/2510.02190v1
Updated: 2025-10-02T16:40:02Z

108: UpSafe$^\circ$C: Upcycling for Controllable Safety in Large Language  Models
Authors: ['Yuhao Sun', 'Zhuoer Xu', 'Shiwen Cui', 'Kun Yang', 'Lingyun Yu', 'Yongdong Zhang', 'Hongtao Xie']
Summary: Large Language Models (LLMs) have achieved remarkable progress across a widerange of tasks, but remain vulnerable to safety risks such as harmful contentgeneration and jailbreak attacks. Existing safety techniques -- includingexternal guardrails, inference-time guidance, and post-training alignment --each face limitations in balancing safety, utility, and controllability. Inthis work, we propose UpSafe$^\circ$C, a unified framework for enhancing LLMsafety through safety-aware upcycling. Our approach first identifiessafety-critical layers and upcycles them into a sparse Mixture-of-Experts (MoE)structure, where the router acts as a soft guardrail that selectively activatesoriginal MLPs and added safety experts. We further introduce a two-stage SFTstrategy to strengthen safety discrimination while preserving generalcapabilities. To enable flexible control at inference time, we introduce asafety temperature mechanism, allowing dynamic adjustment of the trade-offbetween safety and utility. Experiments across multiple benchmarks, base model,and model scales demonstrate that UpSafe$^\circ$C achieves robust safetyimprovements against harmful and jailbreak inputs, while maintainingcompetitive performance on general tasks. Moreover, analysis shows that safetytemperature provides fine-grained inference-time control that achieves thePareto-optimal frontier between utility and safety. Our results highlight a newdirection for LLM safety: moving from static alignment toward dynamic, modular,and inference-aware control.
Link: http://arxiv.org/abs/2510.02194v1
Updated: 2025-10-02T16:43:33Z

109: ARUQULA -- An LLM based Text2SPARQL Approach using ReAct and Knowledge  Graph Exploration Utilities
Authors: ['Felix Brei', 'Lorenz Bühmann', 'Johannes Frey', 'Daniel Gerber', 'Lars-Peter Meyer', 'Claus Stadler', 'Kirill Bulert']
Summary: Interacting with knowledge graphs can be a daunting task for people without abackground in computer science since the query language that is used (SPARQL)has a high barrier of entry. Large language models (LLMs) can lower thatbarrier by providing support in the form of Text2SPARQL translation. In thispaper we introduce a generalized method based on SPINACH, an LLM backed agentthat translates natural language questions to SPARQL queries not in a singleshot, but as an iterative process of exploration and execution. We describe theoverall architecture and reasoning behind our design decisions, and alsoconduct a thorough analysis of the agent behavior to gain insights into futureareas for targeted improvements. This work was motivated by the Text2SPARQLchallenge, a challenge that was held to facilitate improvements in theText2SPARQL domain.
Link: http://arxiv.org/abs/2510.02200v1
Updated: 2025-10-02T16:49:27Z

110: Detection of Chagas Disease from the ECG: The George B. Moody PhysioNet  Challenge 2025
Authors: ['Matthew A. Reyna', 'Zuzana Koscova', 'Jan Pavlus', 'Soheil Saghafi', 'James Weigle', 'Andoni Elola', 'Salman Seyedi', 'Kiersten Campbell', 'Qiao Li', 'Ali Bahrami Rad', 'Antônio H. Ribeiro', 'Antonio Luiz P. Ribeiro', 'Reza Sameni', 'Gari D. Clifford']
Summary: Objective: Chagas disease is a parasitic infection that is endemic to SouthAmerica, Central America, and, more recently, the U.S., primarily transmittedby insects. Chronic Chagas disease can cause cardiovascular diseases anddigestive problems. Serological testing capacities for Chagas disease arelimited, but Chagas cardiomyopathy often manifests in ECGs, providing anopportunity to prioritize patients for testing and treatment. Approach: TheGeorge B. Moody PhysioNet Challenge 2025 invites teams to develop algorithmicapproaches for identifying Chagas disease from electrocardiograms (ECGs). Mainresults: This Challenge provides multiple innovations. First, we leveragedseveral datasets with labels from patient reports and serological testing,provided a large dataset with weak labels and smaller datasets with stronglabels. Second, we augmented the data to support model robustness andgeneralizability to unseen data sources. Third, we applied an evaluation metricthat captured the local serological testing capacity for Chagas disease toframe the machine learning problem as a triage task. Significance: Over 630participants from 111 teams submitted over 1300 entries during the Challenge,representing diverse approaches from academia and industry worldwide.
Link: http://arxiv.org/abs/2510.02202v1
Updated: 2025-10-02T16:50:36Z

111: DiFFPO: Training Diffusion LLMs to Reason Fast and Furious via  Reinforcement Learning
Authors: ['Hanyang Zhao', 'Dawen Liang', 'Wenpin Tang', 'David Yao', 'Nathan Kallus']
Summary: We propose DiFFPO, Diffusion Fast and Furious Policy Optimization, a unifiedframework for training masked diffusion large language models (dLLMs) to reasonnot only better (furious), but also faster via reinforcement learning (RL). Wefirst unify the existing baseline approach such as d1 by proposing to trainsurrogate policies via off-policy RL, whose likelihood is much more tractableas an approximation to the true dLLM policy. This naturally motivates a moreaccurate and informative two-stage likelihood approximation combined withimportance sampling correction, which leads to generalized RL algorithms withbetter sample efficiency and superior task performance. Second, we propose anew direction of joint training efficient samplers/controllers of dLLMs policy.Via RL, we incentivize dLLMs' natural multi-token prediction capabilities byletting the model learn to adaptively allocate an inference threshold for eachprompt. By jointly training the sampler, we yield better accuracies with lowernumber of function evaluations (NFEs) compared to training the model only,obtaining the best performance in improving the Pareto frontier of theinference-time compute of dLLMs. We showcase the effectiveness of our pipelineby training open source large diffusion language models over benchmark math andplanning tasks.
Link: http://arxiv.org/abs/2510.02212v1
Updated: 2025-10-02T16:57:24Z

112: TempoControl: Temporal Attention Guidance for Text-to-Video Models
Authors: ['Shira Schiber', 'Ofir Lindenbaum', 'Idan Schwartz']
Summary: Recent advances in generative video models have enabled the creation ofhigh-quality videos based on natural language prompts. However, these modelsfrequently lack fine-grained temporal control, meaning they do not allow usersto specify when particular visual elements should appear within a generatedsequence. In this work, we introduce TempoControl, a method that allows fortemporal alignment of visual concepts during inference, without requiringretraining or additional supervision. TempoControl utilizes cross-attentionmaps, a key component of text-to-video diffusion models, to guide the timing ofconcepts through a novel optimization approach. Our method steers attentionusing three complementary principles: aligning its temporal shape with acontrol signal (via correlation), amplifying it where visibility is needed (viaenergy), and maintaining spatial focus (via entropy). TempoControl allowsprecise control over timing while ensuring high video quality and diversity. Wedemonstrate its effectiveness across various video generation applications,including temporal reordering for single and multiple objects, as well asaction and audio-aligned generation.
Link: http://arxiv.org/abs/2510.02226v1
Updated: 2025-10-02T17:13:35Z

113: More Than One Teacher: Adaptive Multi-Guidance Policy Optimization for  Diverse Exploration
Authors: ['Xiaoyang Yuan', 'Yujuan Ding', 'Yi Bin', 'Wenqi Shao', 'Jinyu Cai', 'Jingkuan Song', 'Yang Yang', 'Hengtao Shen']
Summary: Reinforcement Learning with Verifiable Rewards (RLVR) is a promising paradigmfor enhancing the reasoning ability in Large Language Models (LLMs). However,prevailing methods primarily rely on self-exploration or a single off-policyteacher to elicit long chain-of-thought (LongCoT) reasoning, which mayintroduce intrinsic model biases and restrict exploration, ultimately limitingreasoning diversity and performance. Drawing inspiration from multi-teacherstrategies in knowledge distillation, we introduce Adaptive Multi-GuidancePolicy Optimization (AMPO), a novel framework that adaptively leveragesguidance from multiple proficient teacher models, but only when the on-policymodel fails to generate correct solutions. This "guidance-on-demand" approachexpands exploration while preserving the value of self-discovery. Moreover,AMPO incorporates a comprehension-based selection mechanism, prompting thestudent to learn from the reasoning paths that it is most likely to comprehend,thus balancing broad exploration with effective exploitation. Extensiveexperiments show AMPO substantially outperforms a strong baseline (GRPO), witha 4.3% improvement on mathematical reasoning tasks and 12.2% onout-of-distribution tasks, while significantly boosting Pass@k performance andenabling more diverse exploration. Notably, using four peer-sized teachers, ourmethod achieves comparable results to approaches that leverage a single, morepowerful teacher (e.g., DeepSeek-R1) with more data. These results demonstratea more efficient and scalable path to superior reasoning and generalizability.Our code is available at https://github.com/SII-Enigma/AMPO.
Link: http://arxiv.org/abs/2510.02227v1
Updated: 2025-10-02T17:14:00Z

114: The Reasoning Boundary Paradox: How Reinforcement Learning Constrains  Language Models
Authors: ['Phuc Minh Nguyen', 'Chinh D. La', 'Duy M. H. Nguyen', 'Nitesh V. Chawla', 'Binh T. Nguyen', 'Khoa D. Doan']
Summary: Reinforcement Learning with Verifiable Rewards (RLVR) has emerged as a keymethod for improving Large Language Models' reasoning capabilities, yet recentevidence suggests it may paradoxically shrink the reasoning boundary ratherthan expand it. This paper investigates the shrinkage issue of RLVR byanalyzing its learning dynamics and reveals two critical phenomena that explainthis failure. First, we expose negative interference in RLVR, where learning tosolve certain training problems actively reduces the likelihood of correctsolutions for others, leading to the decline of Pass@$k$ performance, or theprobability of generating a correct solution within $k$ attempts. Second, weuncover the winner-take-all phenomenon: RLVR disproportionately reinforcesproblems with high likelihood, correct solutions, under the base model, whilesuppressing other initially low-likelihood ones. Through extensive theoreticaland empirical analysis on multiple mathematical reasoning benchmarks, we showthat this effect arises from the inherent on-policy sampling in standard RLobjectives, causing the model to converge toward narrow solution strategies.Based on these insights, we propose a simple yet effective data curationalgorithm that focuses RLVR learning on low-likelihood problems, achievingnotable improvement in Pass@$k$ performance. Our code is available athttps://github.com/mail-research/SELF-llm-interference.
Link: http://arxiv.org/abs/2510.02230v1
Updated: 2025-10-02T17:17:27Z

115: RewardMap: Tackling Sparse Rewards in Fine-grained Visual Reasoning via  Multi-Stage Reinforcement Learning
Authors: ['Sicheng Feng', 'Kaiwen Tuo', 'Song Wang', 'Lingdong Kong', 'Jianke Zhu', 'Huan Wang']
Summary: Fine-grained visual reasoning remains a core challenge for multimodal largelanguage models (MLLMs). The recently introduced ReasonMap highlights this gapby showing that even advanced MLLMs struggle with spatial reasoning instructured and information-rich settings such as transit maps, a task of clearpractical and scientific importance. However, standard reinforcement learning(RL) on such tasks is impeded by sparse rewards and unstable optimization. Toaddress this, we first construct ReasonMap-Plus, an extended dataset thatintroduces dense reward signals through Visual Question Answering (VQA) tasks,enabling effective cold-start training of fine-grained visual understandingskills. Next, we propose RewardMap, a multi-stage RL framework designed toimprove both visual understanding and reasoning capabilities of MLLMs.RewardMap incorporates two key designs. First, we introduce a difficulty-awarereward design that incorporates detail rewards, directly tackling the sparserewards while providing richer supervision. Second, we propose a multi-stage RLscheme that bootstraps training from simple perception to complex reasoningtasks, offering a more effective cold-start strategy than conventionalSupervised Fine-Tuning (SFT). Experiments on ReasonMap and ReasonMap-Plusdemonstrate that each component of RewardMap contributes to consistentperformance gains, while their combination yields the best results. Moreover,models trained with RewardMap achieve an average improvement of 3.47% across 6benchmarks spanning spatial reasoning, fine-grained visual reasoning, andgeneral tasks beyond transit maps, underscoring enhanced visual understandingand reasoning capabilities.
Link: http://arxiv.org/abs/2510.02240v1
Updated: 2025-10-02T17:29:46Z

116: ExGRPO: Learning to Reason from Experience
Authors: ['Runzhe Zhan', 'Yafu Li', 'Zhi Wang', 'Xiaoye Qu', 'Dongrui Liu', 'Jing Shao', 'Derek F. Wong', 'Yu Cheng']
Summary: Reinforcement learning from verifiable rewards (RLVR) is an emerging paradigmfor improving the reasoning ability of large language models. However, standardon-policy training discards rollout experiences after a single update, leadingto computational inefficiency and instability. While prior work on RL hashighlighted the benefits of reusing past experience, the role of experiencecharacteristics in shaping learning dynamics of large reasoning models remainsunderexplored. In this paper, we are the first to investigate what makes areasoning experience valuable and identify rollout correctness and entropy aseffective indicators of experience value. Based on these insights, we proposeExGRPO (Experiential Group Relative Policy Optimization), a framework thatorganizes and prioritizes valuable experiences, and employs a mixed-policyobjective to balance exploration with experience exploitation. Experiments onfive backbone models (1.5B-8B parameters) show that ExGRPO consistentlyimproves reasoning performance on mathematical/general benchmarks, with anaverage gain of +3.5/7.6 points over on-policy RLVR. Moreover, ExGRPOstabilizes training on both stronger and weaker models where on-policy methodsfail. These results highlight principled experience management as a keyingredient for efficient and scalable RLVR.
Link: http://arxiv.org/abs/2510.02245v1
Updated: 2025-10-02T17:31:30Z

117: Explore Briefly, Then Decide: Mitigating LLM Overthinking via Cumulative  Entropy Regulation
Authors: ['Tianyi Jiang', 'Yi Bin', 'Yujuan Ding', 'Kainian Zhu', 'Fei Ma', 'Jingkuan Song', 'Heng Tao Shen']
Summary: Large Language Models (LLMs) have demonstrated remarkable reasoning abilitieson complex problems using long Chain-of-Thought (CoT) reasoning. However, theyoften suffer from overthinking, meaning generating unnecessarily lengthyreasoning steps for simpler problems. This issue may degrade the efficiency ofthe models and make them difficult to adapt the reasoning depth to thecomplexity of problems. To address this, we introduce a novel metric TokenEntropy Cumulative Average (TECA), which measures the extent of explorationthroughout the reasoning process. We further propose a novel reasoning paradigm-- Explore Briefly, Then Decide -- with an associated Cumulative EntropyRegulation (CER) mechanism. This paradigm leverages TECA to help the modeldynamically determine the optimal point to conclude its thought process andprovide a final answer, thus achieving efficient reasoning. Experimentalresults across diverse mathematical benchmarks show that our approachsubstantially mitigates overthinking without sacrificing problem-solvingability. With our thinking paradigm, the average response length decreases byup to 71% on simpler datasets, demonstrating the effectiveness of our method increating a more efficient and adaptive reasoning process.
Link: http://arxiv.org/abs/2510.02249v1
Updated: 2025-10-02T17:36:50Z

118: The Unreasonable Effectiveness of Scaling Agents for Computer Use
Authors: ['Gonzalo Gonzalez-Pumariega', 'Vincent Tu', 'Chih-Lun Lee', 'Jiachen Yang', 'Ang Li', 'Xin Eric Wang']
Summary: Computer-use agents (CUAs) hold promise for automating everyday digitaltasks, but their unreliability and high variance hinder their application tolong-horizon, complex tasks. We introduce Behavior Best-of-N (bBoN), a methodthat scales over agents by generating multiple rollouts and selecting amongthem using behavior narratives that describe the agents' rollouts. It enablesboth wide exploration and principled trajectory selection, substantiallyimproving robustness and success rates. On OSWorld, our bBoN scaling methodestablishes a new state of the art (SoTA) at 69.9%, significantly outperformingprior methods and approaching human-level performance at 72%, withcomprehensive ablations validating key design choices. We further demonstratestrong generalization results to different operating systems onWindowsAgentArena and AndroidWorld. Crucially, our results highlight theunreasonable effectiveness of scaling CUAs, when you do it right: effectivescaling requires structured trajectory understanding and selection, and bBoNprovides a practical framework to achieve this.
Link: http://arxiv.org/abs/2510.02250v1
Updated: 2025-10-02T17:37:08Z

119: DragFlow: Unleashing DiT Priors with Region Based Supervision for Drag  Editing
Authors: ['Zihan Zhou', 'Shilin Lu', 'Shuli Leng', 'Shaocong Zhang', 'Zhuming Lian', 'Xinlei Yu', 'Adams Wai-Kin Kong']
Summary: Drag-based image editing has long suffered from distortions in the targetregion, largely because the priors of earlier base models, Stable Diffusion,are insufficient to project optimized latents back onto the natural imagemanifold. With the shift from UNet-based DDPMs to more scalable DiT with flowmatching (e.g., SD3.5, FLUX), generative priors have become significantlystronger, enabling advances across diverse editing tasks. However, drag-basedediting has yet to benefit from these stronger priors. This work proposes thefirst framework to effectively harness FLUX's rich prior for drag-basedediting, dubbed DragFlow, achieving substantial gains over baselines. We firstshow that directly applying point-based drag editing to DiTs performs poorly:unlike the highly compressed features of UNets, DiT features are insufficientlystructured to provide reliable guidance for point-wise motion supervision. Toovercome this limitation, DragFlow introduces a region-based editing paradigm,where affine transformations enable richer and more consistent featuresupervision. Additionally, we integrate pretrained open-domain personalizationadapters (e.g., IP-Adapter) to enhance subject consistency, while preservingbackground fidelity through gradient mask-based hard constraints. Multimodallarge language models (MLLMs) are further employed to resolve task ambiguities.For evaluation, we curate a novel Region-based Dragging benchmark (ReD Bench)featuring region-level dragging instructions. Extensive experiments onDragBench-DR and ReD Bench show that DragFlow surpasses both point-based andregion-based baselines, setting a new state-of-the-art in drag-based imageediting. Code and datasets will be publicly available upon publication.
Link: http://arxiv.org/abs/2510.02253v1
Updated: 2025-10-02T17:39:13Z

120: RLAD: Training LLMs to Discover Abstractions for Solving Reasoning  Problems
Authors: ['Yuxiao Qu', 'Anikait Singh', 'Yoonho Lee', 'Amrith Setlur', 'Ruslan Salakhutdinov', 'Chelsea Finn', 'Aviral Kumar']
Summary: Reasoning requires going beyond pattern matching or memorization of solutionsto identify and implement "algorithmic procedures" that can be used to deduceanswers to hard problems. Doing so requires realizing the most relevantprimitives, intermediate results, or shared procedures, and building upon them.While RL post-training on long chains of thought ultimately aims to uncoverthis kind of algorithmic behavior, most reasoning traces learned by largemodels fail to consistently capture or reuse procedures, instead drifting intoverbose and degenerate exploration. To address more effective reasoning, weintroduce reasoning abstractions: concise natural language descriptions ofprocedural and factual knowledge that guide the model toward learningsuccessful reasoning. We train models to be capable of proposing multipleabstractions given a problem, followed by RL that incentivizes building asolution while using the information provided by these abstractions. Thisresults in a two-player RL training paradigm, abbreviated as RLAD, that jointlytrains an abstraction generator and a solution generator. This setupeffectively enables structured exploration, decouples learning signals ofabstraction proposal and solution generation, and improves generalization toharder problems. We also show that allocating more test-time compute togenerating abstractions is more beneficial for performance than generating moresolutions at large test budgets, illustrating the role of abstractions inguiding meaningful exploration.
Link: http://arxiv.org/abs/2510.02263v1
Updated: 2025-10-02T17:44:23Z

121: Paving the Way Towards Kinematic Assessment Using Monocular Video: A  Preclinical Benchmark of State-of-the-Art Deep-Learning-Based 3D Human Pose  Estimators Against Inertial Sensors in Daily Living Activities
Authors: ['Mario Medrano-Paredes', 'Carmen Fernández-González', 'Francisco-Javier Díaz-Pernas', 'Hichem Saoudi', 'Javier González-Alonso', 'Mario Martínez-Zarzuela']
Summary: Advances in machine learning and wearable sensors offer new opportunities forcapturing and analyzing human movement outside specialized laboratories.Accurate assessment of human movement under real-world conditions is essentialfor telemedicine, sports science, and rehabilitation. This preclinicalbenchmark compares monocular video-based 3D human pose estimation models withinertial measurement units (IMUs), leveraging the VIDIMU dataset containing atotal of 13 clinically relevant daily activities which were captured using bothcommodity video cameras and five IMUs. During this initial study only healthysubjects were recorded, so results cannot be generalized to pathologicalcohorts. Joint angles derived from state-of-the-art deep learning frameworks(MotionAGFormer, MotionBERT, MMPose 2D-to-3D pose lifting, and NVIDIABodyTrack) were evaluated against joint angles computed from IMU data usingOpenSim inverse kinematics following the Human3.6M dataset format with 17keypoints. Among them, MotionAGFormer demonstrated superior performance,achieving the lowest overall RMSE ($9.27\deg \pm 4.80\deg$) and MAE ($7.86\deg\pm 4.18\deg$), as well as the highest Pearson correlation ($0.86 \pm 0.15$)and the highest coefficient of determination $R^{2}$ ($0.67 \pm 0.28$). Theresults reveal that both technologies are viable for out-of-the-lab kinematicassessment. However, they also highlight key trade-offs between video- andsensor-based approaches including costs, accessibility, and precision. Thisstudy clarifies where off-the-shelf video models already provide clinicallypromising kinematics in healthy adults and where they lag behind IMU-basedestimates while establishing valuable guidelines for researchers and cliniciansseeking to develop robust, cost-effective, and user-friendly solutions fortelehealth and remote patient monitoring.
Link: http://arxiv.org/abs/2510.02264v1
Updated: 2025-10-02T17:44:31Z

122: How to Combat Reactive and Dynamic Jamming Attacks with Reinforcement  Learning
Authors: ['Yalin E. Sagduyu', 'Tugba Erpek', 'Kemal Davaslioglu', 'Sastry Kompella']
Summary: This paper studies the problem of mitigating reactive jamming, where a jammeradopts a dynamic policy of selecting channels and sensing thresholds to detectand jam ongoing transmissions. The transmitter-receiver pair learns to avoidjamming and optimize throughput over time (without prior knowledge of channelconditions or jamming strategies) by using reinforcement learning (RL) to adapttransmit power, modulation, and channel selection. Q-learning is employed fordiscrete jamming-event states, while Deep Q-Networks (DQN) are employed forcontinuous states based on received power. Through different reward functionsand action sets, the results show that RL can adapt rapidly to spectrumdynamics and sustain high rates as channels and jamming policies change overtime.
Link: http://arxiv.org/abs/2510.02265v1
Updated: 2025-10-02T17:44:38Z

123: microCLIP: Unsupervised CLIP Adaptation via Coarse-Fine Token Fusion for  Fine-Grained Image Classification
Authors: ['Sathira Silva', 'Eman Ali', 'Chetan Arora', 'Muhammad Haris Khan']
Summary: Unsupervised adaptation of CLIP-based vision-language models (VLMs) forfine-grained image classification requires sensitivity to microscopic localcues. While CLIP exhibits strong zero-shot transfer, its reliance on coarseglobal features restricts its performance on fine-grained classification tasks.Prior efforts inject fine-grained knowledge by aligning large language model(LLM) descriptions with the CLIP $\texttt{[CLS]}$ token; however, this approachoverlooks spatial precision. We propose $\textbf{microCLIP}$, a self-trainingframework that jointly refines CLIP's visual and textual representations usingfine-grained cues. At its core is Saliency-Oriented Attention Pooling (SOAP)within a lightweight TokenFusion module, which builds a saliency-guided$\texttt{[FG]}$ token from patch embeddings and fuses it with the global$\texttt{[CLS]}$ token for coarse-fine alignment. To stabilize adaptation, weintroduce a two-headed LLM-derived classifier: a frozen classifier that, viamulti-view alignment, provides a stable text-based prior for pseudo-labeling,and a learnable classifier initialized from LLM descriptions and fine-tunedwith TokenFusion. We further develop Dynamic Knowledge Aggregation, whichconvexly combines fixed LLM/CLIP priors with TokenFusion's evolving logits toiteratively refine pseudo-labels. Together, these components uncover latentfine-grained signals in CLIP, yielding a consistent $2.90\%$ average accuracygain across 13 fine-grained benchmarks while requiring only light adaptation.Our code is available at https://github.com/sathiiii/microCLIP.
Link: http://arxiv.org/abs/2510.02270v1
Updated: 2025-10-02T17:47:39Z

124: InfoMosaic-Bench: Evaluating Multi-Source Information Seeking in  Tool-Augmented Agents
Authors: ['Yaxin Du', 'Yuanshuo Zhang', 'Xiyuan Yang', 'Yifan Zhou', 'Cheng Wang', 'Gongyi Zou', 'Xianghe Pang', 'Wenhao Wang', 'Menglan Chen', 'Shuo Tang', 'Zhiyu Li', 'Siheng Chen']
Summary: Information seeking is a fundamental requirement for humans. However,existing LLM agents rely heavily on open-web search, which exposes twofundamental weaknesses: online content is noisy and unreliable, and manyreal-world tasks require precise, domain-specific knowledge unavailable fromthe web. The emergence of the Model Context Protocol (MCP) now allows agents tointerface with thousands of specialized tools, seemingly resolving thislimitation. Yet it remains unclear whether agents can effectively leverage suchtools -- and more importantly, whether they can integrate them withgeneral-purpose search to solve complex tasks. Therefore, we introduceInfoMosaic-Bench, the first benchmark dedicated to multi-source informationseeking in tool-augmented agents. Covering six representative domains(medicine, finance, maps, video, web, and multi-domain integration),InfoMosaic-Bench requires agents to combine general-purpose search withdomain-specific tools. Tasks are synthesized with InfoMosaic-Flow, a scalablepipeline that grounds task conditions in verified tool outputs, enforcescross-source dependencies, and filters out shortcut cases solvable by triviallookup. This design guarantees both reliability and non-triviality. Experimentswith 14 state-of-the-art LLM agents reveal three findings: (i) web informationalone is insufficient, with GPT-5 achieving only 38.2% accuracy and 67.5% passrate; (ii) domain tools provide selective but inconsistent benefits, improvingsome domains while degrading others; and (iii) 22.4% of failures arise fromincorrect tool usage or selection, highlighting that current LLMs stillstruggle with even basic tool handling.
Link: http://arxiv.org/abs/2510.02271v1
Updated: 2025-10-02T17:48:03Z

125: Parallel Scaling Law: Unveiling Reasoning Generalization through A  Cross-Linguistic Perspective
Authors: ['Wen Yang', 'Junhong Wu', 'Chong Li', 'Chengqing Zong', 'Jiajun Zhang']
Summary: Recent advancements in Reinforcement Post-Training (RPT) have significantlyenhanced the capabilities of Large Reasoning Models (LRMs), sparking increasedinterest in the generalization of RL-based reasoning. While existing work hasprimarily focused on investigating its generalization across tasks ormodalities, this study proposes a novel cross-linguistic perspective toinvestigate reasoning generalization. This raises a crucial question:$\textit{Does the reasoning capability achieved from English RPT effectivelytransfer to other languages?}$ We address this by systematically evaluatingEnglish-centric LRMs on multilingual reasoning benchmarks and introducing ametric to quantify cross-lingual transferability. Our findings reveal thatcross-lingual transferability varies significantly across initial model, targetlanguage, and training paradigm. Through interventional studies, we find thatmodels with stronger initial English capabilities tend to over-rely onEnglish-specific patterns, leading to diminished cross-lingual generalization.To address this, we conduct a thorough parallel training study. Experimentalresults yield three key findings: $\textbf{First-Parallel Leap}$, a substantialleap in performance when transitioning from monolingual to just a singleparallel language, and a predictable $\textbf{Parallel Scaling Law}$, revealingthat cross-lingual reasoning transfer follows a power-law with the number oftraining parallel languages. Moreover, we identify the discrepancy betweenactual monolingual performance and the power-law prediction as$\textbf{Monolingual Generalization Gap}$, indicating that English-centric LRMsfail to fully generalize across languages. Our study challenges the assumptionthat LRM reasoning mirrors human cognition, providing critical insights for thedevelopment of more language-agnostic LRMs.
Link: http://arxiv.org/abs/2510.02272v1
Updated: 2025-10-02T17:49:49Z

126: BioX-Bridge: Model Bridging for Unsupervised Cross-Modal Knowledge  Transfer across Biosignals
Authors: ['Chenqi Li', 'Yu Liu', 'Timothy Denison', 'Tingting Zhu']
Summary: Biosignals offer valuable insights into the physiological states of the humanbody. Although biosignal modalities differ in functionality, signal fidelity,sensor comfort, and cost, they are often intercorrelated, reflecting theholistic and interconnected nature of human physiology. This opens up thepossibility of performing the same tasks using alternative biosignalmodalities, thereby improving the accessibility, usability, and adaptability ofhealth monitoring systems. However, the limited availability of large labeleddatasets presents challenges for training models tailored to specific tasks andmodalities of interest. Unsupervised cross-modal knowledge transfer offers apromising solution by leveraging knowledge from an existing modality to supportmodel training for a new modality. Existing methods are typically based onknowledge distillation, which requires running a teacher model alongsidestudent model training, resulting in high computational and memory overhead.This challenge is further exacerbated by the recent development of foundationmodels that demonstrate superior performance and generalization across tasks atthe cost of large model sizes. To this end, we explore a new framework forunsupervised cross-modal knowledge transfer of biosignals by training alightweight bridge network to align the intermediate representations and enableinformation flow between foundation models and across modalities. Specifically,we introduce an efficient strategy for selecting alignment positions where thebridge should be constructed, along with a flexible prototype network as thebridge architecture. Extensive experiments across multiple biosignalmodalities, tasks, and datasets show that BioX-Bridge reduces the number oftrainable parameters by 88--99\% while maintaining or even improving transferperformance compared to state-of-the-art methods.
Link: http://arxiv.org/abs/2510.02276v1
Updated: 2025-10-02T17:51:19Z

127: Addressing Pitfalls in the Evaluation of Uncertainty Estimation Methods  for Natural Language Generation
Authors: ['Mykyta Ielanskyi', 'Kajetan Schweighofer', 'Lukas Aichberger', 'Sepp Hochreiter']
Summary: Hallucinations are a common issue that undermine the reliability of largelanguage models (LLMs). Recent studies have identified a specific subset ofhallucinations, known as confabulations, which arise due to predictiveuncertainty of LLMs. To detect confabulations, various methods for estimatingpredictive uncertainty in natural language generation (NLG) have beendeveloped. These methods are typically evaluated by correlating uncertaintyestimates with the correctness of generated text, with question-answering (QA)datasets serving as the standard benchmark. However, commonly used approximatecorrectness functions have substantial disagreement between each other and,consequently, in the ranking of the uncertainty estimation methods. This allowsone to inflate the apparent performance of uncertainty estimation methods. Wepropose using several alternative risk indicators for risk correlationexperiments that improve robustness of empirical assessment of UE algorithmsfor NLG. For QA tasks, we show that marginalizing over multiple LLM-as-a-judgevariants leads to reducing the evaluation biases. Furthermore, we explorestructured tasks as well as out of distribution and perturbation detectiontasks which provide robust and controllable risk indicators. Finally, wepropose to use an Elo rating of uncertainty estimation methods to give anobjective summarization over extensive evaluation settings.
Link: http://arxiv.org/abs/2510.02279v1
Updated: 2025-10-02T17:54:09Z

128: Self-Forcing++: Towards Minute-Scale High-Quality Video Generation
Authors: ['Justin Cui', 'Jie Wu', 'Ming Li', 'Tao Yang', 'Xiaojie Li', 'Rui Wang', 'Andrew Bai', 'Yuanhao Ban', 'Cho-Jui Hsieh']
Summary: Diffusion models have revolutionized image and video generation, achievingunprecedented visual quality. However, their reliance on transformerarchitectures incurs prohibitively high computational costs, particularly whenextending generation to long videos. Recent work has explored autoregressiveformulations for long video generation, typically by distilling fromshort-horizon bidirectional teachers. Nevertheless, given that teacher modelscannot synthesize long videos, the extrapolation of student models beyond theirtraining horizon often leads to pronounced quality degradation, arising fromthe compounding of errors within the continuous latent space. In this paper, wepropose a simple yet effective approach to mitigate quality degradation inlong-horizon video generation without requiring supervision from long-videoteachers or retraining on long video datasets. Our approach centers onexploiting the rich knowledge of teacher models to provide guidance for thestudent model through sampled segments drawn from self-generated long videos.Our method maintains temporal consistency while scaling video length by up to20x beyond teacher's capability, avoiding common issues such as over-exposureand error-accumulation without recomputing overlapping frames like previousmethods. When scaling up the computation, our method shows the capability ofgenerating videos up to 4 minutes and 15 seconds, equivalent to 99.9% of themaximum span supported by our base model's position embedding and more than 50xlonger than that of our baseline model. Experiments on standard benchmarks andour proposed improved benchmark demonstrate that our approach substantiallyoutperforms baseline methods in both fidelity and consistency. Our long-horizonvideos demo can be found at https://self-forcing-plus-plus.github.io/
Link: http://arxiv.org/abs/2510.02283v1
Updated: 2025-10-02T17:55:42Z

129: Learning to Generate Object Interactions with Physics-Guided Video  Diffusion
Authors: ['David Romero', 'Ariana Bermudez', 'Hao Li', 'Fabio Pizzati', 'Ivan Laptev']
Summary: Recent models for video generation have achieved remarkable progress and arenow deployed in film, social media production, and advertising. Beyond theircreative potential, such models also hold promise as world simulators forrobotics and embodied decision making. Despite strong advances, however,current approaches still struggle to generate physically plausible objectinteractions and lack physics-grounded control mechanisms. To address thislimitation, we introduce KineMask, an approach for physics-guided videogeneration that enables realistic rigid body control, interactions, andeffects. Given a single image and a specified object velocity, our methodgenerates videos with inferred motions and future object interactions. Wepropose a two-stage training strategy that gradually removes future motionsupervision via object masks. Using this strategy we train video diffusionmodels (VDMs) on synthetic scenes of simple interactions and demonstratesignificant improvements of object interactions in real scenes. Furthermore,KineMask integrates low-level motion control with high-level textualconditioning via predictive scene descriptions, leading to effective supportfor synthesis of complex dynamical phenomena. Extensive experiments show thatKineMask achieves strong improvements over recent models of comparable size.Ablation studies further highlight the complementary roles of low- andhigh-level conditioning in VDMs. Our code, model, and data will be madepublicly available.
Link: http://arxiv.org/abs/2510.02284v1
Updated: 2025-10-02T17:56:46Z

130: Tree-based Dialogue Reinforced Policy Optimization for Red-Teaming  Attacks
Authors: ['Ruohao Guo', 'Afshin Oroojlooy', 'Roshan Sridhar', 'Miguel Ballesteros', 'Alan Ritter', 'Dan Roth']
Summary: Despite recent rapid progress in AI safety, current large language modelsremain vulnerable to adversarial attacks in multi-turn interaction settings,where attackers strategically adapt their prompts across conversation turns andpose a more critical yet realistic challenge. Existing approaches that discoversafety vulnerabilities either rely on manual red-teaming with human experts oremploy automated methods using pre-defined templates and human-curated attackdata, with most focusing on single-turn attacks. However, these methods did notexplore the vast space of possible multi-turn attacks, failing to considernovel attack trajectories that emerge from complex dialogue dynamics andstrategic conversation planning. This gap is particularly critical given recentfindings that LLMs exhibit significantly higher vulnerability to multi-turnattacks compared to single-turn attacks. We propose DialTree-RPO, an on-policyreinforcement learning framework integrated with tree search that autonomouslydiscovers diverse multi-turn attack strategies by treating the dialogue as asequential decision-making problem, enabling systematic exploration withoutmanually curated data. Through extensive experiments, our approach not onlyachieves more than 25.9% higher ASR across 10 target models compared toprevious state-of-the-art approaches, but also effectively uncovers new attackstrategies by learning optimal dialogue policies that maximize attack successacross multiple turns.
Link: http://arxiv.org/abs/2510.02286v1
Updated: 2025-10-02T17:57:05Z

131: F2LLM Technical Report: Matching SOTA Embedding Performance with 6  Million Open-Source Data
Authors: ['Ziyin Zhang', 'Zihan Liao', 'Hang Yu', 'Peng Di', 'Rui Wang']
Summary: We introduce F2LLM - Foundation to Feature Large Language Models, a suite ofstate-of-the-art embedding models in three sizes: 0.6B, 1.7B, and 4B. Unlikeprevious top-ranking embedding models that require massive contrastivepretraining, sophisticated training pipelines, and costly synthetic trainingdata, F2LLM is directly finetuned from foundation models on 6 millionquery-document-negative tuples curated from open-source, non-syntheticdatasets, striking a strong balance between training cost, model size, andembedding performance. On the MTEB English leaderboard, F2LLM-4B ranks 2ndamong models with approximately 4B parameters and 7th overall, while F2LLM-1.7Branks 1st among models in the 1B-2B size range. To facilitate future researchin the field, we release the models, training dataset, and code, positioningF2LLM as a strong, reproducible, and budget-friendly baseline for future works.
Link: http://arxiv.org/abs/2510.02294v1
Updated: 2025-10-02T17:58:49Z

132: VideoNSA: Native Sparse Attention Scales Video Understanding
Authors: ['Enxin Song', 'Wenhao Chai', 'Shusheng Yang', 'Ethan Armand', 'Xiaojun Shan', 'Haiyang Xu', 'Jianwen Xie', 'Zhuowen Tu']
Summary: Video understanding in multimodal language models remains limited by contextlength: models often miss key transition frames and struggle to maintaincoherence across long time scales. To address this, we adapt Native SparseAttention (NSA) to video-language models. Our method, VideoNSA, adaptsQwen2.5-VL through end-to-end training on a 216K video instruction dataset. Weemploy a hardware-aware hybrid approach to attention, preserving denseattention for text, while employing NSA for video. Compared totoken-compression and training-free sparse baselines, VideoNSA achievesimproved performance on long-video understanding, temporal reasoning, andspatial benchmarks. Further ablation analysis reveals four key findings: (1)reliable scaling to 128K tokens; (2) an optimal global-local attentionallocation at a fixed budget; (3) task-dependent branch usage patterns; and (4)the learnable combined sparse attention help induce dynamic attention sinks.
Link: http://arxiv.org/abs/2510.02295v1
Updated: 2025-10-02T17:58:54Z

133: Interactive Training: Feedback-Driven Neural Network Optimization
Authors: ['Wentao Zhang', 'Yang Young Lu', 'Yuntian Deng']
Summary: Traditional neural network training typically follows fixed, predefinedoptimization recipes, lacking the flexibility to dynamically respond toinstabilities or emerging training issues. In this paper, we introduceInteractive Training, an open-source framework that enables real-time,feedback-driven intervention during neural network training by human experts orautomated AI agents. At its core, Interactive Training uses a control server tomediate communication between users or agents and the ongoing training process,allowing users to dynamically adjust optimizer hyperparameters, training data,and model checkpoints. Through three case studies, we demonstrate thatInteractive Training achieves superior training stability, reduced sensitivityto initial hyperparameters, and improved adaptability to evolving user needs,paving the way toward a future training paradigm where AI agents autonomouslymonitor training logs, proactively resolve instabilities, and optimize trainingdynamics.
Link: http://arxiv.org/abs/2510.02297v1
Updated: 2025-10-02T17:59:00Z

134: Equilibrium Matching: Generative Modeling with Implicit Energy-Based  Models
Authors: ['Runqian Wang', 'Yilun Du']
Summary: We introduce Equilibrium Matching (EqM), a generative modeling frameworkbuilt from an equilibrium dynamics perspective. EqM discards thenon-equilibrium, time-conditional dynamics in traditional diffusion andflow-based generative models and instead learns the equilibrium gradient of animplicit energy landscape. Through this approach, we can adopt anoptimization-based sampling process at inference time, where samples areobtained by gradient descent on the learned landscape with adjustable stepsizes, adaptive optimizers, and adaptive compute. EqM surpasses the generationperformance of diffusion/flow models empirically, achieving an FID of 1.90 onImageNet 256$\times$256. EqM is also theoretically justified to learn andsample from the data manifold. Beyond generation, EqM is a flexible frameworkthat naturally handles tasks including partially noised image denoising, OODdetection, and image composition. By replacing time-conditional velocities witha unified equilibrium landscape, EqM offers a tighter bridge between flow andenergy-based models and a simple route to optimization-driven inference.
Link: http://arxiv.org/abs/2510.02300v1
Updated: 2025-10-02T17:59:06Z

135: Diffusion Models and the Manifold Hypothesis: Log-Domain Smoothing is  Geometry Adaptive
Authors: ['Tyler Farghly', 'Peter Potaptchik', 'Samuel Howard', 'George Deligiannidis', 'Jakiw Pidstrigach']
Summary: Diffusion models have achieved state-of-the-art performance, demonstratingremarkable generalisation capabilities across diverse domains. However, themechanisms underpinning these strong capabilities remain only partiallyunderstood. A leading conjecture, based on the manifold hypothesis, attributesthis success to their ability to adapt to low-dimensional geometric structurewithin the data. This work provides evidence for this conjecture, focusing onhow such phenomena could result from the formulation of the learning problemthrough score matching. We inspect the role of implicit regularisation byinvestigating the effect of smoothing minimisers of the empirical scorematching objective. Our theoretical and empirical results confirm thatsmoothing the score function -- or equivalently, smoothing in the log-densitydomain -- produces smoothing tangential to the data manifold. In addition, weshow that the manifold along which the diffusion model generalises can becontrolled by choosing an appropriate smoothing.
Link: http://arxiv.org/abs/2510.02305v1
Updated: 2025-10-02T17:59:39Z

136: NoiseShift: Resolution-Aware Noise Recalibration for Better  Low-Resolution Image Generation
Authors: ['Ruozhen He', 'Moayed Haji-Ali', 'Ziyan Yang', 'Vicente Ordonez']
Summary: Text-to-image diffusion models trained on a fixed set of resolutions oftenfail to generalize, even when asked to generate images at lower resolutionsthan those seen during training. High-resolution text-to-image generators arecurrently unable to easily offer an out-of-the-box budget-efficient alternativeto their users who might not need high-resolution images. We identify a keytechnical insight in diffusion models that when addressed can help tackle thislimitation: Noise schedulers have unequal perceptual effects acrossresolutions. The same level of noise removes disproportionately more signalfrom lower-resolution images than from high-resolution images, leading to atrain-test mismatch. We propose NoiseShift, a training-free method thatrecalibrates the noise level of the denoiser conditioned on resolution size.NoiseShift requires no changes to model architecture or sampling schedule andis compatible with existing models. When applied to Stable Diffusion 3, StableDiffusion 3.5, and Flux-Dev, quality at low resolutions is significantlyimproved. On LAION-COCO, NoiseShift improves SD3.5 by 15.89%, SD3 by 8.56%, andFlux-Dev by 2.44% in FID on average. On CelebA, NoiseShift improves SD3.5 by10.36%, SD3 by 5.19%, and Flux-Dev by 3.02% in FID on average. These resultsdemonstrate the effectiveness of NoiseShift in mitigating resolution-dependentartifacts and enhancing the quality of low-resolution image generation.
Link: http://arxiv.org/abs/2510.02307v1
Updated: 2025-10-02T17:59:43Z

