1: Towards Interpretable and Inference-Optimal COT Reasoning with Sparse  Autoencoder-Guided Generation
Authors: ['Daniel Zhao', 'Abhilash Shankarampeta', 'Lanxiang Hu', 'Tajana Rosing', 'Hao Zhang']
Summary: We propose a novel method that leverages sparse autoencoders (SAEs) andclustering techniques to analyze the internal token representations of largelanguage models (LLMs) and guide generations in mathematical reasoning tasks.Our approach first trains an SAE to generate sparse vector representations fortraining tokens, then applies k-means clustering to construct a graph wherevertices represent token clusters and weighted edges capture sequential tokentransitions. Using this graph, we define an edge-weight based reward functionto quantify adherence to established reasoning traces, thereby identifyingexploitative reasoning trajectories. Additionally, we measure generationdiversity from clustering to assess the extent of exploration. Our findingsindicate that balancing both exploitation and exploration is crucial forachieving high accuracy in mathematical reasoning tasks. During generation, theSAE can serve as a scalable reward model to guide generations, ensuring abalanced trade-off between exploitation and exploration. This prevents extremebehaviors in either direction, ultimately fostering a higher-quality reasoningprocess in LLMs.
摘要: 我们提出了一种新方法，利用稀疏自编码器（SAEs）和聚类技术来分析大型语言模型（LLMs）的内部令牌表示，并指导数学推理任务中的生成过程。我们的方法首先训练一个SAE，为训练令牌生成稀疏向量表示，然后应用k均值聚类构建一个图，其中顶点代表令牌簇，加权边捕获令牌的顺序转换。利用该图，我们定义了一个基于边权重的奖励函数，以量化对既定推理轨迹的遵循程度，从而识别出利用性推理轨迹。此外，我们还从聚类中测量生成多样性，以评估探索的程度。研究结果表明，平衡利用和探索对于在数学推理任务中实现高准确性至关重要。在生成过程中，SAE可作为可扩展的奖励模型来指导生成，确保利用与探索之间的平衡权衡。这能防止任一方向的极端行为，最终在大型语言模型中培育出更高质量的推理过程。
Link: http://arxiv.org/abs/2510.01528v1
Updated: 2025-10-02T00:01:08Z

2: LOGicalThought: Logic-Based Ontological Grounding of LLMs for  High-Assurance Reasoning
Authors: ['Navapat Nananukul', 'Yue Zhang', 'Ryan Lee', 'Eric Boxer', 'Jonathan May', 'Vibhav Giridhar Gogate', 'Jay Pujara', 'Mayank Kejriwal']
Summary: High-assurance reasoning, particularly in critical domains such as law andmedicine, requires conclusions that are accurate, verifiable, and explicitlygrounded in evidence. This reasoning relies on premises codified from rules,statutes, and contracts, inherently involving defeasible or non-monotonic logicdue to numerous exceptions, where the introduction of a single fact caninvalidate general rules, posing significant challenges. While large languagemodels (LLMs) excel at processing natural language, their capabilities instandard inference tasks do not translate to the rigorous reasoning requiredover high-assurance text guidelines. Core reasoning challenges within suchtexts often manifest specific logical structures involving negation,implication, and, most critically, defeasible rules and exceptions. In thispaper, we propose a novel neurosymbolically-grounded architecture calledLOGicalThought (LogT) that uses an advanced logical language and reasoner inconjunction with an LLM to construct a dual symbolic graph context andlogic-based context. These two context representations transform the problemfrom inference over long-form guidelines into a compact grounded evaluation.Evaluated on four multi-domain benchmarks against four baselines, LogT improvesoverall performance by 11.84% across all LLMs. Performance improvessignificantly across all three modes of reasoning: by up to +10.2% on negation,+13.2% on implication, and +5.5% on defeasible reasoning compared to thestrongest baseline.
摘要: 高保证推理，特别是在法律和医学等关键领域，要求结论准确、可验证，并明确基于证据。这种推理依赖于从规则、法规和合同中编码的前提，由于存在大量例外情况，其本质上涉及可废止或非单调逻辑，即单一事实的引入可能使一般规则失效，从而带来重大挑战。虽然大型语言模型（LLM）在处理自然语言方面表现出色，但它们在标准推理任务中的能力无法转化为对高保证文本指南所需的严格推理。此类文本中的核心推理挑战通常表现为涉及否定、蕴含以及最关键的可废止规则和例外的特定逻辑结构。在本文中，我们提出了一种新颖的基于神经符号的架构，称为LOGicalThought（LogT），它使用一种先进的逻辑语言和推理器与大型语言模型相结合，构建双重符号图上下文和基于逻辑的上下文。这两种上下文表示将问题从对长篇指南的推理转化为紧凑的基于保证的评估。在四个多领域基准测试中，与四个基线模型相比，LogT在所有大型语言模型上的整体性能提升了11.84%。在所有三种推理模式上，性能均有显著提升：与最强基线相比，否定推理提升高达+10.2%，蕴含推理提升+13.2%，可废止推理提升+5.5%。
Link: http://arxiv.org/abs/2510.01530v1
Updated: 2025-10-02T00:06:23Z

3: Information Seeking for Robust Decision Making under Partial  Observability
Authors: ['Djengo Cyun-Jyun Fang', 'Tsung-Wei Ke']
Summary: Explicit information seeking is essential to human problem-solving inpractical environments characterized by incomplete information and noisydynamics. When the true environmental state is not directly observable, humansseek information to update their internal dynamics and inform futuredecision-making. Although existing Large Language Model (LLM) planning agentshave addressed observational uncertainty, they often overlook discrepanciesbetween their internal dynamics and the actual environment. We introduceInformation Seeking Decision Planner (InfoSeeker), an LLM decision-makingframework that integrates task-oriented planning with information seeking toalign internal dynamics and make optimal decisions under uncertainty in bothagent observations and environmental dynamics. InfoSeeker prompts an LLM toactively gather information by planning actions to validate its understanding,detect environmental changes, or test hypotheses before generating or revisingtask-oriented plans. To evaluate InfoSeeker, we introduce a novel benchmarksuite featuring partially observable environments with incomplete observationsand uncertain dynamics. Experiments demonstrate that InfoSeeker achieves a 74%absolute performance gain over prior methods without sacrificing sampleefficiency. Moreover, InfoSeeker generalizes across LLMs and outperformsbaselines on established benchmarks such as robotic manipulation and webnavigation. These findings underscore the importance of tightly integratingplanning and information seeking for robust behavior in partially observableenvironments. The project page is available at https://infoseekerllm.github.io
摘要: 在信息不完整且动态嘈杂的实际环境中，显式信息获取对于人类解决问题至关重要。当真实环境状态无法直接观测时，人类会主动获取信息以更新其内部动态并指导未来的决策。尽管现有的大型语言模型（LLM）规划智能体已解决了观测不确定性问题，但它们往往忽略了内部动态与实际环境之间的差异。我们提出了信息获取决策规划器（InfoSeeker），这是一个LLM决策框架，它将面向任务的规划与信息获取相结合，以在智能体观测和环境动态均不确定的情况下对齐内部动态并做出最优决策。InfoSeeker通过规划操作来提示LLM主动收集信息，以验证其理解、检测环境变化或测试假设，然后再生成或修订面向任务的规划。为了评估InfoSeeker，我们引入了一个新颖的基准测试套件，其特点是具有不完整观测和不确定动态的部分可观测环境。实验表明，InfoSeeker在保持样本效率的同时，比先前方法实现了74%的绝对性能提升。此外，InfoSeeker能够跨LLM泛化，并在机器人操作和网络导航等既定基准测试上优于基线模型。这些研究结果强调了在部分可观测环境中紧密整合规划与信息获取对于实现鲁棒性行为的重要性。项目页面可在https://infoseekerllm.github.io获取。
Link: http://arxiv.org/abs/2510.01531v1
Updated: 2025-10-02T00:06:32Z

4: Step-Aware Policy Optimization for Reasoning in Diffusion Large Language  Models
Authors: ['Shaoan Xie', 'Lingjing Kong', 'Xiangchen Song', 'Xinshuai Dong', 'Guangyi Chen', 'Eric P. Xing', 'Kun Zhang']
Summary: Diffusion language models (dLLMs) offer a promising, non-autoregressiveparadigm for text generation, yet training them for complex reasoning remains akey challenge. Current reinforcement learning approaches often rely on sparse,outcome-based rewards, which can reinforce flawed reasoning paths that lead tocoincidentally correct answers. We argue that this stems from a fundamentalmismatch with the natural structure of reasoning. We first propose atheoretical framework that formalizes complex problem solving as a hierarchicalselection process, where an intractable global constraint is decomposed into aseries of simpler, localized logical steps. This framework provides aprincipled foundation for algorithm design, including theoretical insights intothe identifiability of this latent reasoning structure. Motivated by thistheory, we identify unstructured refinement -- a failure mode where a model'siterative steps do not contribute meaningfully to the solution -- as a coredeficiency in existing methods. We then introduce Step-Aware PolicyOptimization (SAPO), a novel RL algorithm that aligns the dLLM's denoisingprocess with the latent reasoning hierarchy. By using a process-based rewardfunction that encourages incremental progress, SAPO guides the model to learnstructured, coherent reasoning paths. Our empirical results show that thisprincipled approach significantly improves performance on challenging reasoningbenchmarks and enhances the interpretability of the generation process.
摘要: 扩散语言模型（dLLMs）为文本生成提供了一种前景广阔的非自回归范式，然而，训练它们进行复杂推理仍是一个关键挑战。当前的强化学习方法通常依赖于稀疏的、基于结果的奖励，这可能会强化那些因巧合而得出正确答案的 flawed 推理路径。我们认为，这源于其与推理自然结构之间的根本性不匹配。我们首先提出了一个理论框架，将复杂问题求解形式化为一个分层选择过程，其中，一个难以处理的全局约束被分解为一系列更简单的、局部化的逻辑步骤。该框架为算法设计提供了原则性基础，包括对该潜在推理结构可识别性的理论洞见。受此理论启发，我们识别出“无结构精炼”——一种模型的迭代步骤未能对解决方案做出有意义贡献的失效模式——作为现有方法的核心缺陷。接着，我们引入了“步骤感知策略优化”（SAPO），这是一种新颖的强化学习算法，它将dLLM的去噪过程与潜在推理层级对齐。通过使用一个鼓励增量进展的基于过程的奖励函数，SAPO引导模型学习结构化、连贯的推理路径。我们的实证结果表明，这种原则性方法显著提升了模型在具有挑战性的推理基准上的性能，并增强了生成过程的可解释性。
Link: http://arxiv.org/abs/2510.01544v1
Updated: 2025-10-02T00:34:15Z

5: Predictive Preference Learning from Human Interventions
Authors: ['Haoyuan Cai', 'Zhenghao Peng', 'Bolei Zhou']
Summary: Learning from human involvement aims to incorporate the human subject tomonitor and correct agent behavior errors. Although most interactive imitationlearning methods focus on correcting the agent's action at the current state,they do not adjust its actions in future states, which may be potentially morehazardous. To address this, we introduce Predictive Preference Learning fromHuman Interventions (PPL), which leverages the implicit preference signalscontained in human interventions to inform predictions of future rollouts. Thekey idea of PPL is to bootstrap each human intervention into L future timesteps, called the preference horizon, with the assumption that the agentfollows the same action and the human makes the same intervention in thepreference horizon. By applying preference optimization on these future states,expert corrections are propagated into the safety-critical regions where theagent is expected to explore, significantly improving learning efficiency andreducing human demonstrations needed. We evaluate our approach with experimentson both autonomous driving and robotic manipulation benchmarks and demonstrateits efficiency and generality. Our theoretical analysis further shows thatselecting an appropriate preference horizon L balances coverage of risky stateswith label correctness, thereby bounding the algorithmic optimality gap. Demoand code are available at: https://metadriverse.github.io/ppl
摘要: 借鉴人类参与旨在将人类主体纳入其中，以监控和纠正智能体的行为错误。尽管大多数交互式模仿学习方法专注于纠正智能体在当前状态下的动作，但它们并未调整其在未来状态下的动作，而这些动作可能潜在地更具危险性。为解决这一问题，我们提出了基于人类干预的预测偏好学习（PPL），该方法利用人类干预中隐含的偏好信号，为未来展开的预测提供信息。PPL的核心思想是将每次人类干预推广至L个未来时间步（称为偏好视界），其假设是智能体在偏好视界内遵循相同的动作，且人类进行相同的干预。通过对这些未来状态应用偏好优化，专家的纠正被传播至智能体预期探索的安全关键区域，从而显著提升学习效率并减少所需的人类示范。我们通过在自动驾驶和机器人操作基准测试上的实验评估了该方法，并展示了其高效性和通用性。我们的理论分析进一步表明，选择合适的偏好视界L能够平衡风险状态的覆盖与标签正确性，从而限制算法的最优性差距。演示和代码可在以下网址获取：https://metadriverse.github.io/ppl。
Link: http://arxiv.org/abs/2510.01545v1
Updated: 2025-10-02T00:38:18Z

6: POLAR: Automating Cyber Threat Prioritization through LLM-Powered  Assessment
Authors: ['Luoxi Tang', 'Yuqiao Meng', 'Ankita Patra', 'Weicheng Ma', 'Muchao Ye', 'Zhaohan Xi']
Summary: Large Language Models (LLMs) are intensively used to assist security analystsin counteracting the rapid exploitation of cyber threats, wherein LLMs offercyber threat intelligence (CTI) to support vulnerability assessment andincident response. While recent work has shown that LLMs can support a widerange of CTI tasks such as threat analysis, vulnerability detection, andintrusion defense, significant performance gaps persist in practicaldeployments. In this paper, we investigate the intrinsic vulnerabilities ofLLMs in CTI, focusing on challenges that arise from the nature of the threatlandscape itself rather than the model architecture. Using large-scaleevaluations across multiple CTI benchmarks and real-world threat reports, weintroduce a novel categorization methodology that integrates stratification,autoregressive refinement, and human-in-the-loop supervision to reliablyanalyze failure instances. Through extensive experiments and human inspections,we reveal three fundamental vulnerabilities: spurious correlations,contradictory knowledge, and constrained generalization, that limit LLMs ineffectively supporting CTI. Subsequently, we provide actionable insights fordesigning more robust LLM-powered CTI systems to facilitate future research.
摘要: 大型语言模型（LLMs）被广泛用于协助安全分析师对抗网络威胁的快速利用，其中LLMs提供网络威胁情报（CTI）以支持漏洞评估和事件响应。尽管近期研究表明LLMs可支持威胁分析、漏洞检测和入侵防御等多种CTI任务，但在实际部署中仍存在显著性能差距。本文探讨了LLMs在CTI领域的内在脆弱性，重点关注源于威胁格局本身而非模型架构的挑战。通过跨多个CTI基准和真实世界威胁报告的大规模评估，我们提出了一种新颖的分类方法，该方法整合了分层、自回归优化和人在环路监督以可靠地分析失败案例。通过大量实验和人工审查，我们揭示了限制LLMs有效支持CTI的三大根本脆弱性：虚假相关性、矛盾知识和受限泛化能力。随后，我们为设计更稳健的LLM驱动CTI系统提供了可操作的见解，以促进未来研究。
Link: http://arxiv.org/abs/2510.01552v1
Updated: 2025-10-02T00:49:20Z

7: Rethinking KL Regularization in RLHF: From Value Estimation to Gradient  Optimization
Authors: ['Kezhao Liu', 'Jason Klein Liu', 'Mingtao Chen', 'Yiming Liu']
Summary: Reinforcement Learning from Human Feedback (RLHF) leverages aKullback-Leibler (KL) divergence loss to stabilize training and preventoverfitting. However, in methods such as GRPO, its implementation may be guidedby principles from numerical value estimation-a practice that overlooks theterm's functional role as an optimization loss. To analyze this issue, weestablish a unified framework that connects two seemingly distinctimplementation styles: using the mathematical term $k_n$ as a detachedcoefficient for the policy's score function ('$k_n$ in reward') or as a directloss function through which gradients are propagated ('$k_n$ as loss'). We showthat the latter can always be analyzed via an equivalent gradient coefficientin the former, unifying the two perspectives. Through this framework, we provethat the conventional '$k_1$ in reward' (like in PPO) is the principled lossfor Reverse KL (RKL) regularization. We further establish a key finding: underon-policy conditions, the '$k_2$ as loss' formulation is, in fact,gradient-equivalent to '$k_1$ in reward'. This equivalence, first proven in ourwork, identifies both as the theoretically sound implementations of the RKLobjective. In contrast, we show that the recently adopted '$k_3$ as loss' (likein GRPO) is merely a first-order, biased approximation of the principled loss.Furthermore, we argue that common off-policy implementations of '$k_n$ as loss'methods are biased due to neglected importance sampling, and we propose aprincipled correction. Our findings provide a comprehensive, gradient-basedrationale for choosing and correctly implementing KL regularization, paving theway for more robust and effective RLHF systems.
摘要: 基于人类反馈的强化学习（RLHF）利用Kullback-Leibler（KL）散度损失来稳定训练并防止过拟合。然而，在GRPO等方法中，其实现可能受数值估计原则的指导——这种做法忽视了该术语作为优化损失的功能作用。为分析此问题，我们建立了一个统一框架，连接两种看似不同的实现风格：将数学项$k_n$作为策略评分函数的独立系数（“$k_n$作为奖励”）或作为直接传递梯度的损失函数（“$k_n$作为损失”）。我们证明后者总可通过前者的等效梯度系数进行分析，从而统一两种视角。通过该框架，我们证明传统的“$k_1$作为奖励”（如PPO中）是反向KL（RKL）正则化的原则性损失。我们进一步确立一个关键发现：在同策略条件下，“$k_2$作为损失”形式实际上与“$k_1$作为奖励”梯度等效。这一首次在本工作中证明的等价性，将两者均识别为RKL目标的理论合理实现。相反，我们证明近期采用的“$k_3$作为损失”（如GRPO中）仅是原则性损失的一阶有偏近似。此外，我们论证“$k_n$作为损失”方法的常见异策略实现因忽略重要性采样而产生偏差，并提出原则性修正。我们的发现为选择和正确实现KL正则化提供了全面的梯度理论基础，为构建更鲁棒、有效的RLHF系统铺平道路。
Link: http://arxiv.org/abs/2510.01555v1
Updated: 2025-10-02T01:00:02Z

8: InvThink: Towards AI Safety via Inverse Reasoning
Authors: ['Yubin Kim', 'Taehan Kim', 'Eugene Park', 'Chunjong Park', 'Cynthia Breazeal', 'Daniel McDuff', 'Hae Won Park']
Summary: We present InvThink, a simple yet powerful approach that gives large languagemodels (LLMs) the capability of inverse thinking: reasoning through failuremodes before generating responses. Unlike existing safety alignment methodsthat optimize directly for safe response, InvThink instructs models to 1)enumerate potential harms, 2) analyze their consequences, and 3) generate safeoutputs that proactively avoid these risks. Our method reveals three keyfindings: (i) safety improvements show stronger scaling with model sizecompared to existing safety methods. (ii) InvThink mitigates safety tax; bytraining models to systematically consider failure modes, it preserves generalreasoning capabilities on standard benchmarks. (iii) beyond general safetytasks, InvThink excels in high-stakes domains including external-facing(medicine, finance, law) and agentic (blackmail, murder) risk scenarios,achieving up to 15.7% reduction in harmful responses compared to baselinemethods like SafetyPrompt. We further implement InvThink via supervisedfine-tuning, and reinforcement learning across three LLM families. Theseresults suggest that inverse reasoning provides a scalable and generalizablepath toward safer, more capable language models.
摘要: 我们提出了InvThink，一种简单而强大的方法，它赋予大型语言模型（LLMs）逆向思考的能力：在生成响应之前，通过失败模式进行推理。与现有直接优化安全响应的安全对齐方法不同，InvThink指示模型1）列举潜在危害，2）分析其后果，以及3）生成主动规避这些风险的安全输出。我们的方法揭示了三个关键发现：（i）与现有安全方法相比，安全改进随模型规模扩大而表现更强的扩展性。（ii）InvThink减轻了安全税；通过训练模型系统性地考虑失败模式，它在标准基准上保留了通用推理能力。（iii）除了通用安全任务，InvThink在高风险领域表现出色，包括面向外部的（医学、金融、法律）和代理性的（勒索、谋杀）风险场景，与SafetyPrompt等基线方法相比，有害响应减少了高达15.7%。我们进一步通过监督微调和强化学习在三个大型语言模型家族中实现了InvThink。这些结果表明，逆向推理为构建更安全、更强大的语言模型提供了一种可扩展且可推广的路径。
Link: http://arxiv.org/abs/2510.01569v1
Updated: 2025-10-02T01:26:53Z

9: From Supervision to Exploration: What Does Protein Language Model Learn  During Reinforcement Learning?
Authors: ['Hanqun Cao', 'Hongrui Zhang', 'Junde Xu', 'Zhou Zhang', 'Lingdong Shen', 'Minghao Sun', 'Ge Liu', 'Jinbo Xu', 'Wu-Jun Li', 'Jinren Ni', 'Cesar de la Fuente-Nunez', 'Tianfan Fu', 'Yejin Choi', 'Pheng-Ann Heng', 'Fang Wu']
Summary: Protein language models (PLMs) have advanced computational protein sciencethrough large-scale pretraining and scalable architectures. In parallel,reinforcement learning (RL) has broadened exploration and enabled precisemulti-objective optimization in protein design. Yet whether RL can push PLMsbeyond their pretraining priors to uncover latent sequence-structure-functionrules remains unclear. We address this by pairing RL with PLMs across fourdomains: antimicrobial peptide design, kinase variant optimization, antibodyengineering, and inverse folding. Using diverse RL algorithms and modelclasses, we ask if RL improves sampling efficiency and, more importantly, if itreveals capabilities not captured by supervised learning. Across benchmarks, RLconsistently boosts success rates and sample efficiency. Performance follows athree-factor interaction: task headroom, reward fidelity, and policy capacityjointly determine gains. When rewards are accurate and informative, policieshave sufficient capacity, and tasks leave room beyond supervised baselines,improvements scale; when rewards are noisy or capacity is constrained, gainssaturate despite exploration. This view yields practical guidance for RL inprotein design: prioritize reward modeling and calibration before scalingpolicy size, match algorithm and regularization strength to task difficulty,and allocate capacity where marginal gains are largest. Implementation isavailable at https://github.com/chq1155/RL-PLM.
摘要: 蛋白质语言模型（PLMs）通过大规模预训练和可扩展架构推进了计算蛋白质科学的发展。与此同时，强化学习（RL）拓宽了探索范围，并在蛋白质设计中实现了精确的多目标优化。然而，RL是否能推动PLMs超越其预训练先验知识，以揭示潜在的序列-结构-功能规律，仍不清楚。我们通过将RL与PLMs在四个领域相结合来解决这个问题：抗菌肽设计、激酶变体优化、抗体工程和逆向折叠。利用多样的RL算法和模型类别，我们探究RL是否提升了采样效率，更重要的是，它是否揭示了监督学习未能捕捉的能力。在各项基准测试中，RL持续提高了成功率和采样效率。性能遵循一个三因素交互作用：任务潜力、奖励保真度和策略容量共同决定了增益。当奖励准确且信息丰富、策略容量充足且任务在监督学习基线之外留有提升空间时，改进会随之扩大；而当奖励存在噪声或容量受限时，尽管进行了探索，增益仍会饱和。这一观点为蛋白质设计中的RL应用提供了实践指导：在扩大策略规模之前，优先进行奖励建模和校准，根据任务难度匹配算法和正则化强度，并在边际增益最大的地方分配容量。实现代码可在 https://github.com/chq1155/RL-PLM 获取。
Link: http://arxiv.org/abs/2510.01571v1
Updated: 2025-10-02T01:31:10Z

10: Synthetic Prefixes to Mitigate Bias in Real-Time Neural Query  Autocomplete
Authors: ['Adithya Rajan', 'Xiaoyu Liu', 'Prateek Verma', 'Vibhu Arora']
Summary: We introduce a data-centric approach for mitigating presentation bias inreal-time neural query autocomplete systems through the use of syntheticprefixes. These prefixes are generated from complete user queries collectedduring regular search sessions where autocomplete was not active. This allowsus to enrich the training data for learning to rank models with more diverseand less biased examples. This method addresses the inherent bias in engagementsignals collected from live query autocomplete interactions, where modelsuggestions influence user behavior. Our neural ranker is optimized forreal-time deployment under strict latency constraints and incorporates a richset of features, including query popularity, seasonality, fuzzy match scores,and contextual signals such as department affinity, device type, and verticalalignment with previous user queries. To support efficient training, weintroduce a task-specific simplification of the listwise loss, reducingcomputational complexity from $O(n^2)$ to $O(n)$ by leveraging the queryautocomplete structure of having only one ground-truth selection per prefix.Deployed in a large-scale e-commerce setting, our system demonstratesstatistically significant improvements in user engagement, as measured by meanreciprocal rank and related metrics. Our findings show that synthetic prefixesnot only improve generalization but also provide a scalable path toward biasmitigation in other low-latency ranking tasks, including related searches andquery recommendations.
摘要: 我们介绍了一种以数据为中心的方法，通过使用合成前缀来缓解实时神经查询自动补全系统中的呈现偏差。这些前缀是从常规搜索会话中收集的完整用户查询生成的，在这些会话中自动补全功能未激活。这使我们能够用更多样化和更少偏差的示例来丰富学习排序模型的训练数据。该方法解决了从实时查询自动补全交互中收集的参与信号中固有的偏差，其中模型建议会影响用户行为。我们的神经排序器针对严格延迟约束下的实时部署进行了优化，并包含一组丰富的特征，包括查询流行度、季节性、模糊匹配分数以及上下文信号，如部门亲和力、设备类型和与先前用户查询的垂直对齐。为了支持高效训练，我们引入了一种针对任务的列表式损失的简化，通过利用每个前缀只有一个真实选择的查询自动补全结构，将计算复杂度从$O(n^2)$降低到$O(n)$。在大规模电子商务环境中部署后，我们的系统在用户参与度方面表现出统计显著的改进，这通过平均倒数排名和相关指标来衡量。我们的研究结果表明，合成前缀不仅提高了泛化能力，还为在其他低延迟排序任务（包括相关搜索和查询推荐）中缓解偏差提供了一条可扩展的路径。
Link: http://arxiv.org/abs/2510.01574v1
Updated: 2025-10-02T01:44:44Z

11: Guiding Multimodal Large Language Models with Blind and Low Vision  People Visual Questions for Proactive Visual Interpretations
Authors: ['Ricardo Gonzalez Penuela', 'Felipe Arias-Russi', 'Victor Capriles']
Summary: Multimodal large language models (MLLMs) have been integrated into visualinterpretation applications to support Blind and Low Vision (BLV) users becauseof their accuracy and ability to provide rich, human-like interpretations.However, these applications often default to comprehensive, lengthydescriptions regardless of context. This leads to inefficient exchanges, asusers must go through irrelevant details rather than receiving the specificinformation they are likely to seek. To deliver more contextually-relevantinformation, we developed a system that draws on historical BLV usersquestions. When given an image, our system identifies similar past visualcontexts from the VizWiz-LF dataset and uses the associated questions to guidethe MLLM generate descriptions more relevant to BLV users. An evaluation withthree human labelers who revised 92 context-aware and context-free descriptionsshowed that context-aware descriptions anticipated and answered users'questions in 76.1% of cases (70 out of 92) and were preferred in 54.4% ofcomparisons (50 out of 92). Our paper reviews, and data analysis are publiclyavailable in a Github repository athttps://github.com/rgonzalezp/guiding-multimodal-large-language-models-with-blind-and-low-vision-people-visual-questions .
摘要: 多模态大语言模型（MLLM）因其准确性和提供丰富、类人化描述的能力，已被整合到视觉解读应用中，以支持盲人和低视力（BLV）用户。然而，这些应用通常默认提供全面且冗长的描述，而不考虑具体情境。这导致信息交换效率低下，因为用户必须浏览无关细节，而非获取他们可能寻求的特定信息。为提供更贴合情境的信息，我们开发了一个系统，该系统利用了历史上BLV用户提出的问题。当给定一张图像时，我们的系统会从VizWiz-LF数据集中识别相似的过往视觉情境，并利用相关问题引导MLLM生成更贴合BLV用户需求的描述。一项由三名标注员参与、修订了92份情境感知描述和非情境感知描述的评估显示，情境感知描述在76.1%的案例中（70/92）预判并回答了用户的问题，并在54.4%的比较中（50/92）更受青睐。我们的论文综述和数据分析已在GitHub仓库中公开，网址为https://github.com/rgonzalezp/guiding-multimodal-large-language-models-with-blind-and-low-vision-people-visual-questions。
Link: http://arxiv.org/abs/2510.01576v1
Updated: 2025-10-02T01:48:51Z

12: Think Right: Learning to Mitigate Under-Over Thinking via Adaptive,  Attentive Compression
Authors: ['Joykirat Singh', 'Justin Chih-Yao Chen', 'Archiki Prasad', 'Elias Stengel-Eskin', 'Akshay Nambi', 'Mohit Bansal']
Summary: Recent thinking models solve complex reasoning tasks by scaling test-timecompute, but this scaling must be allocated in line with task difficulty. Onone hand, short reasoning (underthinking) leads to errors on harder problemsthat require extended reasoning steps; but, excessively long reasoning(overthinking) can be token-inefficient, generating unnecessary steps evenafter reaching a correct intermediate solution. We refer to this asunder-adaptivity, where the model fails to modulate its response lengthappropriately given problems of varying difficulty. To address under-adaptivityand strike a balance between under- and overthinking, we propose TRAAC (ThinkRight with Adaptive, Attentive Compression), an online post-training RL methodthat leverages the model's self-attention over a long reasoning trajectory toidentify important steps and prune redundant ones. TRAAC also estimatesdifficulty and incorporates it into training rewards, thereby learning toallocate reasoning budget commensurate with example difficulty. Our approachimproves accuracy, reduces reasoning steps, and enables adaptive thinkingcompared to base models and other RL baselines. Across a variety of tasks(AIME, AMC, GPQA-D, BBEH), TRAAC (Qwen3-4B) achieves an average absoluteaccuracy gain of 8.4% with a relative reduction in reasoning length of 36.8%compared to the base model, and a 7.9% accuracy gain paired with a 29.4% lengthdrop compared to the best RL baseline. TRAAC also shows strong generalization:although our models are trained on math datasets, they show accuracy andefficiency gains on out-of-distribution non-math datasets like GPQA-D, BBEH,and OptimalThinkingBench. Our analysis further verifies that TRAAC providesfine-grained adjustments to thinking budget based on difficulty and that acombination of task-difficulty calibration and attention-based compressionyields gains across diverse tasks.
摘要: 近期，思维模型通过扩展测试时的计算量来解决复杂推理任务，但这种扩展必须与任务难度相匹配。一方面，过短的推理（思考不足）会导致在需要更多推理步骤的难题上出错；但，过长的推理（过度思考）则可能造成token效率低下，即使在得出正确中间解后仍会生成不必要的步骤。我们将此称为适应性不足，即模型在面对不同难度的问题时，无法适当调整其响应长度。为解决适应性不足并在思考不足与过度思考之间取得平衡，我们提出了TRAAC（通过自适应、注意力压缩实现正确思考），这是一种在线后训练强化学习方法，利用模型对长推理轨迹的自注意力来识别重要步骤并修剪冗余步骤。TRAAC还评估任务难度并将其纳入训练奖励，从而学习分配与示例难度相称的推理预算。与基础模型及其他强化学习基线相比，我们的方法提高了准确率、减少了推理步骤，并实现了自适应思维。在多项任务（AIME、AMC、GPQA-D、BBEH）中，TRAAC（Qwen3-4B）相比基础模型平均绝对准确率提升8.4%，推理长度相对减少36.8%；相比最佳强化学习基线，准确率提升7.9%的同时长度降低29.4%。TRAAC还展现出强大的泛化能力：尽管我们的模型在数学数据集上训练，但在GPQA-D、BBEH及OptimalThinkingBench等分布外的非数学数据集上仍实现了准确率和效率的提升。我们的分析进一步验证，TRAAC能根据难度对思维预算进行细粒度调整，且任务难度校准与基于注意力的压缩相结合可在多样化任务中带来增益。
Link: http://arxiv.org/abs/2510.01581v1
Updated: 2025-10-02T02:00:20Z

13: AdvEvo-MARL: Shaping Internalized Safety through Adversarial  Co-Evolution in Multi-Agent Reinforcement Learning
Authors: ['Zhenyu Pan', 'Yiting Zhang', 'Zhuo Liu', 'Yolo Yunlong Tang', 'Zeliang Zhang', 'Haozheng Luo', 'Yuwei Han', 'Jianshu Zhang', 'Dennis Wu', 'Hong-Yu Chen', 'Haoran Lu', 'Haoyang Fang', 'Manling Li', 'Chenliang Xu', 'Philip S. Yu', 'Han Liu']
Summary: LLM-based multi-agent systems excel at planning, tool use, and rolecoordination, but their openness and interaction complexity also expose them tojailbreak, prompt-injection, and adversarial collaboration. Existing defensesfall into two lines: (i) self-verification that asks each agent to pre-filterunsafe instructions before execution, and (ii) external guard modules thatpolice behaviors. The former often underperforms because a standalone agentlacks sufficient capacity to detect cross-agent unsafe chains anddelegation-induced risks; the latter increases system overhead and creates asingle-point-of-failure-once compromised, system-wide safety collapses, andadding more guards worsens cost and complexity. To solve these challenges, wepropose AdvEvo-MARL, a co-evolutionary multi-agent reinforcement learningframework that internalizes safety into task agents. Rather than relying onexternal guards, AdvEvo-MARL jointly optimizes attackers (which synthesizeevolving jailbreak prompts) and defenders (task agents trained to bothaccomplish their duties and resist attacks) in adversarial learningenvironments. To stabilize learning and foster cooperation, we introduce apublic baseline for advantage estimation: agents within the same functionalgroup share a group-level mean-return baseline, enabling lower-variance updatesand stronger intra-group coordination. Across representative attack scenarios,AdvEvo-MARL consistently keeps attack-success rate (ASR) below 20%, whereasbaselines reach up to 38.33%, while preserving-and sometimes improving-taskaccuracy (up to +3.67% on reasoning tasks). These results show that safety andutility can be jointly improved without relying on extra guard agents or addedsystem overhead.
摘要: 基于大语言模型的多智能体系统在规划、工具使用和角色协调方面表现出色，但其开放性和交互复杂性也使其面临越狱、提示注入和对抗性协作等风险。现有防御措施分为两类：（i）自我验证，即要求每个智能体在执行指令前预先过滤不安全指令；（ii）外部守护模块，用于监控行为。前者效果往往不佳，因为单个智能体缺乏足够的能力来检测跨智能体的不安全链和委托引发的风险；后者则会增加系统开销，并造成单点故障——一旦被攻破，整个系统的安全性将崩溃，而增加更多守护模块会进一步加剧成本和复杂性。为解决这些挑战，我们提出了AdvEvo-MARL，一种将安全性内化于任务智能体的协同进化多智能体强化学习框架。AdvEvo-MARL不依赖外部守护模块，而是在对抗性学习环境中联合优化攻击者（用于生成不断演化的越狱提示）和防御者（经过训练以完成任务并抵御攻击的任务智能体）。为稳定学习并促进协作，我们引入了一种用于优势估计的公共基线：同一功能组内的智能体共享组级平均回报基线，从而实现更低方差的更新和更强的组内协调。在各类代表性攻击场景中，AdvEvo-MARL始终将攻击成功率（ASR）控制在20%以下，而基线方法的攻击成功率高达38.33%，同时保持甚至提升了任务准确性（在推理任务上最高提升3.67%）。这些结果表明，无需依赖额外的守护智能体或增加系统开销，安全性和实用性即可得到共同提升。
Link: http://arxiv.org/abs/2510.01586v1
Updated: 2025-10-02T02:06:30Z

14: Enhancing Noise Robustness of Parkinson's Disease Telemonitoring via  Contrastive Feature Augmentation
Authors: ['Ziming Tang', 'Chengbin Hou', 'Tianyu Zhang', 'Bangxu Tian', 'Jinbao Wang', 'Hairong Lv']
Summary: Parkinson's disease (PD) is one of the most common neurodegenerativedisorder. PD telemonitoring emerges as a novel assessment modality enablingself-administered at-home tests of Unified Parkinson's Disease Rating Scale(UPDRS) scores, enhancing accessibility for PD patients. However, three typesof noise would occur during measurements: (1) patient-induced measurementinaccuracies, (2) environmental noise, and (3) data packet loss duringtransmission, resulting in higher prediction errors. To address thesechallenges, NoRo, a noise-robust UPDRS prediction framework is proposed. First,the original speech features are grouped into ordered bins, based on thecontinuous values of a selected feature, to construct contrastive pairs.Second, the contrastive pairs are employed to train a multilayer perceptronencoder for generating noise-robust features. Finally, these features areconcatenated with the original features as the augmented features, which arethen fed into the UPDRS prediction models. Notably, we further introduces anovel evaluation approach with customizable noise injection module, andextensive experiments show that NoRo can successfully enhance the noiserobustness of UPDRS prediction across various downstream prediction modelsunder different noisy environments.
摘要: 帕金森病（PD）是最常见的神经退行性疾病之一。PD远程监测作为一种新型评估模式应运而生，它使患者能够在家自行进行统一帕金森病评定量表（UPDRS）评分测试，从而提高了PD患者的可及性。然而，在测量过程中会出现三类噪声：（1）患者引起的测量误差，（2）环境噪声，以及（3）传输过程中的数据包丢失，从而导致更高的预测误差。为应对这些挑战，我们提出了NoRo，一种抗噪的UPDRS预测框架。首先，根据选定特征的连续值，将原始语音特征分组为有序的区间，以构建对比对。其次，利用这些对比对训练一个多层感知器编码器，以生成抗噪特征。最后，将这些特征与原始特征拼接作为增强特征，然后输入到UPDRS预测模型中。值得注意的是，我们进一步引入了一种具有可定制噪声注入模块的新型评估方法，大量实验表明，在不同噪声环境下，NoRo能够成功增强多种下游预测模型的UPDRS预测抗噪能力。
Link: http://arxiv.org/abs/2510.01588v1
Updated: 2025-10-02T02:07:41Z

15: A Comparison of Independent and Joint Fine-tuning Strategies for  Retrieval-Augmented Generation
Authors: ['Neal Gregory Lawton', 'Alfy Samuel', 'Anoop Kumar', 'Daben Liu']
Summary: A Comparison of Independent and Joint Fine-tuning Strategies forRetrieval-Augmented Generation Download PDF Neal Gregory Lawton, Alfy Samuel,Anoop Kumar, Daben Liu Published: 20 Aug 2025, Last Modified: 17 Sept 2025EMNLP2025 FindingsConference, Publication Chairs, AuthorsRevisionsBibTeXCC BY 4.0Keywords: Retrieval-Augmented Generation (RAG), Large Language Models (LLMs),Fine-tuning, Question Answering, Joint fine-tuning TL;DR: We evaluate andcompare strategies for fine-tuning Retrieval Augmented Generation (RAG)pipelines, including independent fine-tuning, joint fine-tuning, and two-phasefine-tuning. Abstract: Retrieval augmented generation (RAG) is a popularframework for question answering that is powered by two large language models(LLMs): an embedding model that retrieves context documents from a databasethat are relevant to a given question, and a generator model that uses theretrieved context to generate an answer to the question. Both the embedding andgenerator models can be fine-tuned to increase performance of a RAG pipeline ona new task, but multiple fine-tuning strategies exist with different costs andbenefits. In this paper, we evaluate and compare several RAG fine-tuningstrategies, including independent, joint, and two-phase fine-tuning. In ourexperiments, we observe that all of these strategies achieve about equalimprovement in EM and F1 generation quality metrics, although they havesignificantly different computational costs. We conclude the optimalfine-tuning strategy to use depends on whether the training dataset includescontext labels and whether a grid search over the learning rates for theembedding and generator models is required.
摘要: 检索增强生成的独立与联合微调策略比较 下载PDF Neal Gregory Lawton, Alfy Samuel, Anoop Kumar, Daben Liu 发表日期：2025年8月20日，最后修改日期：2025年9月17日 EMNLP2025 Findings会议，出版主席，作者 修订 BibTeX CC BY 4.0 关键词：检索增强生成（RAG），大型语言模型（LLMs），微调，问答，联合微调 TL;DR：我们评估并比较了用于微调检索增强生成（RAG）管道的策略，包括独立微调、联合微调和两阶段微调。 摘要：检索增强生成（RAG）是一种流行的问答框架，由两个大型语言模型（LLMs）驱动：一个嵌入模型，用于从数据库中检索与给定问题相关的上下文文档；一个生成器模型，利用检索到的上下文生成问题的答案。嵌入模型和生成器模型都可以进行微调，以提高RAG管道在新任务上的性能，但存在多种具有不同成本和效益的微调策略。在本文中，我们评估并比较了几种RAG微调策略，包括独立微调、联合微调和两阶段微调。在我们的实验中，我们观察到所有这些策略在EM和F1生成质量指标上均取得了大致相等的改进，尽管它们的计算成本差异显著。我们得出结论，使用的最佳微调策略取决于训练数据集是否包含上下文标签，以及是否需要对嵌入模型和生成器模型的学习率进行网格搜索。
Link: http://arxiv.org/abs/2510.01600v1
Updated: 2025-10-02T02:30:28Z

16: Bridging Collaborative Filtering and Large Language Models with Dynamic  Alignment, Multimodal Fusion and Evidence-grounded Explanations
Authors: ['Bo Ma', 'LuYao Liu', 'Simon Lau', 'Chandler Yuan', 'and XueY Cui', 'Rosie Zhang']
Summary: Recent research has explored using Large Language Models for recommendationtasks by transforming user interaction histories and item metadata into textprompts, then having the LLM produce rankings or recommendations. A promisingapproach involves connecting collaborative filtering knowledge to LLMrepresentations through compact adapter networks, which avoids expensivefine-tuning while preserving the strengths of both components. Yet severalchallenges persist in practice: collaborative filtering models often use staticsnapshots that miss rapidly changing user preferences; many real-world itemscontain rich visual and audio content beyond textual descriptions; and currentsystems struggle to provide trustworthy explanations backed by concreteevidence. Our work introduces \model{}, a framework that tackles theselimitations through three key innovations. We develop an online adaptationmechanism that continuously incorporates new user interactions throughlightweight modules, avoiding the need to retrain large models. We create aunified representation that seamlessly combines collaborative signals withvisual and audio features, handling cases where some modalities may beunavailable. Finally, we design an explanation system that groundsrecommendations in specific collaborative patterns and item attributes,producing natural language rationales users can verify. Our approach maintainsthe efficiency of frozen base models while adding minimal computationaloverhead, making it practical for real-world deployment.
摘要: 近期研究探索了将大型语言模型用于推荐任务，其方法是将用户交互历史和项目元数据转换为文本提示，然后让大型语言模型生成排序或推荐。一种有前景的方法是通过紧凑的适配器网络将协同过滤知识与大型语言模型表示相结合，从而避免了昂贵的微调，同时保留了两者各自的优势。然而，在实践中仍存在若干挑战：协同过滤模型通常使用静态快照，无法捕捉快速变化的用户偏好；许多现实世界的项目除了文本描述外，还包含丰富的视觉和音频内容；现有系统难以提供由具体证据支撑的可信解释。我们的工作引入了\model{}框架，该框架通过三项关键创新解决了这些局限性。我们开发了一种在线适应机制，通过轻量级模块持续整合新的用户交互，从而无需重新训练大型模型。我们创建了一种统一表示，能够无缝融合协同信号与视觉和音频特征，并处理某些模态可能缺失的情况。最后，我们设计了一个解释系统，将推荐建立在特定的协同模式和项目属性之上，生成用户可以验证的自然语言理由。我们的方法在保持冻结基础模型效率的同时，仅增加了极小的计算开销，使其在实际部署中具有实用性。
Link: http://arxiv.org/abs/2510.01606v1
Updated: 2025-10-02T02:43:24Z

17: AgentRec: Next-Generation LLM-Powered Multi-Agent Collaborative  Recommendation with Adaptive Intelligence
Authors: ['Bo Ma', 'Hang Li', 'ZeHua Hu', 'XiaoFan Gui', 'LuYao Liu', 'Simon Lau']
Summary: Interactive conversational recommender systems have gained significantattention for their ability to capture user preferences through naturallanguage interactions. However, existing approaches face substantial challengesin handling dynamic user preferences, maintaining conversation coherence, andbalancing multiple ranking objectives simultaneously. This paper introducesAgentRec, a next-generation LLM-powered multi-agent collaborativerecommendation framework that addresses these limitations through hierarchicalagent networks with adaptive intelligence. Our approach employs specializedLLM-powered agents for conversation understanding, preference modeling, contextawareness, and dynamic ranking, coordinated through an adaptive weightingmechanism that learns from interaction patterns. We propose a three-tierlearning strategy combining rapid response for simple queries, intelligentreasoning for complex preferences, and deep collaboration for challengingscenarios. Extensive experiments on three real-world datasets demonstrate thatAgentRec achieves consistent improvements over state-of-the-art baselines, with2.8\% enhancement in conversation success rate, 1.9\% improvement inrecommendation accuracy (NDCG@10), and 3.2\% better conversation efficiencywhile maintaining comparable computational costs through intelligent agentcoordination.
摘要: 交互式对话推荐系统因其能够通过自然语言交互捕捉用户偏好而获得了广泛关注。然而，现有方法在处理动态用户偏好、维持对话连贯性以及同时平衡多个排序目标方面面临着重大挑战。本文介绍了AgentRec，这是一种下一代由大型语言模型驱动的多智能体协作推荐框架，它通过具有自适应智能的分层智能体网络来解决这些局限性。我们的方法采用专门的大型语言模型驱动的智能体，分别负责对话理解、偏好建模、情境感知和动态排序，并通过一个从交互模式中学习的自适应权重机制进行协调。我们提出了一种三层学习策略，结合了对简单查询的快速响应、对复杂偏好的智能推理以及对挑战性场景的深度协作。在三个真实世界数据集上的大量实验表明，与最先进的基线模型相比，AgentRec取得了一致的改进，对话成功率提升了2.8%，推荐准确度（NDCG@10）提高了1.9%，对话效率提升了3.2%，同时通过智能体协调保持了相当的计算成本。
Link: http://arxiv.org/abs/2510.01609v1
Updated: 2025-10-02T02:47:11Z

18: PychoBench: Evaluating the Psychology Intelligence of Large Language  Models
Authors: ['Min Zeng']
Summary: Large Language Models (LLMs) have demonstrated remarkable success across awide range of industries, primarily due to their impressive generativeabilities. Yet, their potential in applications requiring cognitive abilities,such as psychological counseling, remains largely untapped. This paperinvestigates the key question: Can LLMs be effectively applied to psychologicalcounseling? To determine whether an LLM can effectively take on the role of apsychological counselor, the first step is to assess whether it meets thequalifications required for such a role, namely the ability to pass the U.S.National Counselor Certification Exam (NCE). This is because, just as a humancounselor must pass a certification exam to practice, an LLM must demonstratesufficient psychological knowledge to meet the standards required for such arole. To address this, we introduce PsychoBench, a benchmark grounded inU.S.national counselor examinations, a licensure test for professionalcounselors that requires about 70% accuracy to pass. PsychoBench comprisesapproximately 2,252 carefully curated single-choice questions, crafted torequire deep understanding and broad enough to cover various sub-disciplines ofpsychology. This benchmark provides a comprehensive assessment of an LLM'sability to function as a counselor. Our evaluation shows that advanced modelssuch as GPT-4o, Llama3.3-70B, and Gemma3-27B achieve well above the passingthreshold, while smaller open-source models (e.g., Qwen2.5-7B, Mistral-7B)remain far below it. These results suggest that only frontier LLMs arecurrently capable of meeting counseling exam standards, highlighting both thepromise and the challenges of developing psychology-oriented LLMs.
摘要: 大型语言模型（LLMs）已在众多行业展现出显著的成功，主要归功于其卓越的生成能力。然而，它们在需要认知能力的应用（如心理咨询）中的潜力，在很大程度上仍未被开发。本文探讨了一个关键问题：LLMs能否有效应用于心理咨询？为判断LLM是否能有效胜任心理咨询师的角色，首要步骤是评估其是否满足该角色所需的资质，即通过美国国家咨询师认证考试（NCE）的能力。这是因为，正如人类咨询师必须通过认证考试才能执业，LLM也必须展示出足够的心理学知识以达到该角色的标准要求。为此，我们引入了PsychoBench，一个基于美国国家咨询师考试的基准测试，这是一项专业咨询师执照考试，要求约70%的准确率才能通过。PsychoBench包含约2,252道精心策划的单选题，这些题目旨在考察深度理解，且覆盖范围足够广泛，涵盖心理学的各个子学科。该基准测试为评估LLM作为咨询师履职的能力提供了全面的衡量标准。我们的评估显示，GPT-4o、Llama3.3-70B和Gemma3-27B等先进模型的得分远超及格线，而较小的开源模型（如Qwen2.5-7B、Mistral-7B）则远低于此。这些结果表明，目前只有前沿LLMs能够达到心理咨询考试的标准，这既凸显了开发心理学导向型LLMs的潜力，也揭示了其中的挑战。
Link: http://arxiv.org/abs/2510.01611v1
Updated: 2025-10-02T02:49:06Z

19: RAG-BioQA Retrieval-Augmented Generation for Long-Form Biomedical  Question Answering
Authors: ['Lovely Yeswanth Panchumarthi', 'Sai Prasad Gudari', 'Atharva Negi', 'Praveen Raj Budime', 'Harsit Upadhya']
Summary: The exponential growth of biomedical literature creates significantchallenges for accessing precise medical information. Current biomedicalquestion-answering systems primarily focus on short-form answers, failing toprovide the comprehensive explanations necessary for clinical decision-making.We present RAG-BioQA, a novel framework combining retrieval-augmentedgeneration with domain-specific fine-tuning to produce evidence-based,long-form biomedical answers. Our approach integrates BioBERT embeddings withFAISS indexing and compares various re-ranking strategies (BM25, ColBERT,MonoT5) to optimize context selection before synthesizing evidence through afine-tuned T5 model. Experimental results on the PubMedQA dataset showsignificant improvements over baselines, with our best model achievingsubstantial gains across BLEU, ROUGE, and METEOR metrics, advancing the stateof accessible, evidence-based biomedical knowledge retrieval.
摘要: 生物医学文献的指数级增长为获取精准医疗信息带来了重大挑战。当前生物医学问答系统主要侧重于简短答案，未能提供临床决策所需的全方面解释。我们提出了RAG-BioQA，一种新颖的框架，结合了检索增强生成与领域特定微调，以生成基于证据的长篇生物医学答案。我们的方法将BioBERT嵌入与FAISS索引相结合，并比较了多种重排序策略（BM25、ColBERT、MonoT5），以在通过微调的T5模型整合证据前优化上下文选择。在PubMedQA数据集上的实验结果表明，相较于基线模型有显著改进，我们的最佳模型在BLEU、ROUGE和METEOR指标上均取得了大幅提升，推动了可获取的、基于证据的生物医学知识检索的发展。
Link: http://arxiv.org/abs/2510.01612v1
Updated: 2025-10-02T02:49:09Z

20: Learning to Decide with Just Enough: Information-Theoretic Context  Summarization for CDMPs
Authors: ['Peidong Liu', 'Junjiang Lin', 'Shaowen Wang', 'Yao Xu', 'Haiqing Li', 'Xuhao Xie', 'Siyi Wu', 'Hao Li']
Summary: Contextual Markov Decision Processes (CMDPs) offer a framework for sequentialdecision-making under external signals, but existing methods often fail togeneralize in high-dimensional or unstructured contexts, resulting in excessivecomputation and unstable performance. We propose an information-theoreticsummarization approach that uses large language models (LLMs) to compresscontextual inputs into low-dimensional, semantically rich summaries. Thesesummaries augment states by preserving decision-critical cues while reducingredundancy. Building on the notion of approximate context sufficiency, weprovide, to our knowledge, the first regret bounds and a latency-entropytrade-off characterization for CMDPs. Our analysis clarifies howinformativeness impacts computational cost. Experiments across discrete,continuous, visual, and recommendation benchmarks show that our methodoutperforms raw-context and non-context baselines, improving reward, successrate, and sample efficiency, while reducing latency and memory usage. Thesefindings demonstrate that LLM-based summarization offers a scalable andinterpretable solution for efficient decision-making in context-rich,resource-constrained environments.
摘要: 上下文马尔可夫决策过程（CMDP）为外部信号下的序列决策提供了一个框架，但现有方法在高维或非结构化上下文中往往难以泛化，导致计算量过大和性能不稳定。我们提出了一种信息理论摘要方法，利用大型语言模型（LLM）将上下文输入压缩为低维、语义丰富的摘要。这些摘要通过保留决策关键线索同时减少冗余来增强状态。基于近似上下文充分性的概念，据我们所知，我们首次为CMDP提供了遗憾界和延迟-熵权衡表征。我们的分析阐明了信息量如何影响计算成本。在离散、连续、视觉和推荐基准上的实验表明，我们的方法优于原始上下文和非上下文基线，提高了奖励、成功率和样本效率，同时降低了延迟和内存使用。这些发现表明，基于LLM的摘要为上下文丰富、资源受限环境中的高效决策提供了一种可扩展且可解释的解决方案。
Link: http://arxiv.org/abs/2510.01620v1
Updated: 2025-10-02T02:52:24Z

21: LLM4Rec: Large Language Models for Multimodal Generative Recommendation  with Causal Debiasing
Authors: ['Bo Ma', 'Hang Li', 'ZeHua Hu', 'XiaoFan Gui', 'LuYao Liu', 'Simon Lau']
Summary: Contemporary generative recommendation systems face significant challenges inhandling multimodal data, eliminating algorithmic biases, and providingtransparent decision-making processes. This paper introduces an enhancedgenerative recommendation framework that addresses these limitations throughfive key innovations: multimodal fusion architecture, retrieval-augmentedgeneration mechanisms, causal inference-based debiasing, explainablerecommendation generation, and real-time adaptive learning capabilities. Ourframework leverages advanced large language models as the backbone whileincorporating specialized modules for cross-modal understanding, contextualknowledge integration, bias mitigation, explanation synthesis, and continuousmodel adaptation. Extensive experiments on three benchmark datasets(MovieLens-25M, Amazon-Electronics, Yelp-2023) demonstrate consistentimprovements in recommendation accuracy, fairness, and diversity compared toexisting approaches. The proposed framework achieves up to 2.3% improvement inNDCG@10 and 1.4% enhancement in diversity metrics while maintainingcomputational efficiency through optimized inference strategies.
摘要: 当代生成式推荐系统在处理多模态数据、消除算法偏见以及提供透明的决策过程方面面临重大挑战。本文介绍了一种增强型生成式推荐框架，通过五项关键创新来解决这些局限性：多模态融合架构、检索增强生成机制、基于因果推断的去偏技术、可解释的推荐生成以及实时自适应学习能力。该框架以先进的大型语言模型为基础，同时整合了用于跨模态理解、情境知识整合、偏见缓解、解释合成和持续模型适配的专用模块。在三个基准数据集（MovieLens-25M、Amazon-Electronics、Yelp-2023）上进行的大量实验表明，与现有方法相比，该框架在推荐准确性、公平性和多样性方面均有一致的提升。通过优化的推理策略，所提出的框架在保持计算效率的同时，NDCG@10指标提升了2.3%，多样性指标增强了1.4%。
Link: http://arxiv.org/abs/2510.01622v1
Updated: 2025-10-02T02:53:05Z

22: Quagmires in SFT-RL Post-Training: When High SFT Scores Mislead and What  to Use Instead
Authors: ['Feiyang Kang', 'Michael Kuchnik', 'Karthik Padthe', 'Marin Vlastelica', 'Ruoxi Jia', 'Carole-Jean Wu', 'Newsha Ardalani']
Summary: In post-training for reasoning Large Language Models (LLMs), the currentstate of practice trains LLMs in two independent stages: Supervised Fine-Tuning(SFT) and Reinforcement Learning with Verifiable Rewards (RLVR, shortened as``RL'' below). In this work, we challenge whether high SFT scores translate toimproved performance after RL. We provide extensive counter-examples where thisis not true. We find high SFT scores can be biased toward simpler or morehomogeneous data and are not reliably predictive of subsequent RL gains orscaled-up post-training effectiveness. In some cases, RL training on modelswith improved SFT performance could lead to substantially worse outcomecompared to RL on the base model without SFT. We study alternative metrics andidentify generalization loss on held-out reasoning examples and Pass@large kperformance to provide strong proxies for the RL outcome. We trained hundredsof models up to 12B-parameter with SFT and RLVR via GRPO and ran extensiveevaluations on 7 math benchmarks with up to 256 repetitions, spending $>$1M GPUhours. Experiments include models from Llama3, Mistral-Nemo, Qwen3 and multiplestate-of-the-art SFT/RL datasets. Compared to directly predicting from pre-RLperformance, prediction based on generalization loss and Pass@large k achievessubstantial higher precision, improving $R^2$ coefficient and Spearman's rankcorrelation coefficient by up to 0.5 (2x). This provides strong utility forbroad use cases. For example, in most experiments, we find SFT training onunique examples for a one epoch underperforms training on half examples for twoepochs, either after SFT or SFT-then-RL; With the same SFT budget, trainingonly on short examples may lead to better SFT performance, though, it oftenleads to worse outcome after RL compared to training on examples with varyinglengths. Evaluation tool will be open-sourced.
摘要: 在用于推理的大语言模型（LLMs）的后训练中，当前实践的做法是将LLMs的训练分为两个独立阶段：监督微调（SFT）和基于可验证奖励的强化学习（RLVR，下文简称为“RL”）。在本研究中，我们质疑高SFT分数是否能转化为RL后性能的提升。我们提供了大量与此相悖的反例。我们发现，高SFT分数可能偏向于更简单或更同质化的数据，并不能可靠地预测后续的RL增益或规模化后训练的效果。在某些情况下，对SFT性能提升的模型进行RL训练，其结果可能显著差于对未经SFT的基础模型进行RL训练。我们研究了替代性指标，并确定了在保留的推理示例上的泛化损失以及Pass@large k性能，作为RL结果的有力代理指标。我们通过GRPO训练了数百个参数规模高达120亿的SFT和RLVR模型，并在7个数学基准测试上进行了多达256次重复的广泛评估，耗时超过100万GPU小时。实验涵盖了Llama3、Mistral-Nemo、Qwen3等多个模型以及多种最先进的SFT/RL数据集。与直接基于RL前性能进行预测相比，基于泛化损失和Pass@large k的预测实现了显著更高的精度，将R²系数和斯皮尔曼等级相关系数提高了高达0.5（2倍）。这为广泛的应用场景提供了强大的实用性。例如，在大多数实验中，我们发现对独特示例进行一个周期的SFT训练，其效果不如对一半示例进行两个周期的训练，无论是在SFT后还是在SFT-then-RL后；在相同的SFT预算下，仅训练短示例可能会带来更好的SFT性能，但与训练不同长度的示例相比，其RL后的结果往往更差。评估工具将开源。
Link: http://arxiv.org/abs/2510.01624v1
Updated: 2025-10-02T02:57:00Z

23: Demystifying Synthetic Data in LLM Pre-training: A Systematic Study of  Scaling Laws, Benefits, and Pitfalls
Authors: ['Feiyang Kang', 'Newsha Ardalani', 'Michael Kuchnik', 'Youssef Emad', 'Mostafa Elhoushi', 'Shubhabrata Sengupta', 'Shang-Wen Li', 'Ramya Raghavendra', 'Ruoxi Jia', 'Carole-Jean Wu']
Summary: Training data plays a crucial role in Large Language Models (LLM) scaling,yet high quality data is of limited supply. Synthetic data techniques offer apotential path toward sidestepping these limitations. We conduct a large-scaleempirical investigation (>1000 LLMs with >100k GPU hours) using a unifiedprotocol and scaling laws, comparing natural web data, diverse synthetic types(rephrased text, generated textbooks), and mixtures of natural and syntheticdata. Specifically, we found pre-training on rephrased synthetic data\textit{alone} is not faster than pre-training on natural web texts; whilepre-training on 1/3 rephrased synthetic data mixed with 2/3 natural web textscan speed up 5-10x (to reach the same validation loss) at larger data budgets.Pre-training on textbook-style synthetic data \textit{alone} results in notablyhigher loss on many downstream domains especially at small data budgets. "Good"ratios of synthetic data in training data mixtures depend on the model size anddata budget, empirically converging to ~30% for rephrased synthetic data.Larger generator models do not necessarily yield better pre-training data than~8B-param models. These results contribute mixed evidence on "model collapse"during large-scale single-round (n=1) model training on syntheticdata--training on rephrased synthetic data shows no degradation in performancein foreseeable scales whereas training on mixtures of textbook-stylepure-generated synthetic data shows patterns predicted by "model collapse". Ourwork demystifies synthetic data in pre-training, validates its conditionalbenefits, and offers practical guidance.
摘要: 训练数据在大型语言模型（LLM）的扩展中扮演着至关重要的角色，然而高质量数据的供应却十分有限。合成数据技术为规避这些限制提供了一条潜在路径。我们采用统一的协议和扩展定律进行了一项大规模实证研究（涉及超过1000个LLM和超过10万GPU小时），比较了自然网络数据、多样化的合成数据类型（改写文本、生成的教科书）以及自然与合成数据的混合。具体而言，我们发现仅使用改写合成数据进行预训练并不比使用自然网络文本进行预训练更快；而在较大的数据预算下，使用1/3的改写合成数据与2/3的自然网络文本混合进行预训练，可将速度提升5-10倍（以达到相同的验证损失）。仅使用教科书风格的合成数据进行预训练会导致在许多下游领域上的损失显著更高，尤其是在数据预算较小的情况下。训练数据混合中合成数据的“良好”比例取决于模型大小和数据预算，实证表明改写合成数据的比例会收敛至约30%。更大的生成模型并不一定能产生比约80亿参数模型更好的预训练数据。这些结果为在合成数据上进行大规模单轮（n=1）模型训练期间的“模型崩溃”问题提供了喜忧参半的证据——使用改写合成数据进行训练在可预见的规模下未表现出性能下降，而使用教科书风格的纯生成合成数据混合物进行训练则显示出“模型崩溃”所预测的模式。我们的工作揭示了预训练中合成数据的神秘性，验证了其有条件的好处，并提供了实用指导。
Link: http://arxiv.org/abs/2510.01631v1
Updated: 2025-10-02T03:24:42Z

24: BioBlobs: Differentiable Graph Partitioning for Protein Representation  Learning
Authors: ['Xin Wang', 'Carlos Oliver']
Summary: Protein function is driven by coherent substructures which vary in size andtopology, yet current protein representation learning models (PRL) distortthese signals by relying on rigid substructures such as k-hop and fixed radiusneighbourhoods. We introduce BioBlobs, a plug-and-play, fully differentiablemodule that represents proteins by dynamically partitioning structures intoflexibly-sized, non-overlapping substructures ("blobs"). The resulting blobsare quantized into a shared and interpretable codebook, yielding a discretevocabulary of function-relevant protein substructures used to compute proteinembeddings. We show that BioBlobs representations improve the performance ofwidely used protein encoders such as GVP-GNN across various PRL tasks. Ourapproach highlights the value of architectures that directly capturefunction-relevant protein substructures, enabling both improved predictiveperformance and mechanistic insight into protein function.
摘要: 蛋白质功能是由连贯的子结构驱动的，这些子结构在大小和拓扑上各不相同，然而当前的蛋白质表示学习模型（PRL）通过依赖k跳和固定半径邻域等刚性子结构，扭曲了这些信号。我们介绍了BioBlobs，这是一个即插即用、完全可微的模块，通过将结构动态划分为灵活大小、非重叠的子结构（“blobs”）来表示蛋白质。生成的blobs被量化为一个共享且可解释的码本，从而产生一个与功能相关的蛋白质子结构的离散词汇表，用于计算蛋白质嵌入。我们表明，BioBlobs表示在各种PRL任务中提升了广泛使用的蛋白质编码器（如GVP-GNN）的性能。我们的方法凸显了直接捕获与功能相关的蛋白质子结构的架构的价值，从而实现了预测性能的提升和对蛋白质功能的机制性洞察。
Link: http://arxiv.org/abs/2510.01632v1
Updated: 2025-10-02T03:25:02Z

25: Towards Human-Centered RegTech: Unpacking Professionals' Strategies and  Needs for Using LLMs Safely
Authors: ['Siying Hu', 'Yaxing Yao', 'Zhicong Lu']
Summary: Large Language Models are profoundly changing work patterns in high-riskprofessional domains, yet their application also introduces severe andunderexplored compliance risks. To investigate this issue, we conductedsemi-structured interviews with 24 highly-skilled knowledge workers fromindustries such as law, healthcare, and finance. The study found that theseexperts are commonly concerned about sensitive information leakage,intellectual property infringement, and uncertainty regarding the quality ofmodel outputs. In response, they spontaneously adopt various mitigationstrategies, such as actively distorting input data and limiting the details intheir prompts. However, the effectiveness of these spontaneous efforts islimited due to a lack of specific compliance guidance and training for LargeLanguage Models. Our research reveals a significant gap between current NLPtools and the actual compliance needs of experts. This paper positions thesevaluable empirical findings as foundational work for building the nextgeneration of Human-Centered, Compliance-Driven Natural Language Processing forRegulatory Technology (RegTech), providing a critical human-centeredperspective and design requirements for engineering NLP systems that canproactively support expert compliance workflows.
摘要: 大型语言模型正在深刻改变高风险专业领域的工作模式，然而其应用也带来了严重且尚未得到充分探讨的合规风险。为探究此问题，我们对来自法律、医疗和金融等行业的24名高技能知识工作者进行了半结构化访谈。研究发现，这些专家普遍担忧敏感信息泄露、知识产权侵权以及模型输出质量的不确定性。为此，他们自发采取了各种缓解策略，例如主动扭曲输入数据并限制提示中的细节。然而，由于缺乏针对大型语言模型的具体合规指导和培训，这些自发努力的有效性有限。我们的研究揭示了当前自然语言处理工具与专家实际合规需求之间存在显著差距。本文将这些宝贵的实证发现定位为构建下一代以人为本、合规驱动的监管科技自然语言处理的基础性工作，为能够主动支持专家合规工作流的自然语言处理系统工程提供了关键的人本视角和设计要求。
Link: http://arxiv.org/abs/2510.01638v1
Updated: 2025-10-02T03:35:46Z

26: Understanding the Geospatial Reasoning Capabilities of LLMs: A  Trajectory Recovery Perspective
Authors: ['Thinh Hung Truong', 'Jey Han Lau', 'Jianzhong Qi']
Summary: We explore the geospatial reasoning capabilities of Large Language Models(LLMs), specifically, whether LLMs can read road network maps and performnavigation. We frame trajectory recovery as a proxy task, which requires modelsto reconstruct masked GPS traces, and introduce GLOBALTRACE, a dataset withover 4,000 real-world trajectories across diverse regions and transportationmodes. Using road network as context, our prompting framework enables LLMs togenerate valid paths without accessing any external navigation tools.Experiments show that LLMs outperform off-the-shelf baselines and specializedtrajectory recovery models, with strong zero-shot generalization. Fine-grainedanalysis shows that LLMs have strong comprehension of the road network andcoordinate systems, but also pose systematic biases with respect to regions andtransportation modes. Finally, we demonstrate how LLMs can enhance navigationexperiences by reasoning over maps in flexible ways to incorporate userpreferences.
摘要: 我们探索了大型语言模型（LLMs）的地理空间推理能力，具体而言，即LLMs能否阅读路网地图并进行导航。我们将轨迹恢复设定为一项代理任务，该任务要求模型重建被掩码的GPS轨迹，并引入了GLOBALTRACE数据集，该数据集包含跨越不同地区和交通方式的4000多条真实世界轨迹。通过利用路网作为上下文，我们的提示框架使LLMs能够在不访问任何外部导航工具的情况下生成有效路径。实验表明，LLMs不仅优于现成的基线模型和专门的轨迹恢复模型，还展现出强大的零样本泛化能力。细粒度分析显示，LLMs对路网和坐标系具有强大的理解能力，但在地区和交通方式方面也存在系统性偏差。最后，我们展示了LLMs如何通过以灵活方式对地图进行推理来融入用户偏好，从而提升导航体验。
Link: http://arxiv.org/abs/2510.01639v1
Updated: 2025-10-02T03:37:41Z

27: NLP Methods for Detecting Novel LLM Jailbreaks and Keyword Analysis with  BERT
Authors: ['John Hawkins', 'Aditya Pramar', 'Rodney Beard', 'Rohitash Chandra']
Summary: Large Language Models (LLMs) suffer from a range of vulnerabilities thatallow malicious users to solicit undesirable responses through manipulation ofthe input text. These so-called jailbreak prompts are designed to trick the LLMinto circumventing the safety guardrails put in place to keep responsesacceptable to the developer's policies. In this study, we analyse the abilityof different machine learning models to distinguish jailbreak prompts fromgenuine uses, including looking at our ability to identify jailbreaks that usepreviously unseen strategies. Our results indicate that using current datasetsthe best performance is achieved by fine tuning a Bidirectional EncoderRepresentations from Transformers (BERT) model end-to-end for identifyingjailbreaks. We visualise the keywords that distinguish jailbreak from genuineprompts and conclude that explicit reflexivity in prompt structure could be asignal of jailbreak intention.
摘要: 大型语言模型（LLMs）存在一系列漏洞，使得恶意用户能够通过操控输入文本来诱导其产生不良响应。这些所谓的越狱提示旨在欺骗大型语言模型，使其绕过为保障响应符合开发者政策而设置的安全护栏。在本研究中，我们分析了不同机器学习模型区分越狱提示与真实使用的能力，包括识别采用前所未见策略的越狱提示的能力。我们的研究结果表明，利用现有数据集，通过端到端微调用于识别越狱提示的来自Transformer的双向编码器表示（BERT）模型，可实现最佳性能。我们可视化区分越狱提示与真实提示的关键词，并得出结论：提示结构中的显式自反性可能是越狱意图的信号。
Link: http://arxiv.org/abs/2510.01644v1
Updated: 2025-10-02T03:55:29Z

28: Position: Privacy Is Not Just Memorization!
Authors: ['Niloofar Mireshghallah', 'Tianshi Li']
Summary: The discourse on privacy risks in Large Language Models (LLMs) hasdisproportionately focused on verbatim memorization of training data, while aconstellation of more immediate and scalable privacy threats remainunderexplored. This position paper argues that the privacy landscape of LLMsystems extends far beyond training data extraction, encompassing risks fromdata collection practices, inference-time context leakage, autonomous agentcapabilities, and the democratization of surveillance through deep inferenceattacks. We present a comprehensive taxonomy of privacy risks across the LLMlifecycle -- from data collection through deployment -- and demonstrate throughcase studies how current privacy frameworks fail to address these multifacetedthreats. Through a longitudinal analysis of 1,322 AI/ML privacy paperspublished at leading conferences over the past decade (2016--2025), we revealthat while memorization receives outsized attention in technical research, themost pressing privacy harms lie elsewhere, where current technical approachesoffer little traction and viable paths forward remain unclear. We call for afundamental shift in how the research community approaches LLM privacy, movingbeyond the narrow focus of current technical solutions and embracinginterdisciplinary approaches that address the sociotechnical nature of theseemerging threats.
摘要: 关于大型语言模型（LLMs）隐私风险的讨论，过度集中在训练数据的逐字记忆上，而一系列更直接且可扩展的隐私威胁却仍未得到充分探索。本立场论文指出，LLM系统的隐私格局远不止于训练数据提取，还包括数据收集实践、推理时上下文泄露、自主代理能力以及通过深度推断攻击实现监控民主化所带来的风险。我们提出了一个涵盖LLM整个生命周期（从数据收集到部署）的隐私风险综合分类法，并通过案例研究展示了现有隐私框架如何未能应对这些多方面的威胁。通过对过去十年（2016-2025年）顶级会议上发表的1,322篇关于人工智能/机器学习隐私的论文进行纵向分析，我们发现，尽管记忆问题在技术研究中受到过度关注，但最紧迫的隐私危害却存在于其他领域，当前的技术方法在这些领域收效甚微，可行的前进路径仍不明朗。我们呼吁研究界在处理LLM隐私问题上进行根本性转变，超越当前技术解决方案的狭隘视角，采用能够应对这些新兴威胁社会技术本质的跨学科方法。
Link: http://arxiv.org/abs/2510.01645v1
Updated: 2025-10-02T04:02:06Z

29: Source-Free Cross-Domain Continual Learning
Authors: ['Muhammad Tanzil Furqon', 'Mahardhika Pratama', 'Igor Škrjanc', 'Lin Liu', 'Habibullah Habibullah', 'Kutluyil Dogancay']
Summary: Although existing cross-domain continual learning approaches successfullyaddress many streaming tasks having domain shifts, they call for a fullylabeled source domain hindering their feasibility in the privacy constrainedenvironments. This paper goes one step ahead with the problem of source-freecross-domain continual learning where the use of source-domain samples arecompletely prohibited. We propose the idea of rehearsal-free frequency-awaredynamic prompt collaborations (REFEREE) to cope with the absence of labeledsource-domain samples in realm of cross-domain continual learning. REFEREE isbuilt upon a synergy between a source-pre-trained model and a large-scalevision-language model, thus overcoming the problem of sub-optimalgeneralizations when relying only on a source pre-trained model. The domainshift problem between the source domain and the target domain is handled by afrequency-aware prompting technique encouraging low-frequency components whilesuppressing high-frequency components. This strategy generates frequency-awareaugmented samples, robust against noisy pseudo labels. The noisy pseudo-labelproblem is further addressed with the uncertainty-aware weighting strategywhere the mean and covariance matrix are weighted by prediction uncertainties,thus mitigating the adverse effects of the noisy pseudo label. Besides, theissue of catastrophic forgetting (CF) is overcome by kernel linear discriminantanalysis (KLDA) where the backbone network is frozen while the classificationis performed using the linear discriminant analysis approach guided by therandom kernel method. Our rigorous numerical studies confirm the advantage ofour approach where it beats prior arts having access to source domain sampleswith significant margins.
摘要: 尽管现有的跨领域持续学习方法成功解决了许多具有领域偏移的流式任务，但它们需要一个完全标记的源领域，这限制了它们在隐私受限环境中的可行性。本文进一步研究了无源跨领域持续学习问题，其中完全禁止使用源领域样本。我们提出了无排练的频率感知动态提示协作（REFEREE）的概念，以应对跨领域持续学习领域中标记源领域样本的缺失。REFEREE建立在源预训练模型和大规模视觉语言模型之间的协同作用之上，从而克服了仅依赖源预训练模型时的次优泛化问题。源领域和目标领域之间的领域偏移问题通过一种频率感知提示技术来处理，该技术鼓励低频成分同时抑制高频成分。该策略生成频率感知增强样本，对噪声伪标签具有鲁棒性。噪声伪标签问题进一步通过不确定性感知加权策略得到解决，其中均值和协方差矩阵通过预测不确定性进行加权，从而减轻噪声伪标签的不利影响。此外，灾难性遗忘（CF）问题通过核线性判别分析（KLDA）得到解决，其中主干网络被冻结，而分类则使用由随机核方法引导的线性判别分析方法进行。我们严格的数值研究证实了我们方法的优势，该方法以显著优势超越了能够访问源领域样本的先前技术。
Link: http://arxiv.org/abs/2510.01649v1
Updated: 2025-10-02T04:09:25Z

30: The Unseen Frontier: Pushing the Limits of LLM Sparsity with  Surrogate-Free ADMM
Authors: ['Kwanhee Lee', 'Hyeondo Jang', 'Dongyeop Lee', 'Dan Alistarh', 'Namhoon Lee']
Summary: Neural network pruning is a promising technique to mitigate the excessivecomputational and memory requirements of large language models (LLMs). Despiteits promise, however, progress in this area has diminished, as conventionalmethods are seemingly unable to surpass moderate sparsity levels (50-60%)without severely degrading model accuracy. This work breaks through the currentimpasse, presenting a principled and effective method called $\texttt{Elsa}$,which achieves extreme sparsity levels of up to 90% while retaining high modelfidelity. This is done by identifying several limitations in current practice,all of which can be traced back to their reliance on a surrogate objectiveformulation. $\texttt{Elsa}$ tackles this issue directly and effectively viastandard and well-established constrained optimization techniques based onADMM. Our extensive experiments across a wide range of models and scales showthat $\texttt{Elsa}$ achieves substantial improvements over existing methods;e.g., it achieves 7.8$\times$ less perplexity than the best existing method onLLaMA-2-7B at 90% sparsity. Furthermore, we present$\texttt{Elsa}_{\text{-L}}$, a quantized variant that scales to extremely largemodels (27B), and establish its theoretical convergence guarantees. Theseresults highlight meaningful progress in advancing the frontier of LLMsparsity, while promising that significant opportunities for furtheradvancement may remain in directions that have so far attracted limitedexploration.
摘要: 神经网络剪枝是一种很有前景的技术，可以缓解大型语言模型（LLM）过高的计算和内存需求。尽管前景广阔，但该领域的进展却有所减缓，因为传统方法似乎无法在不严重损害模型准确性的情况下超越中等稀疏度水平（50-60%）。这项工作突破了当前的僵局，提出了一种名为$\texttt{Elsa}$的原则性且有效的方法，该方法在保持高模型保真度的同时，实现了高达90%的极端稀疏度水平。这是通过识别当前实践中的几个局限性来实现的，所有这些局限性都可以追溯到它们对替代目标公式的依赖。$\texttt{Elsa}$通过基于ADMM的标准且成熟的约束优化技术，直接而有效地解决了这个问题。我们在广泛的模型和规模上进行了大量实验，结果表明$\texttt{Elsa}$比现有方法取得了实质性改进；例如，在LLaMA-2-7B模型上，当稀疏度为90%时，其困惑度比现有最佳方法低7.8倍。此外，我们还提出了$\texttt{Elsa}_{\text{-L}}$，这是一种量化变体，可扩展到超大规模模型（27B），并建立了其理论收敛保证。这些结果凸显了在推进LLM稀疏性前沿方面取得的重大进展，同时预示着在迄今为止探索有限的领域中，可能仍存在显著进一步发展的机会。
Link: http://arxiv.org/abs/2510.01650v1
Updated: 2025-10-02T04:10:17Z

31: SoK: Measuring What Matters for Closed-Loop Security Agents
Authors: ['Mudita Khurana', 'Raunak Jain']
Summary: Cybersecurity is a relentless arms race, with AI driven offensive systemsevolving faster than traditional defenses can adapt. Research and toolingremain fragmented across isolated defensive functions, creating blind spotsthat adversaries exploit. Autonomous agents capable of integrating, exploitconfirmation, remediation, and validation into a single closed loop offerpromise, but the field lacks three essentials: a framework defining the agenticcapabilities of security systems across security life cycle, a principledmethod for evaluating closed loop agents, and a benchmark for measuring theirperformance in practice. We introduce CLASP: the Closed-Loop AutonomousSecurity Performance framework which aligns the security lifecycle(reconnaissance, exploitation, root cause analysis, patch synthesis,validation) with core agentic capabilities (planning, tool use, memory,reasoning, reflection & perception) providing a common vocabulary and rubricfor assessing agentic capabilities in security tasks. By applying CLASP to 21representative works, we map where systems demonstrate strengths, and wherecapability gaps persist. We then define the Closed-Loop Capability (CLC) Score,a composite metric quantifying both degree of loop closure and operationaleffectiveness, and outline the requirements for a closed loop benchmark.Together, CLASP and the CLC Score, provide the vocabulary, diagnostics, andmeasurements needed to advance both function level performance and measureclosed loop security agents.
摘要: 网络安全是一场永无止境的军备竞赛，人工智能驱动的进攻系统的发展速度超过了传统防御的适应能力。研究和工具在孤立的防御功能中仍然支离破碎，这制造了对手可利用的盲点。能够将整合、漏洞确认、修复和验证集成为单一闭环的自主代理展现了希望，但该领域缺乏三个基本要素：一个定义安全系统在整个安全生命周期中代理能力的框架，一种评估闭环代理的原则性方法，以及一个衡量其在实践中性能的基准。我们引入CLASP：闭环自主安全性能框架，该框架将安全生命周期（侦察、漏洞利用、根本原因分析、补丁合成、验证）与核心代理能力（规划、工具使用、记忆、推理、反思和感知）相结合，为评估安全任务中的代理能力提供了共同的词汇和评分标准。通过将CLASP应用于21项代表性工作，我们绘制了系统展现优势的领域以及能力差距仍然存在的领域。然后，我们定义了闭环能力（CLC）分数，这是一个量化闭环程度和运营有效性的综合指标，并概述了闭环基准的要求。CLASP和CLC分数共同提供了推动功能级性能提升和衡量闭环安全代理所需的词汇、诊断方法和度量标准。
Link: http://arxiv.org/abs/2510.01654v1
Updated: 2025-10-02T04:20:35Z

32: Asymmetric Proximal Policy Optimization: mini-critics boost LLM  reasoning
Authors: ['Jiashun Liu', 'Johan Obando-Ceron', 'Han Lu', 'Yancheng He', 'Weixun Wang', 'Wenbo Su', 'Bo Zheng', 'Pablo Samuel Castro', 'Aaron Courville', 'Ling Pan']
Summary: Most recent RL for LLMs (RL4LLM) methods avoid explicit critics, replacingthem with average advantage baselines. This shift is largely pragmatic:conventional value functions are computationally expensive to train at LLMscale and often fail under sparse rewards and long reasoning horizons. Werevisit this bottleneck from an architectural perspective and introduceAsymmetric Proximal Policy Optimization (AsyPPO), a simple and scalableframework that restores the critics role while remaining efficient inlarge-model settings. AsyPPO employs a set of lightweight mini-critics, eachtrained on disjoint prompt shards. This design encourages diversity whilepreserving calibration, reducing value-estimation bias. Beyond robustestimation, AsyPPO leverages inter-critic uncertainty to refine the policyupdate: (i) masking advantages in states where critics agree and gradients addlittle learning signal, and (ii) filtering high-divergence states from entropyregularization, suppressing spurious exploration. After training on open-sourcedata with only 5,000 samples, AsyPPO consistently improves learning stabilityand performance across multiple benchmarks over strong baselines, such as GRPO,achieving performance gains of more than six percent on Qwen3-4b-Base and aboutthree percent on Qwen3-8b-Base and Qwen3-14b-Base over classic PPO, withoutadditional tricks. These results highlight the importance of architecturalinnovations for scalable, efficient algorithms.
摘要: 最近用于大语言模型的强化学习方法大多避免使用显式评论家，转而采用平均优势基线。这一转变主要是出于实用性的考虑：传统的价值函数在大语言模型规模下训练计算成本高昂，且在稀疏奖励和长推理时程下常常失效。我们从架构角度重新审视这一瓶颈，并提出了非对称近端策略优化，这是一个简单且可扩展的框架，它在恢复评论家作用的同时，在大模型设置下仍能保持高效。AsyPPO采用一组轻量级迷你评论家，每个评论家在互不重叠的提示片段上进行训练。这种设计在保持校准的同时鼓励了多样性，从而减少了价值估计偏差。除了稳健的估计外，AsyPPO还利用评论家间的不确定性来优化策略更新：(i) 在评论家达成一致且梯度几乎不提供学习信号的状态下屏蔽优势，以及(ii) 从熵正则化中过滤出高分歧状态，以抑制虚假探索。在仅使用5000个样本的开源数据上进行训练后，AsyPPO在多个基准测试上持续提升了学习的稳定性和性能，相较于GRPO等强基线，在Qwen3-4b-Base上实现了超过6%的性能提升，在Qwen3-8b-Base和Qwen3-14b-Base上相较于经典PPO实现了约3%的性能提升，且无需任何额外技巧。这些结果凸显了架构创新对于可扩展、高效算法的重要性。
Link: http://arxiv.org/abs/2510.01656v1
Updated: 2025-10-02T04:24:27Z

33: Learning Time-Series Representations by Hierarchical  Uniformity-Tolerance Latent Balancing
Authors: ['Amin Jalali', 'Milad Soltany', 'Michael Greenspan', 'Ali Etemad']
Summary: We propose TimeHUT, a novel method for learning time-series representationsby hierarchical uniformity-tolerance balancing of contrastive representations.Our method uses two distinct losses to learn strong representations with theaim of striking an effective balance between uniformity and tolerance in theembedding space. First, TimeHUT uses a hierarchical setup to learn bothinstance-wise and temporal information from input time-series. Next, weintegrate a temperature scheduler within the vanilla contrastive loss tobalance the uniformity and tolerance characteristics of the embeddings.Additionally, a hierarchical angular margin loss enforces instance-wise andtemporal contrast losses, creating geometric margins between positive andnegative pairs of temporal sequences. This approach improves the coherence ofpositive pairs and their separation from the negatives, enhancing the captureof temporal dependencies within a time-series sample. We evaluate our approachon a wide range of tasks, namely 128 UCR and 30 UAE datasets for univariate andmultivariate classification, as well as Yahoo and KPI datasets for anomalydetection. The results demonstrate that TimeHUT outperforms prior methods byconsiderable margins on classification, while obtaining competitive results foranomaly detection. Finally, detailed sensitivity and ablation studies areperformed to evaluate different components and hyperparameters of our method.
摘要: 我们提出了TimeHUT，一种通过对比表示的分层均匀性-容差平衡来学习时间序列表示的新方法。我们的方法使用两种不同的损失函数来学习强大的表示，旨在嵌入空间中实现均匀性与容差之间的有效平衡。首先，TimeHUT采用分层设置，从输入时间序列中同时学习实例级和时间级信息。接下来，我们在标准对比损失中集成了一个温度调度器，以平衡嵌入的均匀性与容差特性。此外，分层角度边际损失强制执行实例级和时间级对比损失，在时间序列的正负样本对之间创建几何边际。这种方法提高了正样本对的一致性及其与负样本的分离度，增强了时间序列样本内时间依赖性的捕捉。我们在广泛的任务上评估了我们的方法，包括用于单变量和多变量分类的128个UCR和30个UAE数据集，以及用于异常检测的Yahoo和KPI数据集。结果表明，TimeHUT在分类任务上以显著优势超越了先前的方法，同时在异常检测任务上取得了具有竞争力的结果。最后，我们进行了详细的敏感性和消融研究，以评估我们方法的不同组件和超参数。
Link: http://arxiv.org/abs/2510.01658v1
Updated: 2025-10-02T04:30:13Z

34: MDSEval: A Meta-Evaluation Benchmark for Multimodal Dialogue  Summarization
Authors: ['Yinhong Liu', 'Jianfeng He', 'Hang Su', 'Ruixue Lian', 'Yi Nian', 'Jake Vincent', 'Srikanth Vishnubhotla', 'Robinson Piramuthu', 'Saab Mansour']
Summary: Multimodal Dialogue Summarization (MDS) is a critical task with wide-rangingapplications. To support the development of effective MDS models, robustautomatic evaluation methods are essential for reducing both cost and humaneffort. However, such methods require a strong meta-evaluation benchmarkgrounded in human annotations. In this work, we introduce MDSEval, the firstmeta-evaluation benchmark for MDS, consisting image-sharing dialogues,corresponding summaries, and human judgments across eight well-defined qualityaspects. To ensure data quality and richfulness, we propose a novel filteringframework leveraging Mutually Exclusive Key Information (MEKI) acrossmodalities. Our work is the first to identify and formalize key evaluationdimensions specific to MDS. We benchmark state-of-the-art modal evaluationmethods, revealing their limitations in distinguishing summaries from advancedMLLMs and their susceptibility to various bias.
摘要: 多模态对话摘要（MDS）是一项具有广泛应用的关键任务。为了支持高效MDS模型的开发，稳健的自动评估方法对于降低成本和人力投入至关重要。然而，此类方法需要一个基于人工标注的可靠元评估基准。在本研究中，我们推出了MDSEval，这是首个面向MDS的元评估基准，包含图像共享对话、相应的摘要以及涵盖八个明确定义的质量维度的人工评判。为确保数据的质量和丰富性，我们提出了一种新颖的过滤框架，该框架利用跨模态的互斥关键信息（MEKI）。我们的研究首次识别并形式化了MDS特有的关键评估维度。我们对最先进的模态评估方法进行了基准测试，揭示了它们在区分来自先进多模态大语言模型（MLLMs）的摘要方面的局限性，以及它们对各种偏见的易感性。
Link: http://arxiv.org/abs/2510.01659v1
Updated: 2025-10-02T04:38:27Z

35: Shift-Invariant Attribute Scoring for Kolmogorov-Arnold Networks via  Shapley Value
Authors: ['Wangxuan Fan', 'Ching Wang', 'Siqi Li', 'Nan Liu']
Summary: For many real-world applications, understanding feature-outcome relationshipsis as crucial as achieving high predictive accuracy. While traditional neuralnetworks excel at prediction, their black-box nature obscures underlyingfunctional relationships. Kolmogorov--Arnold Networks (KANs) address this byemploying learnable spline-based activation functions on edges, enablingrecovery of symbolic representations while maintaining competitive performance.However, KAN's architecture presents unique challenges for network pruning.Conventional magnitude-based methods become unreliable due to sensitivity toinput coordinate shifts. We propose \textbf{ShapKAN}, a pruning framework usingShapley value attribution to assess node importance in a shift-invariantmanner. Unlike magnitude-based approaches, ShapKAN quantifies each node'sactual contribution, ensuring consistent importance rankings regardless ofinput parameterization. Extensive experiments on synthetic and real-worlddatasets demonstrate that ShapKAN preserves true node importance while enablingeffective network compression. Our approach improves KAN's interpretabilityadvantages, facilitating deployment in resource-constrained environments.
摘要: 在许多实际应用中，理解特征与结果之间的关系与实现高预测准确性同样重要。虽然传统神经网络在预测方面表现出色，但其黑盒特性掩盖了底层的函数关系。Kolmogorov-Arnold网络（KAN）通过在边上采用可学习的基于样条的激活函数来解决这一问题，从而在保持竞争力的性能的同时恢复符号表示。然而，KAN的架构给网络剪枝带来了独特的挑战。由于对输入坐标变化的敏感性，传统的基于幅度的方法变得不可靠。我们提出了\textbf{ShapKAN}，这是一种使用Shapley值归因来以移位不变方式评估节点重要性的剪枝框架。与基于幅度的方法不同，ShapKAN量化每个节点的实际贡献，确保无论输入参数化如何，重要性排名都保持一致。在合成和真实数据集上进行的大量实验表明，ShapKAN保留了真实的节点重要性，同时实现了有效的网络压缩。我们的方法增强了KAN的可解释性优势，促进了其在资源受限环境中的部署。
Link: http://arxiv.org/abs/2510.01663v1
Updated: 2025-10-02T04:45:02Z

36: GuruAgents: Emulating Wise Investors with Prompt-Guided LLM Agents
Authors: ['Yejin Kim', 'Youngbin Lee', 'Juhyeong Kim', 'Yongjae Lee']
Summary: This study demonstrates that GuruAgents, prompt-guided AI agents, cansystematically operationalize the strategies of legendary investment gurus. Wedevelop five distinct GuruAgents, each designed to emulate an iconic investor,by encoding their distinct philosophies into LLM prompts that integratefinancial tools and a deterministic reasoning pipeline. In a backtest onNASDAQ-100 constituents from Q4 2023 to Q2 2025, the GuruAgents exhibit uniquebehaviors driven by their prompted personas. The Buffett GuruAgent achieves thehighest performance, delivering a 42.2\% CAGR that significantly outperformsbenchmarks, while other agents show varied results. These findings confirm thatprompt engineering can successfully translate the qualitative philosophies ofinvestment gurus into reproducible, quantitative strategies, highlighting anovel direction for automated systematic investing. The source code and dataare available at https://github.com/yejining99/GuruAgents.
摘要: 本研究表明，GuruAgents（即由提示引导的AI代理）能够系统性地将传奇投资大师的策略转化为可执行的操作。我们开发了五种不同的GuruAgents，每种代理均通过将标志性投资者的独特哲学理念编码到大型语言模型（LLM）提示中，并集成金融工具和确定性推理管道，从而模拟这些投资者的投资风格。在2023年第四季度至2025年第二季度对纳斯达克100指数成分股进行的回测中，GuruAgents展现出由其提示角色驱动的独特行为。其中，巴菲特GuruAgent表现最佳，实现了42.2%的年复合增长率，显著超越基准表现，而其他代理则呈现出不同的结果。这些发现证实，提示工程能够成功地将投资大师的定性哲学理念转化为可复现的量化策略，为自动化系统性投资指明了新的方向。源代码和数据可在https://github.com/yejining99/GuruAgents获取。
Link: http://arxiv.org/abs/2510.01664v1
Updated: 2025-10-02T04:45:27Z

37: Just Do It!? Computer-Use Agents Exhibit Blind Goal-Directedness
Authors: ['Erfan Shayegani', 'Keegan Hines', 'Yue Dong', 'Nael Abu-Ghazaleh', 'Roman Lutz', 'Spencer Whitehead', 'Vidhisha Balachandran', 'Besmira Nushi', 'Vibhav Vineet']
Summary: Computer-Use Agents (CUAs) are an increasingly deployed class of agents thattake actions on GUIs to accomplish user goals. In this paper, we show that CUAsconsistently exhibit Blind Goal-Directedness (BGD): a bias to pursue goalsregardless of feasibility, safety, reliability, or context. We characterizethree prevalent patterns of BGD: (i) lack of contextual reasoning, (ii)assumptions and decisions under ambiguity, and (iii) contradictory orinfeasible goals. We develop BLIND-ACT, a benchmark of 90 tasks capturing thesethree patterns. Built on OSWorld, BLIND-ACT provides realistic environments andemploys LLM-based judges to evaluate agent behavior, achieving 93.75% agreementwith human annotations. We use BLIND-ACT to evaluate nine frontier models,including Claude Sonnet and Opus 4, Computer-Use-Preview, and GPT-5, observinghigh average BGD rates (80.8%) across them. We show that BGD exposes subtlerisks that arise even when inputs are not directly harmful. Whileprompting-based interventions lower BGD levels, substantial risk persists,highlighting the need for stronger training- or inference-time interventions.Qualitative analysis reveals observed failure modes: execution-first bias(focusing on how to act over whether to act), thought-action disconnect(execution diverging from reasoning), and request-primacy (justifying actionsdue to user request). Identifying BGD and introducing BLIND-ACT establishes afoundation for future research on studying and mitigating this fundamental riskand ensuring safe CUA deployment.
摘要: 计算机使用代理（CUA）是一类日益广泛部署的代理，它们通过在图形用户界面（GUI）上执行操作来实现用户目标。在本文中，我们证明CUA持续表现出盲目标导向性（BGD）：一种无论可行性、安全性、可靠性或上下文如何都追求目标的倾向。我们描述了BGD的三种普遍模式：（i）缺乏上下文推理，（ii）在模糊性下的假设和决策，以及（iii）矛盾或不可行的目标。我们开发了BLIND-ACT，这是一个包含90个任务的基准测试，捕捉了这三种模式。BLIND-ACT基于OSWorld构建，提供真实环境，并采用基于大型语言模型（LLM）的评估器来评估代理行为，与人类标注的一致性达到93.75%。我们使用BLIND-ACT评估了九个前沿模型，包括Claude Sonnet和Opus 4、Computer-Use-Preview以及GPT-5，观察到它们的平均BGD率很高（80.8%）。我们表明，BGD揭示了即使输入并非直接有害时也会出现的细微风险。虽然基于提示的干预可以降低BGD水平，但重大风险依然存在，这凸显了在训练或推理阶段进行更强干预的必要性。定性分析揭示了观察到的失败模式：执行优先偏差（关注如何行动而非是否行动）、思维-行动脱节（执行与推理不一致）以及请求主导性（因用户请求而为行动辩护）。识别BGD并引入BLIND-ACT为未来研究和缓解这一根本风险、确保CUA安全部署奠定了基础。
Link: http://arxiv.org/abs/2510.01670v1
Updated: 2025-10-02T04:52:15Z

38: A Locally Executable AI System for Improving Preoperative Patient  Communication: A Multi-Domain Clinical Evaluation
Authors: ['Motoki Sato', 'Yuki Matsushita', 'Hidekazu Takahashi', 'Tomoaki Kakazu', 'Sou Nagata', 'Mizuho Ohnuma', 'Atsushi Yoshikawa', 'Masayuki Yamamura']
Summary: Patients awaiting invasive procedures often have unanswered pre-proceduralquestions; however, time-pressured workflows and privacy constraints limitpersonalized counseling. We present LENOHA (Low Energy, No Hallucination, LeaveNo One Behind Architecture), a safety-first, local-first system that routesinputs with a high-precision sentence-transformer classifier and returnsverbatim answers from a clinician-curated FAQ for clinical queries, eliminatingfree-text generation in the clinical path. We evaluated two domains (toothextraction and gastroscopy) using expert-reviewed validation sets(n=400/domain) for thresholding and independent test sets (n=200/domain). Amongthe four encoders, E5-large-instruct (560M) achieved an overall accuracy of0.983 (95% CI 0.964-0.991), AUC 0.996, and seven total errors, which werestatistically indistinguishable from GPT-4o on this task; Gemini made no errorson this test set. Energy logging shows that the non-generative clinical pathconsumes ~1.0 mWh per input versus ~168 mWh per small-talk reply from a local8B SLM, a ~170x difference, while maintaining ~0.10 s latency on a singleon-prem GPU. These results indicate that near-frontier discrimination andgeneration-induced errors are structurally avoided in the clinical path byreturning vetted FAQ answers verbatim, supporting privacy, sustainability, andequitable deployment in bandwidth-limited environments.
摘要: 接受侵入性操作的患者通常有许多未解答的术前问题；然而，时间紧迫的工作流程和隐私限制阻碍了个性化咨询。我们提出了LENOHA（低能耗、无幻觉、不遗漏任何人的架构），一个安全优先、本地优先的系统，它使用高精度句子转换器分类器路由输入，并从临床医生策划的常见问题解答中返回逐字答案，以应对临床查询，从而在临床路径中消除了自由文本生成。我们使用专家评审的验证集（每个领域n=400）进行阈值设定，并使用独立测试集（每个领域n=200）评估了两个领域（拔牙和胃镜检查）。在四种编码器中，E5-large-instruct（560M）实现了0.983的总准确率（95%置信区间0.964-0.991）、0.996的AUC和总共七个错误，这些错误在统计上与GPT-4o在此任务上的表现无显著差异；Gemini在此测试集上未出现任何错误。能耗日志显示，非生成式临床路径每次输入消耗约1.0毫瓦时，而本地8B小型语言模型每次闲聊回复消耗约168毫瓦时，相差约170倍，同时在单个本地GPU上保持了约0.10秒的延迟。这些结果表明，通过返回经过审查的常见问题解答逐字答案，临床路径在结构上避免了接近前沿的判别和生成引发的错误，从而支持了隐私、可持续性以及在带宽有限环境中的公平部署。
Link: http://arxiv.org/abs/2510.01671v1
Updated: 2025-10-02T04:53:11Z

39: FOR-Prompting: From Objection to Revision via an Asymmetric Prompting  Protocol
Authors: ['He Zhang', 'Anzhou Zhang', 'Jian Dai']
Summary: Reasoning protocols such as Chain of Thought (CoT) and Tree of Thought (ToT)organize internal deliberation but lack an explicit mechanism for externalquestioning that elicits self-revision. We present FOR-Prompting (FromObjection to Revision Prompting), an asymmetric protocol where a Defenderproposes an answer, an Objectioner raises question-style objections with nodirect fixes, and a Host enforces consistency and closure. On GSM8K we observeabout a 22% point gain over single-prompt and accuracy on par with CoT, withmore than 10% higher ratings in reasoning and coherence from a uniform GPT 4.1judge. FOR-Prompting also corrects mistakes without tools or human supervisionon tricky queries, and improves performance for small-scale model (approx. 19%accuracy improved on Llama3.2:1b for GSM8K task), highlighting promise forsmall models and on personal device use. Beyond factual QA, qualitativeanalyses on open-ended tasks show enhanced exploration and refinement, withdialogue traces that make assumptions and trade-offs explicit. The protocol ismodel agnostic and operates purely at the prompt level through role-structuredturns, so it works with hosted and local models of different sizes withoutretraining, and it supports large-scale study of objection-guided reasoning.
摘要: 诸如思维链（CoT）和思维树（ToT）之类的推理协议组织了内部审议，但缺乏一种明确的外部质疑机制来引发自我修正。我们提出了FOR-Prompting（从异议到修正的提示），这是一种非对称协议，其中辩护者提出答案，异议者提出无直接修正的问题式异议，而主持人则确保一致性和终结性。在GSM8K数据集上，我们观察到相较于单次提示提升了约22个百分点，准确率与CoT相当，并且在统一的GPT 4.1评估中，在推理和连贯性方面的评分高出10%以上。FOR-Prompting还能在无需工具或人工监督的情况下修正棘手查询中的错误，并提升了小规模模型的性能（在GSM8K任务中，Llama3.2:1b模型的准确率提高了约19%），凸显了其在小模型和个人设备使用上的潜力。除了事实性问答，对开放性任务的定性分析显示，FOR-Prompting增强了探索和细化过程，其对话轨迹能够明确呈现假设和权衡。该协议与模型无关，纯粹通过角色结构的轮次在提示层面运作，因此无需重新训练即可与不同规模的主托管和本地模型兼容，并支持对异议引导推理的大规模研究。
Link: http://arxiv.org/abs/2510.01674v1
Updated: 2025-10-02T04:57:58Z

40: Look Less, Reason More: Rollout-Guided Adaptive Pixel-Space Reasoning
Authors: ['Xuchen Li', 'Xuzhao Li', 'Jiahui Gao', 'Renjie Pi', 'Shiyu Hu', 'Wentao Zhang']
Summary: Vision-Language Models (VLMs) excel at many multimodal tasks, yet theyfrequently struggle with tasks requiring precise understanding and handling offine-grained visual elements. This is mainly due to information loss duringimage encoding or insufficient attention to critical regions. Recent work hasshown promise by incorporating pixel-level visual information into thereasoning process, enabling VLMs to access high-resolution visual detailsduring their thought process. However, this pixel-level information is oftenoverused, leading to inefficiency and distraction from irrelevant visualdetails. To address these challenges, we propose the first framework foradaptive pixel reasoning that dynamically determines necessary pixel-leveloperations based on the input query. Specifically, we first applyoperation-aware supervised fine-tuning to establish baseline competence intextual reasoning and visual operations, then design a novel rollout-guidedreinforcement learning framework relying on feedback of the model's ownresponses, which enables the VLM to determine when pixel operations should beinvoked based on query difficulty. Experiments on extensive multimodalreasoning benchmarks show that our model achieves superior performance whilesignificantly reducing unnecessary visual operations. Impressively, our modelachieves 73.4\% accuracy on HR-Bench 4K while maintaining a tool usage ratio ofonly 20.1\%, improving accuracy and simultaneously reducing tool usage by66.5\% compared to the previous methods.
摘要: 视觉语言模型（VLMs）在许多多模态任务上表现出色，但在需要精确理解和处理细粒度视觉元素的任务中却常常遇到困难。这主要是由于图像编码过程中的信息丢失或对关键区域的关注不足。近期的研究通过将像素级视觉信息融入推理过程，展现出良好的前景，使VLMs在思考过程中能够访问高分辨率的视觉细节。然而，这种像素级信息往往被过度使用，导致效率低下并受到无关视觉细节的干扰。为应对这些挑战，我们提出了首个自适应像素推理框架，该框架能根据输入查询动态确定必要的像素级操作。具体而言，我们首先应用操作感知的监督微调来建立文本推理和视觉操作的基础能力，然后设计一种新颖的基于模型自身响应反馈的 rollout 引导强化学习框架，使VLM能够根据查询难度判断何时应调用像素操作。在大量多模态推理基准测试中的实验表明，我们的模型在显著减少不必要视觉操作的同时，实现了卓越的性能。令人印象深刻的是，我们的模型在HR-Bench 4K上达到了73.4%的准确率，同时将工具使用率维持在仅20.1%，与之前的方法相比，在提高准确率的同时将工具使用量减少了66.5%。
Link: http://arxiv.org/abs/2510.01681v1
Updated: 2025-10-02T05:14:52Z

41: How Do Language Models Compose Functions?
Authors: ['Apoorv Khandelwal', 'Ellie Pavlick']
Summary: While large language models (LLMs) appear to be increasingly capable ofsolving compositional tasks, it is an open question whether they do so usingcompositional mechanisms. In this work, we investigate how feedforward LLMssolve two-hop factual recall tasks, which can be expressed compositionally as$g(f(x))$. We first confirm that modern LLMs continue to suffer from the"compositionality gap": i.e. their ability to compute both $z = f(x)$ and $y =g(z)$ does not entail their ability to compute the composition $y = g(f(x))$.Then, using logit lens on their residual stream activations, we identify twoprocessing mechanisms, one which solves tasks $\textit{compositionally}$,computing $f(x)$ along the way to computing $g(f(x))$, and one which solvesthem $\textit{directly}$, without any detectable signature of the intermediatevariable $f(x)$. Finally, we find that which mechanism is employed appears tobe related to the embedding space geometry, with the idiomatic mechanism beingdominant in cases where there exists a linear mapping from $x$ to $g(f(x))$ inthe embedding spaces. We fully release our data and code at:https://github.com/apoorvkh/composing-functions .
摘要: 尽管大型语言模型（LLMs）在解决组合任务方面似乎日益表现出色，但它们是否采用组合机制来完成任务仍是一个悬而未决的问题。在本研究中，我们探讨了前馈LLMs如何解决两跳事实回忆任务，这类任务可组合表示为$g(f(x))$。我们首先确认，现代LLMs仍存在“组合性差距”：即它们计算$z = f(x)$和$y = g(z)$的能力并不必然意味着它们能够计算组合$y = g(f(x))$。随后，通过对其残差流激活应用logit透镜技术，我们识别出两种处理机制：一种是“组合式”机制，即在计算$g(f(x))$的过程中逐步计算$f(x)$；另一种是“直接式”机制，在计算过程中未检测到中间变量$f(x)$的任何特征。最后，我们发现所采用的机制似乎与嵌入空间的几何特性相关，当嵌入空间中存在从$x$到$g(f(x))$的线性映射时，直接式机制占据主导地位。我们已在以下网址完整公开数据与代码：https://github.com/apoorvkh/composing-functions。
Link: http://arxiv.org/abs/2510.01685v1
Updated: 2025-10-02T05:21:34Z

42: Improving AGI Evaluation: A Data Science Perspective
Authors: ['John Hawkins']
Summary: Evaluation of potential AGI systems and methods is difficult due to thebreadth of the engineering goal. We have no methods for perfect evaluation ofthe end state, and instead measure performance on small tests designed toprovide directional indication that we are approaching AGI. In this work weargue that AGI evaluation methods have been dominated by a design philosophythat uses our intuitions of what intelligence is to create synthetic tasks,that have performed poorly in the history of AI. Instead we argue for analternative design philosophy focused on evaluating robust task execution thatseeks to demonstrate AGI through competence. This perspective is developed fromcommon practices in data science that are used to show that a system can bereliably deployed. We provide practical examples of what this would mean forAGI evaluation.
摘要: 由于工程目标的广泛性，对潜在通用人工智能系统及方法的评估十分困难。我们尚无完美评估最终状态的方法，转而通过设计小型测试来衡量性能，以提供我们正接近通用人工智能的方向性指示。在本文中，我们认为通用人工智能评估方法一直被一种设计哲学所主导，即依赖我们对智能的直觉来构建合成任务，而这类任务在人工智能历史上表现不佳。我们主张采用一种替代性设计哲学，专注于评估稳健的任务执行，并通过能力来证明通用人工智能。这一观点源于数据科学中用于证明系统可被可靠部署的常见实践。我们为通用人工智能评估提供了实际案例以阐释其含义。
Link: http://arxiv.org/abs/2510.01687v1
Updated: 2025-10-02T05:27:29Z

43: Format Inertia: A Failure Mechanism of LLMs in Medical Pre-Consultation
Authors: ['Seungseop Lim', 'Gibaeg Kim', 'Wooseok Han', 'Jean Seo', 'Hyunkyung Lee', 'Jaehyo Yoo', 'Eunho Yang']
Summary: Recent advances in Large Language Models (LLMs) have brought significantimprovements to various service domains, including chatbots and medicalpre-consultation applications. In the healthcare domain, the most commonapproach for adapting LLMs to multi-turn dialogue generation is SupervisedFine-Tuning (SFT). However, datasets for SFT in tasks like medicalpre-consultation typically exhibit a skewed turn-count distribution. Trainingon such data induces a novel failure mechanism we term **Format Inertia**,where models tend to generate repetitive, format-correct, but diagnosticallyuninformative questions in long medical dialogues. To mitigate this observedfailure mechanism, we adopt a simple, data-centric method that rebalances theturn-count distribution of the training dataset. Experimental results show thatour approach substantially alleviates Format Inertia in medicalpre-consultation.
摘要: 大型语言模型（LLM）的最新进展为包括聊天机器人和医疗预咨询应用在内的多个服务领域带来了显著改进。在医疗领域，将LLM适配用于多轮对话生成的最常见方法是监督式微调（SFT）。然而，用于医疗预咨询等任务的SFT数据集通常呈现出轮次计数分布不均的现象。在此类数据上训练会诱发一种我们称之为“格式惯性”的新型失效机制，即模型在长医疗对话中倾向于生成重复的、格式正确但诊断信息量不足的问题。为缓解这一观察到的失效机制，我们采用了一种简单的、以数据为中心的方法，重新平衡了训练数据集的轮次计数分布。实验结果表明，我们的方法显著减轻了医疗预咨询中的格式惯性问题。
Link: http://arxiv.org/abs/2510.01688v1
Updated: 2025-10-02T05:29:38Z

44: VaPR -- Vision-language Preference alignment for Reasoning
Authors: ['Rohan Wadhawan', 'Fabrice Y Harel-Canada', 'Zi-Yi Dou', 'Suhaila Shakiah', 'Robinson Piramuthu', 'Nanyun Peng']
Summary: Preference finetuning methods like Direct Preference Optimization (DPO) withAI-generated feedback have shown promise in aligning Large Vision-LanguageModels (LVLMs) with human preferences. However, existing techniques overlookthe prevalence of noise in synthetic preference annotations in the form ofstylistic and length biases. To this end, we introduce a hard-negative responsegeneration framework based on LLM-guided response editing, that producesrejected responses with targeted errors, maintaining stylistic and lengthsimilarity to the accepted ones. Using this framework, we develop the VaPRdataset, comprising 30K high-quality samples, to finetune three LVLM families:LLaVA-V1.5, Qwen2VL & Qwen2.5VL (2B-13B sizes). Our VaPR models deliversignificant performance improvements across ten benchmarks, achieving averagegains of 6.5% (LLaVA), 4.0% (Qwen2VL), and 1.5% (Qwen2.5VL), with notableimprovements on reasoning tasks. A scaling analysis shows that performanceconsistently improves with data size, with LLaVA models benefiting even atsmaller scales. Moreover, VaPR reduces the tendency to answer "Yes" in binaryquestions - addressing a common failure mode in LVLMs like LLaVA. Lastly, weshow that the framework generalizes to open-source LLMs as editors, with modelstrained on VaPR-OS achieving ~99% of the performance of models trained on\name, which is synthesized using GPT-4o. Our data, models, and code can befound on the project page https://vap-r.github.io
摘要: 基于人工智能生成反馈的直接偏好优化（DPO）等偏好微调方法，在使大型视觉语言模型（LVLMs）与人类偏好对齐方面已展现出潜力。然而，现有技术忽略了合成偏好标注中普遍存在的噪声，这些噪声以风格和长度偏差的形式存在。为此，我们引入了一种基于大语言模型引导的响应编辑的难例负响应生成框架，该框架能生成具有针对性错误且在风格和长度上与接受响应相似的拒绝响应。利用此框架，我们开发了VaPR数据集，包含3万个高质量样本，用于微调三个LVLM系列：LLaVA-V1.5、Qwen2VL和Qwen2.5VL（2B-13B规模）。我们的VaPR模型在十个基准测试中实现了显著的性能提升，平均增益分别为6.5%（LLaVA）、4.0%（Qwen2VL）和1.5%（Qwen2.5VL），并在推理任务上表现尤为突出。扩展分析表明，性能随数据规模提升而持续改善，LLaVA模型即使在较小规模下也能受益。此外，VaPR减少了在二元问题中回答“是”的倾向，解决了LLaVA等LVLMs中常见的失效模式。最后，我们证明该框架可泛化至开源大语言模型作为编辑器，使用VaPR-OS训练的模型达到了使用GPT-4o合成的\name数据集训练模型性能的约99%。我们的数据、模型和代码可在项目页面https://vap-r.github.io获取。
Link: http://arxiv.org/abs/2510.01700v1
Updated: 2025-10-02T06:10:43Z

45: Holistic Order Prediction in Natural Scenes
Authors: ['Pierre Musacchio', 'Hyunmin Lee', 'Jaesik Park']
Summary: Even in controlled settings, understanding instance-wise geometries is achallenging task for a wide range of visual models. Although specializedsystems exist, modern arts rely on expensive input formats (category labels,binary segmentation masks) and inference costs (a quadratic amount of forwardpasses). We mitigate these limitations by proposing InstaFormer, a networkcapable of holistic order prediction. That is, solely given an input RGB image,InstaFormer returns the full occlusion and depth orderings for all theinstances in the scene in a single forward pass. At its core, InstaFormerrelies on interactions between object queries and latent mask descriptors thatsemantically represent the same objects while carrying complementaryinformation. We comprehensively benchmark and ablate our approach to highlightits effectiveness. Our code and models are open-source and available at thisURL: https://github.com/SNU-VGILab/InstaOrder.
摘要: 即使在受控环境中，理解实例级几何结构对于众多视觉模型而言仍是一项艰巨任务。尽管存在专用系统，但现代方法依赖于昂贵的输入格式（类别标签、二值分割掩码）和推理成本（二次方量的前向传播）。我们通过提出InstaFormer来缓解这些局限性，该网络能够进行整体顺序预测。也就是说，仅需输入RGB图像，InstaFormer即可在单次前向传播中返回场景中所有实例的完整遮挡和深度顺序。其核心在于，InstaFormer依赖于对象查询与潜在掩码描述符之间的交互，这些描述符在语义上表征相同对象的同时携带互补信息。我们通过全面的基准测试和消融研究来验证该方法的有效性。我们的代码和模型已开源，可通过以下网址获取：https://github.com/SNU-VGILab/InstaOrder。
Link: http://arxiv.org/abs/2510.01704v1
Updated: 2025-10-02T06:24:12Z

46: Representational Alignment Across Model Layers and Brain Regions with  Hierarchical Optimal Transport
Authors: ['Shaan Shah', 'Meenakshi Khosla']
Summary: Standard representational similarity methods align each layer of a network toits best match in another independently, producing asymmetric results, lackinga global alignment score, and struggling with networks of different depths.These limitations arise from ignoring global activation structure andrestricting mappings to rigid one-to-one layer correspondences. We proposeHierarchical Optimal Transport (HOT), a unified framework that jointly inferssoft, globally consistent layer-to-layer couplings and neuron-level transportplans. HOT allows source neurons to distribute mass across multiple targetlayers while minimizing total transport cost under marginal constraints. Thisyields both a single alignment score for the entire network comparison and asoft transport plan that naturally handles depth mismatches through massdistribution. We evaluate HOT on vision models, large language models, andhuman visual cortex recordings. Across all domains, HOT matches or surpassesstandard pairwise matching in alignment quality. Moreover, it reveals smooth,fine-grained hierarchical correspondences: early layers map to early layers,deeper layers maintain relative positions, and depth mismatches are resolved bydistributing representations across multiple layers. These structured patternsemerge naturally from global optimization without being imposed, yet are absentin greedy layer-wise methods. HOT thus enables richer, more interpretablecomparisons between representations, particularly when networks differ inarchitecture or depth.
摘要: 标准的表征相似性方法将网络的每一层独立地与另一网络中的最佳匹配层对齐，这会产生不对称的结果，缺乏全局对齐分数，并且在处理不同深度的网络时存在困难。这些局限性源于忽略了全局激活结构，并将映射限制在刚性的一对一层对应关系上。我们提出了分层最优传输（HOT），这是一个统一框架，能够联合推断出软性的、全局一致的层间耦合以及神经元级别的传输方案。HOT允许源神经元在多个目标层之间分配质量，同时在边际约束下最小化总传输成本。这既为整个网络比较生成了单一的对齐分数，也提供了一个软传输方案，通过质量分配自然地处理深度不匹配问题。我们在视觉模型、大型语言模型和人类视觉皮层记录上对HOT进行了评估。在所有领域中，HOT在对齐质量上均达到或超越了标准的逐对匹配方法。此外，它揭示了平滑、细粒度的层次对应关系：早期层映射到早期层，更深的层保持相对位置，而深度不匹配则通过将表征分配到多个层来解决。这些结构化模式是从全局优化中自然涌现的，而非人为强加，但在贪心的逐层方法中却不存在。因此，HOT能够在表征之间实现更丰富、更具可解释性的比较，尤其是在网络架构或深度不同的情况下。
Link: http://arxiv.org/abs/2510.01706v1
Updated: 2025-10-02T06:25:06Z

47: PolySim: Bridging the Sim-to-Real Gap for Humanoid Control via  Multi-Simulator Dynamics Randomization
Authors: ['Zixing Lei', 'Zibo Zhou', 'Sheng Yin', 'Yueru Chen', 'Qingyao Xu', 'Weixin Li', 'Yunhong Wang', 'Bowei Tang', 'Wei Jing', 'Siheng Chen']
Summary: Humanoid whole-body control (WBC) policies trained in simulation often sufferfrom the sim-to-real gap, which fundamentally arises from simulator inductivebias, the inherent assumptions and limitations of any single simulator. Thesebiases lead to nontrivial discrepancies both across simulators and betweensimulation and the real world. To mitigate the effect of simulator inductivebias, the key idea is to train policies jointly across multiple simulators,encouraging the learned controller to capture dynamics that generalize beyondany single simulator's assumptions. We thus introduce PolySim, a WBC trainingplatform that integrates multiple heterogeneous simulators. PolySim can launchparallel environments from different engines simultaneously within a singletraining run, thereby realizing dynamics-level domain randomization.Theoretically, we show that PolySim yields a tighter upper bound on simulatorinductive bias than single-simulator training. In experiments, PolySimsubstantially reduces motion-tracking error in sim-to-sim evaluations; forexample, on MuJoCo, it improves execution success by 52.8 over an IsaacSimbaseline. PolySim further enables zero-shot deployment on a real Unitree G1without additional fine-tuning, showing effective transfer from simulation tothe real world. We will release the PolySim code upon acceptance of this work.
摘要: 在仿真环境中训练的人形机器人全身控制策略，常常会遭遇“仿真到现实”的差距，其根本原因在于仿真器的归纳偏置——即任何单一仿真器所固有的假设与局限性。这些偏置会导致不同仿真器之间、以及仿真与现实世界之间出现显著的差异。为缓解仿真器归纳偏置的影响，核心思想是在多个仿真器上联合训练策略，从而促使学习到的控制器能够捕捉到超越任何单一仿真器假设的动力学特性。为此，我们提出了PolySim，一个集成多种异构仿真器的全身控制训练平台。PolySim能够在单次训练运行中同时启动来自不同引擎的并行环境，从而实现动力学层面的域随机化。理论上，我们证明了PolySim相较于单一仿真器训练，能够提供更紧的仿真器归纳偏置上界。在实验中，PolySim在“仿真到仿真”评估中显著降低了运动跟踪误差；例如，在MuJoCo上，其执行成功率相较于IsaacSim基线提升了52.8%。此外，PolySim进一步实现了在真实Unitree G1机器人上的零样本部署，无需额外微调，展现了从仿真到现实的有效迁移能力。本文工作一经录用，我们将发布PolySim的代码。
Link: http://arxiv.org/abs/2510.01708v1
Updated: 2025-10-02T06:31:42Z

48: PyramidStyler: Transformer-Based Neural Style Transfer with Pyramidal  Positional Encoding and Reinforcement Learning
Authors: ['Raahul Krishna Durairaju', 'K. Saruladha']
Summary: Neural Style Transfer (NST) has evolved from Gatys et al.'s (2015) CNN-basedalgorithm, enabling AI-driven artistic image synthesis. However, existing CNNand transformer-based models struggle to scale efficiently to complex stylesand high-resolution inputs. We introduce PyramidStyler, a transformer frameworkwith Pyramidal Positional Encoding (PPE): a hierarchical, multi-scale encodingthat captures both local details and global context while reducingcomputational load. We further incorporate reinforcement learning todynamically optimize stylization, accelerating convergence. Trained onMicrosoft COCO and WikiArt, PyramidStyler reduces content loss by 62.6% (to2.07) and style loss by 57.4% (to 0.86) after 4000 epochs--achieving 1.39 sinference--and yields further improvements (content 2.03; style 0.75) withminimal speed penalty (1.40 s) when using RL. These results demonstratereal-time, high-quality artistic rendering, with broad applications in mediaand design.
摘要: 神经风格迁移（NST）已从Gatys等人（2015）提出的基于CNN的算法发展而来，实现了由人工智能驱动的艺术图像合成。然而，现有的基于CNN和Transformer的模型在有效扩展至复杂风格和高分辨率输入方面面临挑战。我们提出了PyramidStyler，这是一个采用金字塔位置编码（PPE）的Transformer框架：一种分层、多尺度的编码方式，能够在捕捉局部细节和全局上下文的同时降低计算负载。我们进一步引入强化学习来动态优化风格化过程，加速收敛。在Microsoft COCO和WikiArt数据集上训练后，PyramidStyler在4000个epoch后将内容损失降低62.6%（至2.07），风格损失降低57.4%（至0.86），推理速度达到1.39秒；在使用强化学习时，其性能进一步提升（内容2.03；风格0.75），且速度仅轻微下降（1.40秒）。这些结果证明了实时、高质量的艺术渲染能力，在媒体和设计领域具有广泛应用前景。
Link: http://arxiv.org/abs/2510.01715v1
Updated: 2025-10-02T06:54:52Z

49: Latency-aware Multimodal Federated Learning over UAV Networks
Authors: ['Shaba Shaon', 'Dinh C. Nguyen']
Summary: This paper investigates federated multimodal learning (FML) assisted byunmanned aerial vehicles (UAVs) with a focus on minimizing system latency andproviding convergence analysis. In this framework, UAVs are distributedthroughout the network to collect data, participate in model training, andcollaborate with a base station (BS) to build a global model. By utilizingmultimodal sensing, the UAVs overcome the limitations of unimodal systems,enhancing model accuracy, generalization, and offering a more comprehensiveunderstanding of the environment. The primary objective is to optimize FMLsystem latency in UAV networks by jointly addressing UAV sensing scheduling,power control, trajectory planning, resource allocation, and BS resourcemanagement. To address the computational complexity of our latency minimizationproblem, we propose an efficient iterative optimization algorithm combiningblock coordinate descent and successive convex approximation techniques, whichprovides high-quality approximate solutions. We also present a theoreticalconvergence analysis for the UAV-assisted FML framework under a non-convex lossfunction. Numerical experiments demonstrate that our FML framework outperformsexisting approaches in terms of system latency and model training performanceunder different data settings.
摘要: 本文研究了由无人机辅助的联邦多模态学习，重点关注最小化系统延迟并提供收敛性分析。在该框架中，无人机分布于整个网络，用于收集数据、参与模型训练，并与基站协作构建全局模型。通过利用多模态感知，无人机克服了单模态系统的局限性，提升了模型的准确性、泛化能力，并提供了对环境的更全面理解。主要目标是通过联合优化无人机感知调度、功率控制、轨迹规划、资源分配及基站资源管理，来最小化无人机网络中联邦多模态学习系统的延迟。为解决延迟最小化问题的计算复杂性，我们提出了一种高效的迭代优化算法，该算法结合了块坐标下降和逐次凸逼近技术，能够提供高质量的近似解。我们还在非凸损失函数下，对无人机辅助的联邦多模态学习框架进行了理论收敛性分析。数值实验表明，在不同的数据设置下，我们的联邦多模态学习框架在系统延迟和模型训练性能方面均优于现有方法。
Link: http://arxiv.org/abs/2510.01717v1
Updated: 2025-10-02T06:57:44Z

50: Emotional Text-To-Speech Based on Mutual-Information-Guided  Emotion-Timbre Disentanglement
Authors: ['Jianing Yang', 'Sheng Li', 'Takahiro Shinozaki', 'Yuki Saito', 'Hiroshi Saruwatari']
Summary: Current emotional Text-To-Speech (TTS) and style transfer methods rely onreference encoders to control global style or emotion vectors, but do notcapture nuanced acoustic details of the reference speech. To this end, wepropose a novel emotional TTS method that enables fine-grained phoneme-levelemotion embedding prediction while disentangling intrinsic attributes of thereference speech. The proposed method employs a style disentanglement method toguide two feature extractors, reducing mutual information between timbre andemotion features, and effectively separating distinct style components from thereference speech. Experimental results demonstrate that our method outperformsbaseline TTS systems in generating natural and emotionally rich speech. Thiswork highlights the potential of disentangled and fine-grained representationsin advancing the quality and flexibility of emotional TTS systems.
摘要: 当前的情感文本转语音（TTS）和风格迁移方法依赖于参考编码器来控制全局风格或情感向量，但未能捕捉参考语音中细微的声学细节。为此，我们提出了一种新颖的情感TTS方法，该方法在解耦参考语音内在属性的同时，能够实现细粒度的音素级情感嵌入预测。所提出的方法采用一种风格解耦技术来引导两个特征提取器，降低音色与情感特征之间的互信息，并有效地从参考语音中分离出不同的风格成分。实验结果表明，我们的方法在生成自然且情感丰富的语音方面优于基线TTS系统。这项工作凸显了解耦和细粒度表征在提升情感TTS系统质量与灵活性方面的潜力。
Link: http://arxiv.org/abs/2510.01722v1
Updated: 2025-10-02T07:03:50Z

51: MetaboT: AI-based agent for natural language-based interaction with  metabolomics knowledge graphs
Authors: ['Madina Bekbergenova', 'Lucas Pradi', 'Benjamin Navet', 'Emma Tysinger', 'Franck Michel', 'Matthieu Feraud', 'Yousouf Taghzouti', 'Yan Zhou Chen', 'Olivier Kirchhoffer', 'Florence Mehl', 'Martin Legrand', 'Tao Jiang', 'Marco Pagni', 'Soha Hassoun', 'Jean-Luc Wolfender', 'Wout Bittremieux', 'Fabien Gandon', 'Louis-Félix Nothias']
Summary: Mass spectrometry metabolomics generates vast amounts of data requiringadvanced methods for interpretation. Knowledge graphs address these challengesby structuring mass spectrometry data, metabolite information, and theirrelationships into a connected network (Gaudry et al. 2024). However, effectiveuse of a knowledge graph demands an in-depth understanding of its ontology andits query language syntax. To overcome this, we designed MetaboT, an AI systemutilizing large language models (LLMs) to translate user questions into SPARQLsemantic query language for operating on knowledge graphs (Steve Harris 2013).We demonstrate its effectiveness using the Experimental Natural ProductsKnowledge Graph (ENPKG), a large-scale public knowledge graph for plant naturalproducts (Gaudry et al. 2024).MetaboT employs specialized AI agents forhandling user queries and interacting with the knowledge graph by breaking downcomplex tasks into discrete components, each managed by a specialised agent(Fig. 1a). The multi-agent system is constructed using the LangChain andLangGraph libraries, which facilitate the integration of LLMs with externaltools and information sources (LangChain, n.d.). The query generation processfollows a structured workflow. First, the Entry Agent determines if thequestion is new or a follow-up to previous interactions. New questions areforwarded to the Validator Agent, which verifies if the question is related tothe knowledge graph. Then, the valid question is sent to the Supervisor Agent,which identifies if the question requires chemical conversions or standardizedidentifiers. In this case it delegates the question to the Knowledge GraphAgent, which can use tools to extract necessary details, such as URIs ortaxonomies of chemical names, from the user query. Finally, an agentresponsible for crafting the SPARQL queries equipped with the ontology of theknowledge graph uses the provided identifiers to generate the query. Then, thesystem executes the generated query against the metabolomics knowledge graphand returns structured results to the user (Fig. 1b). To assess the performanceof MetaboT we have curated 50 metabolomics-related questions and their expectedanswers. In addition to submitting these questions to MetaboT, we evaluated abaseline by submitting them to a standard LLM (GPT-4o) with a prompt thatincorporated the knowledge graph ontology but did not provide specific entityIDs. This baseline achieved only 8.16% accuracy, compared to MetaboT's 83.67%,underscoring the necessity of our multi-agent system for accurately retrievingentities and generating correct SPARQL queries. MetaboT demonstrates promisingperformance as a conversational question-answering assistant, enablingresearchers to retrieve structured metabolomics data through natural languagequeries. By automating the generation and execution of SPARQL queries, itremoves technical barriers that have traditionally hindered access to knowledgegraphs. Importantly, MetaboT leverages the capabilities of LLMs whilemaintaining experimentally grounded query generation, ensuring that outputsremain aligned with domain-specific standards and data structures. Thisapproach facilitates data-driven discoveries by bridging the gap betweencomplex semantic technologies and user-friendly interaction. MetaboT isaccessible at [https://metabot.holobiomicslab.eu/], and its source code isavailable at [https://github.com/HolobiomicsLab/MetaboT].
摘要: 质谱代谢组学产生海量数据，需要先进的方法进行解读。知识图谱通过将质谱数据、代谢物信息及其关系构建成互联网络，从而应对这些挑战（Gaudry等人，2024）。然而，有效使用知识图谱需要深入理解其本体论和查询语言语法。为克服这一难题，我们设计了MetaboT，这是一个利用大型语言模型（LLM）将用户问题翻译为SPARQL语义查询语言以操作知识图谱的人工智能系统（Steve Harris，2013）。我们通过实验性天然产物知识图谱（ENPKG）展示了其有效性，这是一个大规模的植物天然产物公共知识图谱（Gaudry等人，2024）。

MetaboT采用专门的AI代理处理用户查询并与知识图谱交互，通过将复杂任务分解为离散组件，每个组件由专门代理管理（图1a）。该多代理系统使用LangChain和LangGraph库构建，这些库促进了LLM与外部工具及信息源的集成（LangChain，未注明日期）。查询生成过程遵循结构化工作流程：首先，入口代理判断问题是新问题还是对先前交互的后续追问。新问题被转发至验证代理，该代理核实问题是否与知识图谱相关。随后，有效问题被发送至主管代理，该代理识别问题是否需要化学转换或标准化标识符。若是，则将问题委托给知识图谱代理，该代理可利用工具从用户查询中提取必要细节（如化学名称的URI或分类法）。最后，一个配备知识图谱本体论并负责构建SPARQL查询的代理，使用提供的标识符生成查询。然后，系统在代谢组学知识图谱上执行生成的查询，并将结构化结果返回给用户（图1b）。

为评估MetaboT的性能，我们整理了50个代谢组学相关问题及其预期答案。除向MetaboT提交这些问题外，我们还通过将问题提交给标准LLM（GPT-4o）来评估基线，其提示词虽包含知识图谱本体论但未提供具体实体ID。该基线准确率仅为8.16%，而MetaboT达到83.67%，凸显了我们的多代理系统在准确检索实体和生成正确SPARQL查询方面的必要性。MetaboT作为对话式问答助手展现出卓越性能，使研究人员能通过自然语言查询获取结构化代谢组学数据。通过自动化SPARQL查询的生成与执行，它消除了传统上阻碍知识图谱访问的技术壁垒。重要的是，MetaboT在利用LLM能力的同时，保持了基于实验的查询生成，确保输出符合领域特定标准与数据结构。该方法通过弥合复杂语义技术与用户友好交互之间的鸿沟，促进了数据驱动的发现。MetaboT可通过[https://metabot.holobiomicslab.eu/]访问，其源代码位于[https://github.com/HolobiomicsLab/MetaboT]。
Link: http://arxiv.org/abs/2510.01724v1
Updated: 2025-10-02T07:05:29Z

52: Machine-interpretable Engineering Design Standards for Valve  Specification
Authors: ['Anders Gjerver', 'Rune Frostad', 'Vedrana Barisic', 'Melinda Hodkiewicz', 'Caitlin Woods', 'Mihaly Fekete', 'Arild Braathen Torjusen', 'Johan Wilhelm Kluwer']
Summary: Engineering design processes use technical specifications and must complywith standards. Product specifications, product type data sheets, and designstandards are still mainly document-centric despite the ambition to digitalizeindustrial work. In this paper, we demonstrate how to transform informationheld in engineering design standards into modular, reusable,machine-interpretable ontologies and use the ontologies in quality assurance ofthe plant design and equipment selection process. We use modelling patterns tocreate modular ontologies for knowledge captured in the text and in frequentlyreferenced tables in International Standards for piping, material and valvedesign. These modules are exchangeable, as stored in a W3C compliant format,and interoperable as they are aligned with the top-level ontology ISO DIS23726-3: Industrial Data Ontology (IDO).  We test these ontologies, created based on international material and pipingstandards and industry norms, on a valve selection process. Valves areinstantiated in semantic asset models as individuals along with a semanticrepresentation of the environmental condition at their location on the asset.We create "functional location tags" as OWL individuals that become instancesof OWL class Valve Data Sheet (VDS) specified valves. Similarly we createinstances of manufacturer product type. Our approach enables automatedvalidation that a specific VDS is compliant with relevant industry standards.Using semantic reasoning and executable design rules, we also determine whetherthe product type meets the valve specification. Creation of shared, reusableIDO-based modular ontologies for design standards enables semantic reasoning tobe applied to equipment selection processes and demonstrates the potential ofthis approach for Standards Bodies wanting to transition to digitized SmartStandards.
摘要: 工程设计流程使用技术规范，并必须遵守标准。尽管有实现工业工作数字化的愿景，但产品规格、产品类型数据表和设计标准在很大程度上仍然以文档为中心。在本文中，我们展示了如何将工程设计标准中包含的信息转换为模块化、可重用、机器可解释的本体，并在工厂设计和设备选择流程的质量保证中使用这些本体。我们使用建模模式，为国际管道、材料和阀门设计标准中文本及频繁引用表格所捕获的知识创建模块化本体。这些模块以符合W3C的格式存储，因此可交换；同时，它们与顶层本体ISO DIS 23726-3：工业数据本体（IDO）保持一致，因此具有互操作性。我们基于国际材料和管道标准以及行业规范，在阀门选择流程中对这些本体进行了测试。阀门在语义资产模型中被实例化为个体，同时，其所在位置的环境条件也以语义方式表示。我们创建“功能位置标签”作为OWL个体，这些个体成为符合OWL类阀门数据表（VDS）规范的阀门的实例。同样，我们也创建了制造商产品类型的实例。我们的方法能够自动验证特定的VDS是否符合相关行业标准。通过运用语义推理和可执行的设计规则，我们还能判断产品类型是否满足阀门规格。为设计标准创建共享的、基于IDO的可重用模块化本体，使得语义推理能够应用于设备选择流程，同时也为希望过渡到数字化智能标准的标准组织展示了此方法的潜力。
Link: http://arxiv.org/abs/2510.01736v1
Updated: 2025-10-02T07:20:37Z

53: A cybersecurity AI agent selection and decision support framework
Authors: ['Masike Malatji']
Summary: This paper presents a novel, structured decision support framework thatsystematically aligns diverse artificial intelligence (AI) agent architectures,reactive, cognitive, hybrid, and learning, with the comprehensive NationalInstitute of Standards and Technology (NIST) Cybersecurity Framework (CSF) 2.0.By integrating agent theory with industry guidelines, this framework provides atransparent and stepwise methodology for selecting and deploying AI solutionsto address contemporary cyber threats. Employing a granular decomposition ofNIST CSF 2.0 functions into specific tasks, the study links essential AI agentproperties such as autonomy, adaptive learning, and real-time responsiveness toeach subcategory's security requirements. In addition, it outlines graduatedlevels of autonomy (assisted, augmented, and fully autonomous) to accommodateorganisations at varying stages of cybersecurity maturity. This holisticapproach transcends isolated AI applications, providing a unified detection,incident response, and governance strategy. Through conceptual validation, theframework demonstrates how tailored AI agent deployments can align withreal-world constraints and risk profiles, enhancing situational awareness,accelerating response times, and fortifying long-term resilience via adaptiverisk management. Ultimately, this research bridges the gap between theoreticalAI constructs and operational cybersecurity demands, establishing a foundationfor robust, empirically validated multi-agent systems that adhere to industrystandards.
摘要: 本文提出了一种新颖的、结构化的决策支持框架，该框架将多样化的人工智能（AI）智能体架构（反应式、认知式、混合式和学习式）与全面的国家标准与技术研究院（NIST）网络安全框架（CSF）2.0进行系统性对齐。通过将智能体理论与行业指南相结合，该框架提供了一种透明且循序渐进的方法论，用于选择和部署AI解决方案以应对当代网络威胁。本研究采用对NIST CSF 2.0功能进行细粒度分解为具体任务的方式，将自主性、自适应学习和实时响应等核心AI智能体特性与每个子类别的安全需求相关联。此外，它还概述了分级的自主性水平（辅助型、增强型和完全自主型），以适应处于不同网络安全成熟度阶段的组织。这种整体性方法超越了孤立的AI应用，提供了一种统一的检测、事件响应和治理策略。通过概念验证，该框架展示了定制化的AI智能体部署如何与现实世界的约束和风险状况相契合，通过自适应风险管理增强态势感知、加速响应时间并强化长期韧性。最终，本研究弥合了理论AI构建与运营网络安全需求之间的差距，为遵循行业标准、稳健且经验证的多智能体系统奠定了基础。
Link: http://arxiv.org/abs/2510.01751v1
Updated: 2025-10-02T07:38:21Z

54: Unsupervised Dynamic Feature Selection for Robust Latent Spaces in  Vision Tasks
Authors: ['Bruno Corcuera', 'Carlos Eiras-Franco', 'Brais Cancela']
Summary: Latent representations are critical for the performance and robustness ofmachine learning models, as they encode the essential features of data in acompact and informative manner. However, in vision tasks, these representationsare often affected by noisy or irrelevant features, which can degrade themodel's performance and generalization capabilities. This paper presents anovel approach for enhancing latent representations using unsupervised DynamicFeature Selection (DFS). For each instance, the proposed method identifies andremoves misleading or redundant information in images, ensuring that only themost relevant features contribute to the latent space. By leveraging anunsupervised framework, our approach avoids reliance on labeled data, making itbroadly applicable across various domains and datasets. Experiments conductedon image datasets demonstrate that models equipped with unsupervised DFSachieve significant improvements in generalization performance across varioustasks, including clustering and image generation, while incurring a minimalincrease in the computational cost.
摘要: 潜在表征对于机器学习模型的性能和鲁棒性至关重要，因为它们以紧凑且信息丰富的方式编码了数据的基本特征。然而，在视觉任务中，这些表征常常受到噪声或不相关特征的影响，从而降低模型的性能和泛化能力。本文提出了一种使用无监督动态特征选择（DFS）来增强潜在表征的新方法。对于每个实例，该方法识别并去除图像中的误导性或冗余信息，确保只有最相关的特征对潜在空间有所贡献。通过利用无监督框架，我们的方法避免了对标记数据的依赖，使其能够广泛应用于不同领域和数据集。在图像数据集上进行的实验表明，配备无监督DFS的模型在聚类和图像生成等多种任务上的泛化性能均有显著提升，同时仅带来最小的计算成本增加。
Link: http://arxiv.org/abs/2510.01758v1
Updated: 2025-10-02T07:46:59Z

55: Secure Multi-Modal Data Fusion in Federated Digital Health Systems via  MCP
Authors: ['Aueaphum Aueawatthanaphisut']
Summary: Secure and interoperable integration of heterogeneous medical data remains agrand challenge in digital health. Current federated learning (FL) frameworksoffer privacy-preserving model training but lack standardized mechanisms toorchestrate multi-modal data fusion across distributed and resource-constrainedenvironments. This study introduces a novel framework that leverages the ModelContext Protocol (MCP) as an interoperability layer for secure, cross-agentcommunication in multi-modal federated healthcare systems. The proposedarchitecture unifies three pillars: (i) multi-modal feature alignment forclinical imaging, electronic medical records, and wearable IoT data; (ii)secure aggregation with differential privacy to protect patient-sensitiveupdates; and (iii) energy-aware scheduling to mitigate dropouts in mobileclients. By employing MCP as a schema-driven interface, the framework enablesadaptive orchestration of AI agents and toolchains while ensuring compliancewith privacy regulations. Experimental evaluation on benchmark datasets andpilot clinical cohorts demonstrates up to 9.8\% improvement in diagnosticaccuracy compared with baseline FL, a 54\% reduction in client dropout rates,and clinically acceptable privacy--utility trade-offs. These results highlightMCP-enabled multi-modal fusion as a scalable and trustworthy pathway towardequitable, next-generation federated health infrastructures.
摘要: 异构医疗数据的安全与互操作集成仍是数字健康领域的一大挑战。当前的联邦学习（FL）框架虽能实现隐私保护的模型训练，却缺乏标准化机制来协调分布式资源受限环境下的多模态数据融合。本研究提出了一种新型框架，利用模型上下文协议（MCP）作为互操作层，在多模态联邦医疗系统中实现安全、跨代理通信。该架构统一了三大支柱：（i）针对临床影像、电子病历及可穿戴物联网数据的多模态特征对齐；（ii）采用差分隐私的安全聚合以保护患者敏感更新；（iii）通过能耗感知调度降低移动客户端的掉线率。通过将MCP作为模式驱动接口，该框架实现了AI代理与工具链的自适应协调，同时确保符合隐私法规。在基准数据集和试点临床队列上的实验评估表明，与基线FL相比，诊断准确率提升高达9.8%，客户端掉线率降低54%，并实现了临床可接受的隐私-效用权衡。这些结果凸显了MCP驱动的多模态融合作为构建公平、下一代联邦健康基础设施的可扩展且可信路径的潜力。
Link: http://arxiv.org/abs/2510.01780v1
Updated: 2025-10-02T08:19:56Z

56: Can LLMs Refuse Questions They Do Not Know? Measuring Knowledge-Aware  Refusal in Factual Tasks
Authors: ['Wenbo Pan', 'Jie Xu', 'Qiguang Chen', 'Junhao Dong', 'Libo Qin', 'Xinfeng Li', 'Haining Yu', 'Xiaohua Jia']
Summary: Large Language Models (LLMs) should refuse to answer questions beyond theirknowledge. This capability, which we term knowledge-aware refusal, is crucialfor factual reliability. However, existing metrics fail to faithfully measurethis ability. On the one hand, simple refusal-based metrics are biased byrefusal rates and yield inconsistent scores when models exhibit differentrefusal tendencies. On the other hand, existing calibration metrics areproxy-based, capturing the performance of auxiliary calibration processesrather than the model's actual refusal behavior. In this work, we propose theRefusal Index (RI), a principled metric that measures how accurately LLMsrefuse questions they do not know. We define RI as Spearman's rank correlationbetween refusal probability and error probability. To make RI practicallymeasurable, we design a lightweight two-pass evaluation method that efficientlyestimates RI from observed refusal rates across two standard evaluation runs.Extensive experiments across 16 models and 5 datasets demonstrate that RIaccurately quantifies a model's intrinsic knowledge-aware refusal capability infactual tasks. Notably, RI remains stable across different refusal rates andprovides consistent model rankings independent of a model's overall accuracyand refusal rates. More importantly, RI provides insight into an important butpreviously overlooked aspect of LLM factuality: while LLMs achieve highaccuracy on factual tasks, their refusal behavior can be unreliable andfragile. This finding highlights the need to complement traditional accuracymetrics with the Refusal Index for comprehensive factuality evaluation.
摘要: 大型语言模型（LLMs）应拒绝回答超出其知识范围的问题。我们称这种能力为知识感知拒绝，它对事实可靠性至关重要。然而，现有指标无法真实衡量这一能力。一方面，简单的基于拒绝的指标受拒绝率影响，并在模型表现出不同拒绝倾向时产生不一致的分数。另一方面，现有的校准指标是基于代理的，捕捉的是辅助校准过程的性能，而非模型的实际拒绝行为。在这项工作中，我们提出了拒绝指数（RI），一种原则性指标，用于衡量LLMs准确拒绝其不知道的问题的程度。我们将RI定义为拒绝概率与错误概率之间的斯皮尔曼等级相关系数。为使RI可实际测量，我们设计了一种轻量级的两遍评估方法，通过两次标准评估运行中观察到的拒绝率高效估计RI。在16个模型和5个数据集上的大量实验表明，RI能准确量化模型在事实任务中固有的知识感知拒绝能力。值得注意的是，RI在不同拒绝率下保持稳定，并提供独立于模型整体准确率和拒绝率的一致模型排名。更重要的是，RI揭示了LLMs事实性的一个重要但此前被忽视的方面：尽管LLMs在事实任务上实现了高准确率，但其拒绝行为可能不可靠且脆弱。这一发现凸显了需要用拒绝指数补充传统准确率指标，以全面评估事实性。
Link: http://arxiv.org/abs/2510.01782v1
Updated: 2025-10-02T08:20:36Z

57: Pack and Force Your Memory: Long-form and Consistent Video Generation
Authors: ['Xiaofei Wu', 'Guozhen Zhang', 'Zhiyong Xu', 'Yuan Zhou', 'Qinglin Lu', 'Xuming He']
Summary: Long-form video generation presents a dual challenge: models must capturelong-range dependencies while preventing the error accumulation inherent inautoregressive decoding. To address these challenges, we make twocontributions. First, for dynamic context modeling, we propose MemoryPack, alearnable context-retrieval mechanism that leverages both textual and imageinformation as global guidance to jointly model short- and long-termdependencies, achieving minute-level temporal consistency. This design scalesgracefully with video length, preserves computational efficiency, and maintainslinear complexity. Second, to mitigate error accumulation, we introduce DirectForcing, an efficient single-step approximating strategy that improvestraining-inference alignment and thereby curtails error propagation duringinference. Together, MemoryPack and Direct Forcing substantially enhance thecontext consistency and reliability of long-form video generation, advancingthe practical usability of autoregressive video models.
摘要: 长视频生成面临双重挑战：模型必须捕捉长期依赖关系，同时防止自回归解码中固有的错误累积。为应对这些挑战，我们做出两项贡献。首先，在动态上下文建模方面，我们提出MemoryPack，这是一种可学习的上下文检索机制，利用文本和图像信息作为全局指导，联合建模短期和长期依赖关系，实现分钟级的时间一致性。该设计随视频长度优雅扩展，保持计算效率，并维持线性复杂度。其次，为缓解错误累积，我们引入Direct Forcing，这是一种高效的单步近似策略，可改进训练与推理的对齐，从而在推理过程中减少错误传播。MemoryPack和Direct Forcing共同显著提升了长视频生成的上下文一致性和可靠性，推动了自回归视频模型的实际应用。
Link: http://arxiv.org/abs/2510.01784v1
Updated: 2025-10-02T08:22:46Z

58: Comparison of Unsupervised Metrics for Evaluating Judicial Decision  Extraction
Authors: ['Ivan Leonidovich Litvak', 'Anton Kostin', 'Fedor Lashkin', 'Tatiana Maksiyan', 'Sergey Lagutin']
Summary: The rapid advancement of artificial intelligence in legal natural languageprocessing demands scalable methods for evaluating text extraction fromjudicial decisions. This study evaluates 16 unsupervised metrics, includingnovel formulations, to assess the quality of extracting seven semantic blocksfrom 1,000 anonymized Russian judicial decisions, validated against 7,168expert reviews on a 1--5 Likert scale. These metrics, spanning document-based,semantic, structural, pseudo-ground truth, and legal-specific categories,operate without pre-annotated ground truth. Bootstrapped correlations, Lin'sconcordance correlation coefficient (CCC), and mean absolute error (MAE) revealthat Term Frequency Coherence (Pearson $r = 0.540$, Lin CCC = 0.512, MAE =0.127) and Coverage Ratio/Block Completeness (Pearson $r = 0.513$, Lin CCC =0.443, MAE = 0.139) best align with expert ratings, while Legal Term Density(Pearson $r = -0.479$, Lin CCC = -0.079, MAE = 0.394) show strong negativecorrelations. The LLM Evaluation Score (mean = 0.849, Pearson $r = 0.382$, LinCCC = 0.325, MAE = 0.197) showed moderate alignment, but its performance, usinggpt-4.1-mini via g4f, suggests limited specialization for legal textse. Thesefindings highlight that unsupervised metrics, including LLM-based approaches,enable scalable screening but, with moderate correlations and low CCC values,cannot fully replace human judgment in high-stakes legal contexts. This workadvances legal NLP by providing annotation-free evaluation tools, withimplications for judicial analytics and ethical AI deployment.
摘要: 法律自然语言处理中人工智能的快速发展，要求有可扩展的方法来评估从司法判决中提取文本的质量。本研究评估了16种无监督指标（包括新型公式），以评估从1000份匿名的俄罗斯司法判决中提取七个语义块的质量，并根据1-5分李克特量表上的7168份专家评审进行了验证。这些指标涵盖基于文档、语义、结构、伪真实值和法律专用类别，无需预先标注的真实值即可运行。自举相关系数、林一致性相关系数（CCC）和平均绝对误差（MAE）显示，术语频率一致性（皮尔逊r = 0.540，林CCC = 0.512，MAE = 0.127）和覆盖率/区块完整性（皮尔逊r = 0.513，林CCC = 0.443，MAE = 0.139）与专家评分最为吻合，而法律术语密度（皮尔逊r = -0.479，林CCC = -0.079，MAE = 0.394）则显示出强烈的负相关。大语言模型评估得分（均值 = 0.849，皮尔逊r = 0.382，林CCC = 0.325，MAE = 0.197）表现出中等一致性，但通过g4f使用gpt-4.1-mini的性能表明其对法律文本的专业化程度有限。这些发现表明，包括基于大语言模型方法在内的无监督指标能够实现可扩展的筛选，但由于相关系数中等且CCC值较低，无法在高风险的法律环境中完全取代人类判断。这项工作通过提供无需标注的评估工具推动了法律自然语言处理的发展，对司法分析和道德人工智能部署具有启示意义。
Link: http://arxiv.org/abs/2510.01792v1
Updated: 2025-10-02T08:32:16Z

59: Nav-EE: Navigation-Guided Early Exiting for Efficient Vision-Language  Models in Autonomous Driving
Authors: ['Haibo Hu', 'Lianming Huang', 'Xinyu Wang', 'Yufei Cui', 'Nan Guan', 'Chun Jason Xue']
Summary: Vision-Language Models (VLMs) are increasingly applied in autonomous drivingfor unified perception and reasoning, but high inference latency hindersreal-time deployment. Early-exit reduces latency by terminating inference atintermediate layers, yet its task-dependent nature limits generalization acrossdiverse scenarios. We observe that this limitation aligns with autonomousdriving: navigation systems can anticipate upcoming contexts (e.g.,intersections, traffic lights), indicating which tasks will be required. Wepropose Nav-EE, a navigation-guided early-exit framework that precomputestask-specific exit layers offline and dynamically applies them online based onnavigation priors. Experiments on CODA, Waymo, and BOSCH show that Nav-EEachieves accuracy comparable to full inference while reducing latency by up to63.9%. Real-vehicle integration with Autoware Universe further demonstratesreduced inference latency (600ms to 300ms), supporting faster decision-makingin complex scenarios. These results suggest that coupling navigation foresightwith early-exit offers a viable path toward efficient deployment of largemodels in autonomous systems. Code and data are available at our anonymousrepository: https://anonymous.4open.science/r/Nav-EE-BBC4
摘要: 视觉语言模型（VLMs）日益应用于自动驾驶领域以实现统一的感知与推理，但其高昂的推理延迟阻碍了实时部署。早期退出策略通过在中间层终止推理来降低延迟，然而其任务依赖性限制了在多样化场景中的泛化能力。我们观察到，这一局限性与自动驾驶的特性相契合：导航系统能够预判即将到来的上下文（如路口、交通信号灯），从而指示哪些任务将被需要。我们提出了Nav-EE，一种由导航引导的早期退出框架，该框架可离线预计算任务特定的退出层，并基于导航先验在线动态应用这些层。在CODA、Waymo及BOSCH数据集上的实验表明，Nav-EE在降低高达63.9%延迟的同时，实现了与完整推理相当的准确性。与Autoware Universe的实车集成进一步展示了推理延迟的降低（从600毫秒降至300毫秒），为复杂场景下的更快决策提供了支持。这些结果表明，将导航预见性与早期退出策略相结合，为大型模型在自动驾驶系统中的高效部署提供了一条可行路径。代码与数据可在我们的匿名仓库获取：https://anonymous.4open.science/r/Nav-EE-BBC4。
Link: http://arxiv.org/abs/2510.01795v1
Updated: 2025-10-02T08:37:58Z

60: Rethinking the shape convention of an MLP
Authors: ['Meng-Hsi Chen', 'Yu-Ang Lee', 'Feng-Ting Liao', 'Da-shan Shiu']
Summary: Multi-layer perceptrons (MLPs) conventionally follow a narrow-wide-narrowdesign where skip connections operate at the input/output dimensions whileprocessing occurs in expanded hidden spaces. We challenge this convention byproposing wide-narrow-wide (Hourglass) MLP blocks where skip connectionsoperate at expanded dimensions while residual computation flows through narrowbottlenecks. This inversion leverages higher-dimensional spaces for incrementalrefinement while maintaining computational efficiency through parameter-matcheddesigns. Implementing Hourglass MLPs requires an initial projection to liftinput signals to expanded dimensions. We propose that this projection canremain fixed at random initialization throughout training, enabling efficienttraining and inference implementations. We evaluate both architectures ongenerative tasks over popular image datasets, characterizingperformance-parameter Pareto frontiers through systematic architectural search.Results show that Hourglass architectures consistently achieve superior Paretofrontiers compared to conventional designs. As parameter budgets increase,optimal Hourglass configurations favor deeper networks with wider skipconnections and narrower bottlenecks-a scaling pattern distinct fromconventional MLPs. Our findings suggest reconsidering skip connection placementin modern architectures, with potential applications extending to Transformersand other residual networks.
摘要: 多层感知机（MLP）传统上采用窄-宽-窄的设计，其中跳跃连接在输入/输出维度上运行，而处理则在扩展的隐藏空间中进行。我们通过提出宽-窄-宽（沙漏）MLP块来挑战这一传统，其中跳跃连接在扩展维度上运行，而残差计算则流经窄瓶颈。这种反转利用高维空间进行增量细化，同时通过参数匹配的设计保持计算效率。实现沙漏MLP需要将输入信号投影到扩展维度。我们提出，这种投影可以在训练过程中保持随机初始化不变，从而实现高效的训练和推理实现。我们在流行的图像数据集上的生成任务中对两种架构进行了评估，通过系统性的架构搜索来表征性能-参数帕累托前沿。结果表明，与传统设计相比，沙漏架构始终能实现更优的帕累托前沿。随着参数预算的增加，最优沙漏配置倾向于具有更宽跳跃连接和更窄瓶颈的更深网络——这是一种与传统MLP不同的扩展模式。我们的研究建议在现代架构中重新考虑跳跃连接的放置，其潜在应用可扩展到Transformer和其他残差网络。
Link: http://arxiv.org/abs/2510.01796v1
Updated: 2025-10-02T08:38:15Z

61: REBot: From RAG to CatRAG with Semantic Enrichment and Graph Routing
Authors: ['Thanh Ma', 'Tri-Tam La', 'Lam-Thu Le Huu', 'Minh-Nghi Nguyen', 'Khanh-Van Pham Luu', 'Huu-Hoa Nguyen']
Summary: Academic regulation advising is essential for helping students interpret andcomply with institutional policies, yet building effective systems requiresdomain specific regulatory resources. To address this challenge, we proposeREBot, an LLM enhanced advisory chatbot powered by CatRAG, a hybrid retrievalreasoning framework that integrates retrieval augmented generation with graphbased reasoning. CatRAG unifies dense retrieval and graph reasoning, supportedby a hierarchical, category labeled knowledge graph enriched with semanticfeatures for domain alignment. A lightweight intent classifier routes queriesto the appropriate retrieval modules, ensuring both factual accuracy andcontextual depth. We construct a regulation specific dataset and evaluate REBoton classification and question answering tasks, achieving state of the artperformance with an F1 score of 98.89%. Finally, we implement a web applicationthat demonstrates the practical value of REBot in real world academic advisingscenarios.
摘要: 学术规定咨询对于帮助学生理解和遵守院校政策至关重要，然而构建有效的系统需要特定领域的监管资源。为应对这一挑战，我们提出了REBot，这是一款由CatRAG驱动的、基于大语言模型增强的咨询聊天机器人。CatRAG是一个混合检索推理框架，将检索增强生成与基于图的推理相结合。它整合了密集检索和图推理，并辅以一个分层、带有类别标签的知识图谱，该图谱通过语义特征进行丰富以实现领域对齐。一个轻量级意图分类器将查询路由至相应的检索模块，确保事实准确性和语境深度。我们构建了一个特定于规定的数据集，并在分类和问答任务上对REBot进行了评估，以98.89%的F1分数达到了最先进的性能。最后，我们实现了一个网络应用程序，展示了REBot在真实世界学术咨询场景中的实用价值。
Link: http://arxiv.org/abs/2510.01800v1
Updated: 2025-10-02T08:40:55Z

62: SingMOS-Pro: An Comprehensive Benchmark for Singing Quality Assessment
Authors: ['Yuxun Tang', 'Lan Liu', 'Wenhao Feng', 'Yiwen Zhao', 'Jionghao Han', 'Yifeng Yu', 'Jiatong Shi', 'Qin Jin']
Summary: Singing voice generation progresses rapidly, yet evaluating singing qualityremains a critical challenge. Human subjective assessment, typically in theform of listening tests, is costly and time consuming, while existing objectivemetrics capture only limited perceptual aspects. In this work, we introduceSingMOS-Pro, a dataset for automatic singing quality assessment. Building onour preview version SingMOS, which provides only overall ratings, SingMOS-Proexpands annotations of the additional part to include lyrics, melody, andoverall quality, offering broader coverage and greater diversity. The datasetcontains 7,981 singing clips generated by 41 models across 12 datasets,spanning from early systems to recent advances. Each clip receives at leastfive ratings from professional annotators, ensuring reliability andconsistency. Furthermore, we explore how to effectively utilize MOS dataannotated under different standards and benchmark several widely usedevaluation methods from related tasks on SingMOS-Pro, establishing strongbaselines and practical references for future research. The dataset can beaccessed at https://huggingface.co/datasets/TangRain/SingMOS-Pro.
摘要: 歌声生成技术发展迅速，然而评估歌声质量仍是一项关键挑战。人类主观评估通常以听力测试形式进行，成本高昂且耗时，而现有的客观指标仅能捕捉有限的感知方面。在本研究中，我们介绍了SingMOS-Pro，一个用于自动歌声质量评估的数据集。基于我们仅提供整体评分的预览版SingMOS，SingMOS-Pro扩展了额外部分的注释，涵盖歌词、旋律和整体质量，提供了更广泛的覆盖面和更大的多样性。该数据集包含来自12个数据集的41个模型生成的7,981个歌声片段，时间跨度从早期系统到近期进展。每个片段均获得至少五名专业注释员的评分，确保了可靠性和一致性。此外，我们探讨了如何有效利用在不同标准下标注的MOS数据，并在SingMOS-Pro上对相关任务中几种广泛使用的评估方法进行了基准测试，为未来研究建立了强有力的基线和实用参考。该数据集可通过https://huggingface.co/datasets/TangRain/SingMOS-Pro访问。
Link: http://arxiv.org/abs/2510.01812v1
Updated: 2025-10-02T08:53:49Z

63: Human-AI Teaming Co-Learning in Military Operations
Authors: ['Clara Maathuis', 'Kasper Cools']
Summary: In a time of rapidly evolving military threats and increasingly complexoperational environments, the integration of AI into military operations provessignificant advantages. At the same time, this implies various challenges andrisks regarding building and deploying human-AI teaming systems in an effectiveand ethical manner. Currently, understanding and coping with them are oftentackled from an external perspective considering the human-AI teaming system asa collective agent. Nevertheless, zooming into the dynamics involved inside thesystem assures dealing with a broader palette of relevant multidimensionalresponsibility, safety, and robustness aspects. To this end, this researchproposes the design of a trustworthy co-learning model for human-AI teaming inmilitary operations that encompasses a continuous and bidirectional exchange ofinsights between the human and AI agents as they jointly adapt to evolvingbattlefield conditions. It does that by integrating four dimensions. First,adjustable autonomy for dynamically calibrating the autonomy levels of agentsdepending on aspects like mission state, system confidence, and environmentaluncertainty. Second, multi-layered control which accounts continuous oversight,monitoring of activities, and accountability. Third, bidirectional feedbackwith explicit and implicit feedback loops between the agents to assure a propercommunication of reasoning, uncertainties, and learned adaptations that each ofthe agents has. And fourth, collaborative decision-making which implies thegeneration, evaluation, and proposal of decisions associated with confidencelevels and rationale behind them. The model proposed is accompanied by concreteexemplifications and recommendations that contribute to further developingresponsible and trustworthy human-AI teaming systems in military operations.
摘要: 在军事威胁快速演变和作战环境日益复杂的时代，将人工智能融入军事行动具有显著优势。同时，这也意味着在有效且合乎道德地构建和部署人机编队系统方面，存在着各种挑战和风险。当前，对理解和应对这些挑战的探讨，往往是从外部视角出发，将人机编队系统视为一个集体代理。然而，深入探究系统内部的动态，能够确保处理更广泛的相关多维责任、安全性和稳健性问题。为此，本研究提出了一种用于军事行动中人机编队的可信赖协同学习模型设计，该模型包含人类与人工智能代理在共同适应不断变化的战场条件时，持续进行双向的见解交流。该模型通过整合四个维度来实现这一目标。首先，可调节的自主性，即根据任务状态、系统置信度和环境不确定性等因素动态校准代理的自主性水平。其次，多层控制，即进行持续的监督、活动监控和问责。第三，双向反馈，即在代理之间建立显性和隐性的反馈回路，以确保每个代理都能就其推理、不确定性和学到的适应性进行恰当的沟通。第四，协同决策，即生成、评估和提出与置信度及其背后原理相关联的决策。所提出的模型附有具体的示例和建议，有助于进一步发展军事行动中负责任且可信赖的人机编队系统。
Link: http://arxiv.org/abs/2510.01815v1
Updated: 2025-10-02T09:01:01Z

64: Plan Then Action:High-Level Planning Guidance Reinforcement Learning for  LLM Reasoning
Authors: ['Zhihao Dou', 'Qinjian Zhao', 'Zhongwei Wan', 'Dinggen Zhang', 'Weida Wang', 'Towsif Raiyan', 'Benteng Chen', 'Qingtao Pan', 'Yang Ouyang', 'Zhiqiang Gao', 'Shufei Zhang', 'Sumon Biswas']
Summary: Large language models (LLMs) have demonstrated remarkable reasoning abilitiesin complex tasks, often relying on Chain-of-Thought (CoT) reasoning. However,due to their autoregressive token-level generation, the reasoning process islargely constrained to local decision-making and lacks global planning. Thislimitation frequently results in redundant, incoherent, or inaccuratereasoning, which significantly degrades overall performance. Existingapproaches, such as tree-based algorithms and reinforcement learning (RL),attempt to address this issue but suffer from high computational costs andoften fail to produce optimal reasoning trajectories. To tackle this challenge,we propose Plan-Then-Action Enhanced Reasoning with Group Relative PolicyOptimization PTA-GRPO, a two-stage framework designed to improve bothhigh-level planning and fine-grained CoT reasoning. In the first stage, weleverage advanced LLMs to distill CoT into compact high-level guidance, whichis then used for supervised fine-tuning (SFT). In the second stage, weintroduce a guidance-aware RL method that jointly optimizes the final outputand the quality of high-level guidance, thereby enhancing reasoningeffectiveness. We conduct extensive experiments on multiple mathematicalreasoning benchmarks, including MATH, AIME2024, AIME2025, and AMC, acrossdiverse base models such as Qwen2.5-7B-Instruct, Qwen3-8B, Qwen3-14B, andLLaMA3.2-3B. Experimental results demonstrate that PTA-GRPO consistentlyachieves stable and significant improvements across different models and tasks,validating its effectiveness and generalization.
摘要: 大型语言模型（LLMs）已在复杂任务中展现出卓越的推理能力，通常依赖于思维链（CoT）推理。然而，由于其自回归的逐词生成机制，推理过程在很大程度上局限于局部决策，缺乏全局规划。这一限制常常导致推理冗余、不连贯或不准确，从而显著降低整体性能。现有方法，如基于树的算法和强化学习（RL），试图解决此问题，但计算成本高昂，且往往无法生成最优的推理轨迹。为应对这一挑战，我们提出了计划-行动增强推理与群体相对策略优化（PTA-GRPO），这是一个旨在提升高层规划和细粒度思维链推理的两阶段框架。在第一阶段，我们利用先进的大型语言模型将思维链提炼为紧凑的高层指导，并用于监督微调（SFT）。在第二阶段，我们引入一种感知指导的强化学习方法，联合优化最终输出和高层指导的质量，从而提升推理效果。我们在多个数学推理基准测试上进行了大量实验，包括MATH、AIME2024、AIME2025和AMC，测试了多种基础模型，如Qwen2.5-7B-Instruct、Qwen3-8B、Qwen3-14B和LLaMA3.2-3B。实验结果表明，PTA-GRPO在不同模型和任务上均实现了稳定且显著的改进，验证了其有效性和泛化能力。
Link: http://arxiv.org/abs/2510.01833v1
Updated: 2025-10-02T09:28:13Z

65: Pre-Hoc Predictions in AutoML: Leveraging LLMs to Enhance Model  Selection and Benchmarking for Tabular datasets
Authors: ['Yannis Belkhiter', 'Seshu Tirupathi', 'Giulio Zizzo', 'Sachin Sharma', 'John D. Kelleher']
Summary: The field of AutoML has made remarkable progress in post-hoc model selection,with libraries capable of automatically identifying the most performing modelsfor a given dataset. Nevertheless, these methods often rely on exhaustivehyperparameter searches, where methods automatically train and test differenttypes of models on the target dataset. Contrastingly, pre-hoc predictionemerges as a promising alternative, capable of bypassing exhaustive searchthrough intelligent pre-selection of models. Despite its potential, pre-hocprediction remains under-explored in the literature. This paper explores theintersection of AutoML and pre-hoc model selection by leveraging traditionalmodels and Large Language Model (LLM) agents to reduce the search space ofAutoML libraries. By relying on dataset descriptions and statisticalinformation, we reduce the AutoML search space. Our methodology is applied tothe AWS AutoGluon portfolio dataset, a state-of-the-art AutoML benchmarkcontaining 175 tabular classification datasets available on OpenML. Theproposed approach offers a shift in AutoML workflows, significantly reducingcomputational overhead, while still selecting the best model for the givendataset.
摘要: AutoML领域在事后模型选择方面取得了显著进展，相关库能够自动识别给定数据集上性能最优的模型。然而，这些方法通常依赖于穷举式超参数搜索，即自动在目标数据集上训练和测试不同类型的模型。相比之下，事前预测作为一种有前景的替代方案应运而生，能够通过智能预选模型来规避穷举搜索。尽管具有潜力，事前预测在现有文献中仍鲜有研究。本文通过利用传统模型和大型语言模型（LLM）智能体来缩小AutoML库的搜索空间，从而探索AutoML与事前模型选择的交叉领域。我们依赖数据集描述和统计信息来缩小AutoML的搜索空间。该方法应用于AWS AutoGluon组合数据集，这是一个包含OpenML上175个表格分类数据集的最先进AutoML基准。所提出的方法改变了AutoML的工作流程，显著降低了计算开销，同时仍能为给定数据集选择最佳模型。
Link: http://arxiv.org/abs/2510.01842v1
Updated: 2025-10-02T09:37:12Z

66: NGGAN: Noise Generation GAN Based on the Practical Measurement Dataset  for Narrowband Powerline Communications
Authors: ['Ying-Ren Chien', 'Po-Heng Chou', 'You-Jie Peng', 'Chun-Yuan Huang', 'Hen-Wai Tsao', 'Yu Tsao']
Summary: Capturing comprehensive statistics of nonperiodic asynchronous impulsivenoise is a critical issue in enhancing impulse noise processing for narrowbandpowerline communication (NB-PLC) transceivers. However, existing mathematicalnoise generative models capture only some of the characteristics of additivenoise. Therefore, we propose a generative adversarial network (GAN), called thenoise-generation GAN (NGGAN), that learns the complicated characteristics ofpractically measured noise samples for data augmentation. To closely match thestatistics of complicated noise in NB-PLC systems, we measured the NB-PLC noisevia the analog coupling and bandpass filtering circuits of a commercial NB-PLCmodem to build a realistic dataset. Specifically, the NGGAN design approachesbased on the practically measured dataset are as follows: (i) we design thelength of input signals that the NGGAN model can fit to facilitatecyclo-stationary noise generation. (ii) Wasserstein distance is used as a lossfunction to enhance the similarity between the generated noise and the trainingdataset and ensure that the sample diversity is sufficient for variousapplications. (iii) To measure the similarity performance of the GAN-basedmodels based on mathematical and practically measured datasets, we performquantitative and qualitative analyses. The training datasets include (1) apiecewise spectral cyclo-stationary Gaussian model (PSCGM), (2) afrequency-shift (FRESH) filter, and (3) practical measurements from NB-PLCsystems. Simulation results demonstrate that the proposed NGGAN trained usingwaveform characteristics is closer to the practically measured dataset in termsof the quality of the generated noise.
摘要: 捕获非周期性异步脉冲噪声的全面统计数据，是提升窄带电力线通信（NB-PLC）收发器脉冲噪声处理能力的关键问题。然而，现有的数学噪声生成模型仅能捕捉加性噪声的部分特征。因此，我们提出了一种生成对抗网络（GAN），称为噪声生成GAN（NGGAN），通过学习实际测量噪声样本的复杂特征来实现数据增强。为了紧密匹配NB-PLC系统中复杂噪声的统计数据，我们通过商用NB-PLC调制解调器的模拟耦合和带通滤波电路测量NB-PLC噪声，以构建一个真实的数据集。具体而言，基于实际测量数据集的NGGAN设计方案如下：（i）我们设计NGGAN模型能够拟合的输入信号长度，以促进循环平稳噪声的生成。（ii）采用Wasserstein距离作为损失函数，以增强生成噪声与训练数据集之间的相似性，并确保样本多样性足以满足各种应用需求。（iii）为评估基于数学模型和实际测量数据集的GAN模型的相似性性能，我们进行了定量和定性分析。训练数据集包括：（1）分段谱循环平稳高斯模型（PSCGM），（2）频移（FRESH）滤波器，以及（3）来自NB-PLC系统的实际测量数据。仿真结果表明，基于波形特征训练的NGGAN在生成噪声质量方面更接近实际测量数据集。
Link: http://dx.doi.org/10.1109/TIM.2024.3523361
Updated: 2025-10-02T09:47:56Z

67: Learning a Dense Reasoning Reward Model from Expert Demonstration via  Inverse Reinforcement Learning
Authors: ['Claudio Fanconi', 'Nicolás Astorga', 'Mihaela van der Schaar']
Summary: We reframe and operationalise adversarial inverse reinforcement learning(IRL) to large language model reasoning, learning a dense, token-level rewardmodel for process supervision directly from expert demonstrations rather thanimitating style via supervised fine-tuning. The learned reasoning reward servestwo complementary roles: (i) it provides step-level feedback to optimise areasoning policy during training; and (ii) it functions at inference as acritic to rerank sampled traces under fixed compute budgets. We demonstratethat our approach prioritises correctness over surface form, yielding scoresthat correlate with eventual answer validity and enabling interpretablelocalisation of errors within a trace. Empirically, on GSM8K with Llama3 andQwen2.5 backbones, we demonstrate: (i) dense reasoning rewards can be used as alearning signal to elicit reasoning, and (ii) predictive performance isimproved from reward-guided reranking (notably for Llama-based policies). Byunifying training signals, inference-time selection, and token-leveldiagnostics into a single reasoning reward, this work suggests reusableprocess-level rewards with broad potential to enhance multi-step reasoning inlanguage models.
摘要: 我们将对抗性逆强化学习（IRL）重新构建并应用于大型语言模型推理，直接从专家演示中学习一个密集的、token级别的过程监督奖励模型，而非通过监督微调来模仿风格。学习到的推理奖励具有两个互补作用：（i）在训练期间提供步骤级反馈以优化推理策略；（ii）在推理时作为评判器，在固定计算预算下对采样轨迹进行重排序。我们证明，我们的方法优先考虑正确性而非表面形式，产生的分数与最终答案有效性相关，并能在轨迹内实现错误的可解释定位。实证上，在基于Llama3和Qwen2.主干模型的GSM8K数据集上，我们展示了：（i）密集推理奖励可作为学习信号来激发推理能力；（ii）通过奖励引导的重排序提升了预测性能（尤其对基于Llama的策略）。通过将训练信号、推理时选择和token级诊断统一到单一推理奖励中，本研究提出了可复用的过程级奖励，具有增强语言模型多步推理能力的广泛潜力。
Link: http://arxiv.org/abs/2510.01857v1
Updated: 2025-10-02T09:55:26Z

68: A Modular Theory of Subjective Consciousness for Natural and Artificial  Minds
Authors: ['Michaël Gillon']
Summary: Understanding how subjective experience arises from information processingremains a central challenge in neuroscience, cognitive science, and AIresearch. The Modular Consciousness Theory (MCT) proposes a biologicallygrounded and computationally explicit framework in which consciousness is adiscrete sequence of Integrated Informational States (IISs). Each IIS is apacket of integrated information tagged with a multidimensional density vectorthat quantifies informational richness. Its magnitude correlates withsubjective intensity, shaping memory, behavior, and continuity of experience.Inputs from body and environment are adaptively filtered, processed by modules(abstraction, narration, evaluation, self-evaluation), and integrated into anIIS. The resulting packet, tagged with its density vector, is transmitted tobehavioral readiness, memory, and decision-making modules, closing the loop.This explains why strongly tagged states exert greater influence on long-termmemory and action. Unlike Global Workspace Theory, Integrated InformationTheory, or Higher-Order Thought, MCT specifies a full computational pipelineproducing discrete informational units with quantifiable internal structure.Subjectivity is reframed as a correlate of the density-tagging signal withfunctional consequences. MCT generates testable predictions, such as stressenhancing memory encoding, and provides a naturalistic blueprint for bothbiological and artificial architectures. Consciousness, in this view, is not anirreducible essence but an evolvable, quantifiable, and constructible featureof complex information processing.
摘要: 理解主观体验如何从信息处理中产生，仍然是神经科学、认知科学和人工智能研究中的一个核心挑战。模块意识理论（MCT）提出了一种基于生物学且计算上明确的框架，在该框架中，意识是一系列离散的整合信息状态（IIS）。每个IIS都是一个整合信息包，并带有一个多维密度向量标签，该向量量化了信息的丰富度。其大小与主观强度相关，塑造了记忆、行为和体验的连续性。来自身体和环境的输入会经过自适应过滤，由模块（抽象、叙述、评估、自我评估）处理，并整合成一个IIS。由此产生的信息包，连同其密度向量标签，被传输至行为准备、记忆和决策模块，从而形成闭环。这解释了为何强标签状态对长期记忆和行动具有更大影响。与全局工作空间理论、整合信息理论或高阶思维理论不同，MCT指定了一个完整的计算流程，该流程产生具有可量化内部结构的离散信息单元。主观性被重新定义为密度标签信号的功能性相关物。MCT提出了可检验的预测，例如压力增强记忆编码，并为生物和人工架构提供了自然主义的蓝图。在此视角下，意识并非不可还原的本质，而是复杂信息处理中一种可演化、可量化且可构建的特征。
Link: http://arxiv.org/abs/2510.01864v1
Updated: 2025-10-02T10:11:56Z

69: TACOS: Task Agnostic COordinator of a multi-drone System
Authors: ['Alessandro Nazzari', 'Roberto Rubinacci', 'Marco Lovera']
Summary: When a single pilot is responsible for managing a multi-drone system, thetask demands varying levels of autonomy, from direct control of individualUAVs, to group-level coordination, to fully autonomous swarm behaviors foraccomplishing high-level tasks. Enabling such flexible interaction requires aframework that supports multiple modes of shared autonomy. As language modelscontinue to improve in reasoning and planning, they provide a naturalfoundation for such systems, reducing pilot workload by enabling high-leveltask delegation through intuitive, language-based interfaces. In this paper wepresent TACOS (Task-Agnostic COordinator of a multi-drone System), a unifiedframework that enables high-level natural language control of multi-UAV systemsthrough Large Language Models (LLMs). TACOS integrates three key capabilitiesinto a single architecture: a one-to-many natural language interface forintuitive user interaction, an intelligent coordinator for translating userintent into structured task plans, and an autonomous agent that executes plansinteracting with the real-world. TACOS allows a LLM to interact with a libraryof executable APIs, bridging semantic reasoning with real-time multi-robotcoordination. We demonstrate the system in real-world multi-drone system andconduct an ablation study to assess the contribution of each module.
摘要: 当一名飞行员负责管理一个多无人机系统时，该任务需要不同级别的自主性，从对单个无人机的直接控制，到群体级协调，再到为实现高级任务而采取的完全自主的群体行为。实现这种灵活的交互需要一个支持多种共享自主模式的框架。随着语言模型在推理和规划方面的持续改进，它们为这类系统提供了自然的基础，通过直观的、基于语言的界面实现高级任务委派，从而减轻飞行员的工作负荷。在本文中，我们提出了TACOS（多无人机系统的任务不可知协调器），这是一个统一的框架，通过大型语言模型（LLM）实现对多无人机系统的高级自然语言控制。TACOS将三项关键功能集成到单一架构中：用于直观用户交互的一对多自然语言界面、将用户意图转化为结构化任务计划的智能协调器，以及与现实世界交互以执行计划的自主代理。TACOS允许大型语言模型与可执行API库进行交互，从而将语义推理与实时多机器人协调连接起来。我们在真实世界的多无人机系统中展示了该系统，并进行了消融研究以评估每个模块的贡献。
Link: http://arxiv.org/abs/2510.01869v1
Updated: 2025-10-02T10:21:35Z

70: REPAIR: Robust Editing via Progressive Adaptive Intervention and  Reintegration
Authors: ['Yisu Wang', 'Ming Wang', 'Haoyuan Song', 'Wenjie Huang', 'Chaozheng Wang', 'Yi Xie', 'Xuming Ran']
Summary: Post-training for large language models (LLMs) is constrained by the highcost of acquiring new knowledge or correcting errors and by the unintended sideeffects that frequently arise from retraining. To address these issues, weintroduce REPAIR (Robust Editing via Progressive Adaptive Intervention andReintegration), a lifelong editing framework designed to support precise andlow-cost model updates while preserving non-target knowledge. REPAIR mitigatesthe instability and conflicts of large-scale sequential edits through aclosed-loop feedback mechanism coupled with dynamic memory management.Furthermore, by incorporating frequent knowledge fusion and enforcing stronglocality guards, REPAIR effectively addresses the shortcomings of traditionaldistribution-agnostic approaches that often overlook unintended ripple effects.Our experiments demonstrate that REPAIR boosts editing accuracy by 10%-30%across multiple model families and significantly reduces knowledge forgetting.This work introduces a robust framework for developing reliable, scalable, andcontinually evolving LLMs.
摘要: 大型语言模型（LLMs）的后训练受到获取新知识或纠正错误的高成本以及再训练过程中频繁出现的意外副作用的制约。为解决这些问题，我们提出了REPAIR（通过渐进式自适应干预与再整合的鲁棒编辑），这是一种终身编辑框架，旨在支持精确且低成本的模型更新，同时保留非目标知识。REPAIR通过结合闭环反馈机制与动态内存管理，缓解了大规模顺序编辑中的不稳定性和冲突。此外，通过融入频繁的知识融合并实施强局部性保护，REPAIR有效解决了传统分布不可知方法常忽略意外涟漪效应的缺陷。我们的实验表明，REPAIR在多个模型系列中将编辑准确率提升了10%-30%，并显著减少了知识遗忘。这项工作为开发可靠、可扩展且持续进化的LLMs引入了一个鲁棒框架。
Link: http://arxiv.org/abs/2510.01879v1
Updated: 2025-10-02T10:35:39Z

71: FINCH: Financial Intelligence using Natural language for Contextualized  SQL Handling
Authors: ['Avinash Kumar Singh', 'Bhaskarjit Sarmah', 'Stefano Pasquali']
Summary: Text-to-SQL, the task of translating natural language questions into SQLqueries, has long been a central challenge in NLP. While progress has beensignificant, applying it to the financial domain remains especially difficultdue to complex schema, domain-specific terminology, and high stakes of error.Despite this, there is no dedicated large-scale financial dataset to advanceresearch, creating a critical gap. To address this, we introduce a curatedfinancial dataset (FINCH) comprising 292 tables and 75,725 natural language-SQLpairs, enabling both fine-tuning and rigorous evaluation. Building on thisresource, we benchmark reasoning models and language models of varying scales,providing a systematic analysis of their strengths and limitations in financialText-to-SQL tasks. Finally, we propose a finance-oriented evaluation metric(FINCH Score) that captures nuances overlooked by existing measures, offering amore faithful assessment of model performance.
摘要: 文本到SQL，即将自然语言问题翻译成SQL查询的任务，长期以来一直是自然语言处理领域的一个核心挑战。尽管取得了显著进展，但由于其复杂的模式、特定领域的术语以及错误的高风险性，将其应用于金融领域仍然尤为困难。尽管如此，目前尚无专门的大规模金融数据集来推动研究，从而造成了一个关键空白。为解决这一问题，我们引入了一个精心策划的金融数据集（FINCH），包含292个表格和75,725个自然语言与SQL配对，支持模型的微调和严格评估。基于这一资源，我们对不同规模的推理模型和语言模型进行了基准测试，系统性地分析了它们在金融文本到SQL任务中的优势与局限。最后，我们提出了一种面向金融的评估指标（FINCH Score），该指标能够捕捉现有衡量标准忽略的细微差别，从而对模型性能提供更真实的评估。
Link: http://arxiv.org/abs/2510.01887v1
Updated: 2025-10-02T10:55:11Z

72: Small is Sufficient: Reducing the World AI Energy Consumption Through  Model Selection
Authors: ['Tiago da Silva Barros', 'Frédéric Giroire', 'Ramon Aparicio-Pardo', 'Joanna Moulierac']
Summary: The energy consumption and carbon footprint of Artificial Intelligence (AI)have become critical concerns due to rising costs and environmental impacts. Inresponse, a new trend in green AI is emerging, shifting from the "bigger isbetter" paradigm, which prioritizes large models, to "small is sufficient",emphasizing energy sobriety through smaller, more efficient models.  We explore how the AI community can adopt energy sobriety today by focusingon model selection during inference. Model selection consists of choosing themost appropriate model for a given task, a simple and readily applicablemethod, unlike approaches requiring new hardware or architectures. Ourhypothesis is that, as in many industrial activities, marginal utility gainsdecrease with increasing model size. Thus, applying model selection cansignificantly reduce energy consumption while maintaining good utility for AIinference.  We conduct a systematic study of AI tasks, analyzing their popularity, modelsize, and efficiency. We examine how the maturity of different tasks and modeladoption patterns impact the achievable energy savings, ranging from 1% to 98%for different tasks. Our estimates indicate that applying model selection couldreduce AI energy consumption by 27.8%, saving 31.9 TWh worldwide in 2025 -equivalent to the annual output of five nuclear power reactors.
摘要: 人工智能（AI）的能源消耗和碳足迹已成为关键问题，原因在于不断上升的成本和环境影响。对此，绿色AI的新趋势正在兴起，从优先考虑大型模型的“越大越好”范式，转向强调通过更小、更高效模型实现能源节约的“小即足够”理念。我们探讨了AI社区如何通过在推理阶段关注模型选择来践行能源节约。模型选择是指为特定任务选择最合适的模型，这是一种简单且易于应用的方法，不同于需要新硬件或架构的方法。我们的假设是，与许多工业活动类似，边际效用增益随模型规模增大而递减。因此，应用模型选择可以在保持AI推理良好效用的同时，显著降低能源消耗。我们对AI任务进行了系统性研究，分析了其流行度、模型规模和效率。我们考察了不同任务的成熟度和模型采用模式如何影响可实现的能源节约，不同任务的节约幅度从1%到98%不等。我们的估计表明，应用模型选择可使AI能源消耗降低27.8%，到2025年全球可节省31.9太瓦时——相当于五座核反应堆的年发电量。
Link: http://arxiv.org/abs/2510.01889v1
Updated: 2025-10-02T10:58:13Z

73: HRTFformer: A Spatially-Aware Transformer for Personalized HRTF  Upsampling in Immersive Audio Rendering
Authors: ['Xuyi Hu', 'Jian Li', 'Shaojie Zhang', 'Stefan Goetz', 'Lorenzo Picinali', 'Ozgur B. Akan', 'Aidan O. T. Hogg']
Summary: Personalized Head-Related Transfer Functions (HRTFs) are starting to beintroduced in many commercial immersive audio applications and are crucial forrealistic spatial audio rendering. However, one of the main hesitationsregarding their introduction is that creating personalized HRTFs is impracticalat scale due to the complexities of the HRTF measurement process. To mitigatethis drawback, HRTF spatial upsampling has been proposed with the aim ofreducing measurements required. While prior work has seen success withdifferent machine learning (ML) approaches, these models often struggle withlong-range spatial consistency and generalization at high upsampling factors.In this paper, we propose a novel transformer-based architecture for HRTFupsampling, leveraging the attention mechanism to better capture spatialcorrelations across the HRTF sphere. Working in the spherical harmonic (SH)domain, our model learns to reconstruct high-resolution HRTFs from sparse inputmeasurements with significantly improved accuracy. To enhance spatialcoherence, we introduce a neighbor dissimilarity loss that promotes magnitudesmoothness, yielding more realistic upsampling. We evaluate our method usingboth perceptual localization models and objective spectral distortion metrics.Experiments show that our model surpasses leading methods by a substantialmargin in generating realistic, high-fidelity HRTFs.
摘要: 个性化头部相关传递函数（HRTF）正开始被引入许多商业沉浸式音频应用中，对于实现逼真的空间音频渲染至关重要。然而，关于其推广应用的主要顾虑之一在于，由于HRTF测量过程的复杂性，大规模创建个性化HRTF并不可行。为缓解这一缺陷，HRTF空间上采样技术被提出，旨在减少所需的测量次数。尽管先前的研究通过不同的机器学习方法取得了一定成功，但这些模型在高上采样率下往往难以保持长程空间一致性和泛化能力。本文中，我们提出了一种基于Transformer的新型HRTF上采样架构，利用注意力机制更好地捕捉HRTF球面上的空间相关性。在球谐（SH）域中工作，我们的模型能够从稀疏输入测量中重建高分辨率HRTF，且准确性显著提升。为增强空间连贯性，我们引入了一种邻居不相似度损失函数，以促进幅度平滑性，从而生成更逼真的上采样结果。我们通过感知定位模型和客观频谱失真指标对方法进行了评估。实验表明，在生成逼真、高保真度HRTF方面，我们的模型以显著优势超越了现有领先方法。
Link: http://arxiv.org/abs/2510.01891v1
Updated: 2025-10-02T10:59:21Z

74: Multimodal Foundation Models for Early Disease Detection
Authors: ['Md Talha Mohsin', 'Ismail Abdulrashid']
Summary: Healthcare generates diverse streams of data, including electronic healthrecords (EHR), medical imaging, genetics, and ongoing monitoring from wearabledevices. Traditional diagnostic models frequently analyze these sources inisolation, which constrains their capacity to identify cross-modal correlationsessential for early disease diagnosis. Our research presents a multimodalfoundation model that consolidates diverse patient data through anattention-based transformer framework. At first, dedicated encoders put eachmodality into a shared latent space. Then, they combine them using multi-headattention and residual normalization. The architecture is made for pretrainingon many tasks, which makes it easy to adapt to new diseases and datasets withlittle extra work. We provide an experimental strategy that uses benchmarkdatasets in oncology, cardiology, and neurology, with the goal of testing earlydetection tasks. The framework includes data governance and model managementtools in addition to technological performance to improve transparency,reliability, and clinical interpretability. The suggested method works toward asingle foundation model for precision diagnostics, which could improve theaccuracy of predictions and help doctors make decisions.
摘要: 医疗领域会产生多种数据流，包括电子健康记录（EHR）、医学影像、基因数据以及来自可穿戴设备的持续监测数据。传统的诊断模型通常孤立地分析这些数据源，这限制了其识别对早期疾病诊断至关重要的跨模态关联的能力。我们的研究提出了一种多模态基础模型，它通过一个基于注意力的Transformer框架来整合多样化的患者数据。首先，专用编码器将每种模态数据映射到一个共享的潜在空间中。然后，通过多头注意力机制和残差归一化将它们融合。该架构专为在多项任务上进行预训练而设计，使其能够轻松适应新的疾病和数据集，而无需额外的大量工作。我们提供了一种实验策略，该策略利用肿瘤学、心脏病学和神经学领域的基准数据集，旨在测试早期检测任务。该框架除技术性能外，还包含数据治理和模型管理工具，以提高透明度、可靠性和临床可解释性。所提出的方法致力于构建一个用于精准诊断的统一基础模型，有望提高预测准确性并辅助医生进行决策。
Link: http://arxiv.org/abs/2510.01899v1
Updated: 2025-10-02T11:12:57Z

75: Constrained Adaptive Rejection Sampling
Authors: ['Paweł Parys', 'Sairam Vaidya', 'Taylor Berg-Kirkpatrick', "Loris D'Antoni"]
Summary: Language Models (LMs) are increasingly used in applications where generatedoutputs must satisfy strict semantic or syntactic constraints. Existingapproaches to constrained generation fall along a spectrum: greedy constraineddecoding methods enforce validity during decoding but distort the LM'sdistribution, while rejection sampling (RS) preserves fidelity but wastescomputation by discarding invalid outputs. Both extremes are problematic indomains such as program fuzzing, where both validity and diversity of samplesare essential. We present Constrained Adaptive Rejection Sampling (CARS), anapproach that strictly improves the sample-efficiency of RS withoutdistributional distortion. CARS begins with unconstrained LM sampling andadaptively rules out constraint-violating continuations by recording them in atrie and subtracting their probability mass from future draws. This adaptivepruning ensures that prefixes proven invalid are never revisited, acceptancerates improve monotonically, and the resulting samples exactly follow theconstrained distribution. In experiments on a variety of domains -- e.g.,program fuzzing and molecular generation -- CARS consistently achieves higherefficiency -- measured in the number of LM forward passes per valid sample --while also producing stronger sample diversity than both GCD and methods thatapproximate the LM's distribution.
摘要: 语言模型（LMs）在生成的输出必须满足严格语义或句法约束的应用中日益普及。现有的约束生成方法涵盖了一个范围：贪婪约束解码方法在解码过程中强制保证有效性，但会扭曲语言模型的分布；而拒绝采样（RS）虽然保真度，但会因丢弃无效输出而浪费计算资源。在程序模糊测试等领域，这两种极端方法都存在问题，因为样本的有效性和多样性都至关重要。我们提出了约束自适应拒绝采样（CARS），这是一种在不扭曲分布的情况下严格提升拒绝采样样本效率的方法。CARS从无约束的语言模型采样开始，通过将违反约束的后续内容记录在字典树中并从后续抽取中减去其概率质量来自适应地排除它们。这种自适应修剪确保已证明无效的前缀永远不会被再次访问，接受率单调提升，且生成的样本精确遵循约束分布。在多个领域（如程序模糊测试和分子生成）的实验中，CARS在效率（以每有效样本的语言模型前向传播次数衡量）方面始终优于贪婪约束解码和近似语言模型分布的方法，同时还能产生更强的样本多样性。
Link: http://arxiv.org/abs/2510.01902v1
Updated: 2025-10-02T11:17:26Z

76: Are LLMs Better GNN Helpers? Rethinking Robust Graph Learning under  Deficiencies with Iterative Refinement
Authors: ['Zhaoyan Wang', 'Zheng Gao', 'Arogya Kharel', 'In-Young Ko']
Summary: Graph Neural Networks (GNNs) are widely adopted in Web-related applications,serving as a core technique for learning from graph-structured data, such astext-attributed graphs. Yet in real-world scenarios, such graphs exhibitdeficiencies that substantially undermine GNN performance. While priorGNN-based augmentation studies have explored robustness against individualimperfections, a systematic understanding of how graph-native and LargeLanguage Models (LLMs) enhanced methods behave under compound deficiencies isstill missing. Specifically, there has been no comprehensive investigationcomparing conventional approaches and recent LLM-on-graph frameworks, leavingtheir merits unclear. To fill this gap, we conduct the first empirical studythat benchmarks these two lines of methods across diverse graph deficiencies,revealing overlooked vulnerabilities and challenging the assumption that LLMaugmentation is consistently superior. Building on empirical findings, wepropose Robust Graph Learning via Retrieval-Augmented Contrastive Refinement(RoGRAD) framework. Unlike prior one-shot LLM-as-Enhancer designs, RoGRAD isthe first iterative paradigm that leverages Retrieval-Augmented Generation(RAG) to inject retrieval-grounded augmentations by supplying class-consistent,diverse augmentations and enforcing discriminative representations throughiterative graph contrastive learning. It transforms LLM augmentation for graphsfrom static signal injection into dynamic refinement. Extensive experimentsdemonstrate RoGRAD's superiority over both conventional GNN- and LLM-enhancedbaselines, achieving up to 82.43% average improvement.
摘要: 图神经网络（GNNs）在Web相关应用中被广泛采用，作为从图结构数据（如文本属性图）中学习的核心技术。然而，在现实场景中，此类图存在缺陷，严重损害了GNN的性能。尽管先前基于GNN的增强研究已探讨了针对单一不完美性的鲁棒性，但对于图原生方法和大语言模型（LLMs）增强方法在复合缺陷下的表现仍缺乏系统性理解。具体而言，目前尚未有全面研究对传统方法和最新的LLM-on-graph框架进行比较，导致其优劣不明确。为填补这一空白，我们开展了首个实证研究，在多种图缺陷上对这两类方法进行基准测试，揭示了被忽视的脆弱性，并挑战了LLM增强始终更优的假设。基于实证发现，我们提出了基于检索增强对比优化的鲁棒图学习（RoGRAD）框架。不同于先前的一次性LLM作为增强器的设计，RoGRAD是首个迭代范式，它利用检索增强生成（RAG）通过提供类别一致且多样的增强数据，并通过迭代图对比学习强制执行判别性表示，从而注入基于检索的增强。它将图的LLM增强从静态信号注入转变为动态优化。大量实验证明，RoGRAD优于传统GNN和LLM增强的基线方法，平均性能提升高达82.43%。
Link: http://arxiv.org/abs/2510.01910v1
Updated: 2025-10-02T11:30:51Z

77: Automated Defect Detection for Mass-Produced Electronic Components Based  on YOLO Object Detection Models
Authors: ['Wei-Lung Mao', 'Chun-Chi Wang', 'Po-Heng Chou', 'Yen-Ting Liu']
Summary: Since the defect detection of conventional industry components istime-consuming and labor-intensive, it leads to a significant burden on qualityinspection personnel and makes it difficult to manage product quality. In thispaper, we propose an automated defect detection system for the dual in-linepackage (DIP) that is widely used in industry, using digital camera optics anda deep learning (DL)-based model. The two most common defect categories of DIPare examined: (1) surface defects, and (2) pin-leg defects. However, the lackof defective component images leads to a challenge for detection tasks. Tosolve this problem, the ConSinGAN is used to generate a suitable-sized datasetfor training and testing. Four varieties of the YOLO model are investigated(v3, v4, v7, and v9), both in isolation and with the ConSinGAN augmentation.The proposed YOLOv7 with ConSinGAN is superior to the other YOLO versions inaccuracy of 95.50\%, detection time of 285 ms, and is far superior tothreshold-based approaches. In addition, the supervisory control and dataacquisition (SCADA) system is developed, and the associated sensor architectureis described. The proposed automated defect detection can be easily establishedwith numerous types of defects or insufficient defect data.
摘要: 由于传统工业组件的缺陷检测耗时且费力，这给质检人员带来了沉重负担，并使得产品质量管理变得困难。在本文中，我们提出了一种针对工业中广泛使用的双列直插式封装（DIP）的自动化缺陷检测系统，该系统采用数码相机光学技术和基于深度学习（DL）的模型。我们研究了DIP最常见的两类缺陷：（1）表面缺陷和（2）引脚缺陷。然而，缺陷组件图像的缺乏给检测任务带来了挑战。为解决这一问题，我们使用ConSinGAN生成适用于训练和测试的合适规模数据集。我们研究了四种YOLO模型变体（v3、v4、v7和v9），分别独立测试并结合ConSinGAN数据增强。所提出的结合ConSinGAN的YOLOv7模型在准确率上达到95.50%，检测时间为285毫秒，优于其他YOLO版本，且远超基于阈值的方法。此外，我们还开发了监控与数据采集（SCADA）系统，并描述了相关的传感器架构。所提出的自动化缺陷检测方法可轻松应用于多种缺陷类型或缺陷数据不足的场景。
Link: http://dx.doi.org/10.1109/JSEN.2024.3418618
Updated: 2025-10-02T11:33:16Z

78: To Mask or to Mirror: Human-AI Alignment in Collective Reasoning
Authors: ['Crystal Qian', 'Aaron Parisi', 'Clémentine Bouleau', 'Vivian Tsai', 'Maël Lebreton', 'Lucas Dixon']
Summary: As large language models (LLMs) are increasingly used to model and augmentcollective decision-making, it is critical to examine their alignment withhuman social reasoning. We present an empirical framework for assessingcollective alignment, in contrast to prior work on the individual level. Usingthe Lost at Sea social psychology task, we conduct a large-scale onlineexperiment (N=748), randomly assigning groups to leader elections with eithervisible demographic attributes (e.g. name, gender) or pseudonymous aliases. Wethen simulate matched LLM groups conditioned on the human data, benchmarkingGemini 2.5, GPT 4.1, Claude Haiku 3.5, and Gemma 3. LLM behaviors diverge: somemirror human biases; others mask these biases and attempt to compensate forthem. We empirically demonstrate that human-AI alignment in collectivereasoning depends on context, cues, and model-specific inductive biases.Understanding how LLMs align with collective human behavior is critical toadvancing socially-aligned AI, and demands dynamic benchmarks that capture thecomplexities of collective reasoning.
摘要: 随着大型语言模型（LLMs）越来越多地被用于建模和增强集体决策，审视其与人类社会推理的一致性变得至关重要。我们提出了一个评估集体一致性的实证框架，这与先前在个体层面的研究有所不同。我们使用“海上迷途”社会心理学任务，开展了一项大规模在线实验（N=748），将小组随机分配到具有可见人口统计属性（如姓名、性别）或化名别称的领导者选举中。随后，我们基于人类数据模拟匹配的LLM小组，对Gemini 2.5、GPT 4.1、Claude Haiku 3.5和Gemma 3进行基准测试。LLM的行为表现各异：一些模型反映了人类偏见；另一些则掩盖了这些偏见并试图加以弥补。我们实证证明，集体推理中的人机一致性取决于情境、线索以及模型特有的归纳偏置。理解LLMs如何与集体人类行为保持一致，对于推进与社会对齐的AI至关重要，并且需要能够捕捉集体推理复杂性的动态基准。
Link: http://arxiv.org/abs/2510.01924v1
Updated: 2025-10-02T11:41:30Z

79: Foundation Visual Encoders Are Secretly Few-Shot Anomaly Detectors
Authors: ['Guangyao Zhai', 'Yue Zhou', 'Xinyan Deng', 'Lars Heckler', 'Nassir Navab', 'Benjamin Busam']
Summary: Few-shot anomaly detection streamlines and simplifies industrial safetyinspection. However, limited samples make accurate differentiation betweennormal and abnormal features challenging, and even more so undercategory-agnostic conditions. Large-scale pre-training of foundation visualencoders has advanced many fields, as the enormous quantity of data helps tolearn the general distribution of normal images. We observe that the anomalyamount in an image directly correlates with the difference in the learntembeddings and utilize this to design a few-shot anomaly detector termedFoundAD. This is done by learning a nonlinear projection operator onto thenatural image manifold. The simple operator acts as an effective tool foranomaly detection to characterize and identify out-of-distribution regions inan image. Extensive experiments show that our approach supports multi-classdetection and achieves competitive performance while using substantially fewerparameters than prior methods. Backed up by evaluations with multiplefoundation encoders, including fresh DINOv3, we believe this idea broadens theperspective on foundation features and advances the field of few-shot anomalydetection.
摘要: 少样本异常检测简化并精简了工业安全检查。然而，有限的样本使得准确区分正常与异常特征具有挑战性，在类别不可知的情况下尤为如此。基础视觉编码器的大规模预训练推动了众多领域的发展，因为海量的数据有助于学习正常图像的通用分布。我们观察到，图像中的异常程度与所学嵌入的差异直接相关，并利用这一点设计了一个名为FoundAD的少样本异常检测器。这是通过学习一个到自然图像流形的非线性投影算子来实现的。这个简单的算子作为异常检测的有效工具，用于表征和识别图像中的分布外区域。大量实验表明，我们的方法支持多类检测，并在使用比先前方法少得多的参数的情况下实现了具有竞争力的性能。经过包括全新DINOv3在内的多种基础编码器的评估支持，我们相信这一思路拓宽了对基础特征的认知，并推动了少样本异常检测领域的发展。
Link: http://arxiv.org/abs/2510.01934v1
Updated: 2025-10-02T11:53:20Z

80: Exploring Resolution-Wise Shared Attention in Hybrid Mamba-U-Nets for  Improved Cross-Corpus Speech Enhancement
Authors: ['Nikolai Lund Kühne', 'Jesper Jensen', 'Jan Østergaard', 'Zheng-Hua Tan']
Summary: Recent advances in speech enhancement have shown that models combining Mambaand attention mechanisms yield superior cross-corpus generalizationperformance. At the same time, integrating Mamba in a U-Net structure hasyielded state-of-the-art enhancement performance, while reducing both modelsize and computational complexity. Inspired by these insights, we proposeRWSA-MambaUNet, a novel and efficient hybrid model combining Mamba andmulti-head attention in a U-Net structure for improved cross-corpusperformance. Resolution-wise shared attention (RWSA) refers to layerwiseattention-sharing across corresponding time- and frequency resolutions. Ourbest-performing RWSA-MambaUNet model achieves state-of-the-art generalizationperformance on two out-of-domain test sets. Notably, our smallest modelsurpasses all baselines on the out-of-domain DNS 2020 test set in terms ofPESQ, SSNR, and ESTOI, and on the out-of-domain EARS-WHAM_v2 test set in termsof SSNR, ESTOI, and SI-SDR, while using less than half the model parameters anda fraction of the FLOPs.
摘要: 语音增强领域的最新进展表明，结合Mamba和注意力机制的模型能够实现卓越的跨语料库泛化性能。同时，将Mamba集成到U-Net结构中不仅取得了最先进的增强性能，还减小了模型规模和计算复杂度。受这些见解的启发，我们提出了RWSA-MambaUNet，这是一种新颖高效的混合模型，在U-Net结构中结合了Mamba和多头注意力机制，以提升跨语料库性能。分辨率级共享注意力（RWSA）指在对应的时间和频率分辨率上进行逐层注意力共享。我们性能最佳的RWSA-MambaUNet模型在两个域外测试集上实现了最先进的泛化性能。值得注意的是，我们最小的模型在域外DNS 2020测试集上的PESQ、SSNR和ESTOI指标，以及在域外EARS-WHAM_v2测试集上的SSNR、ESTOI和SI-SDR指标上均超越了所有基线模型，而其使用的模型参数不到前者的一半，浮点运算次数也仅为一小部分。
Link: http://arxiv.org/abs/2510.01958v1
Updated: 2025-10-02T12:27:29Z

81: ZK-WAGON: Imperceptible Watermark for Image Generation Models using  ZK-SNARKs
Authors: ['Aadarsh Anantha Ramakrishnan', 'Shubham Agarwal', 'Selvanayagam S', 'Kunwar Singh']
Summary: As image generation models grow increasingly powerful and accessible,concerns around authenticity, ownership, and misuse of synthetic media havebecome critical. The ability to generate lifelike images indistinguishable fromreal ones introduces risks such as misinformation, deepfakes, and intellectualproperty violations. Traditional watermarking methods either degrade imagequality, are easily removed, or require access to confidential model internals- making them unsuitable for secure and scalable deployment. We are the firstto introduce ZK-WAGON, a novel system for watermarking image generation modelsusing the Zero-Knowledge Succinct Non Interactive Argument of Knowledge(ZK-SNARKs). Our approach enables verifiable proof of origin without exposingmodel weights, generation prompts, or any sensitive internal information. Wepropose Selective Layer ZK-Circuit Creation (SL-ZKCC), a method to selectivelyconvert key layers of an image generation model into a circuit, reducing proofgeneration time significantly. Generated ZK-SNARK proofs are imperceptiblyembedded into a generated image via Least Significant Bit (LSB) steganography.We demonstrate this system on both GAN and Diffusion models, providing asecure, model-agnostic pipeline for trustworthy AI image generation.
摘要: 随着图像生成模型变得越来越强大和易于获取，围绕合成媒体的真实性、所有权和滥用问题已变得至关重要。生成与真实图像无法区分的逼真图像的能力，会带来虚假信息、深度伪造和知识产权侵权等风险。传统的水印方法要么会降低图像质量，要么容易被移除，要么需要访问机密的模型内部信息，这使它们不适合安全且可扩展的部署。我们是首个引入ZK-WAGON的系统，该系统利用零知识简洁非交互式知识论证（ZK-SNARKs）为图像生成模型添加水印。我们的方法能够在不暴露模型权重、生成提示符或任何敏感内部信息的情况下，提供可验证的来源证明。我们提出了选择性层ZK电路创建（SL-ZKCC）方法，该方法将图像生成模型的关键层选择性转换为电路，从而显著减少证明生成时间。生成的ZK-SNARK证明通过最低有效位（LSB）隐写术被不可察觉地嵌入到生成的图像中。我们在生成对抗网络和扩散模型上均展示了该系统，为可信的AI图像生成提供了一个安全、模型无关的流程。
Link: http://arxiv.org/abs/2510.01967v1
Updated: 2025-10-02T12:39:57Z

82: Clarifying Semantics of In-Context Examples for Unit Test Generation
Authors: ['Chen Yang', 'Lin Yang', 'Ziqi Wang', 'Dong Wang', 'Jianyi Zhou', 'Junjie Chen']
Summary: Recent advances in large language models (LLMs) have enabled promisingperformance in unit test generation through in-context learning (ICL). However,the quality of in-context examples significantly influences the effectivenessof generated tests-poorly structured or semantically unclear test examplesoften lead to suboptimal outputs. In this paper, we propose CLAST, a noveltechnique that systematically refines unit tests to improve their semanticclarity, thereby enhancing their utility as in-context examples. The approachdecomposes complex tests into logically clearer ones and improves semanticclarity through a combination of program analysis and LLM-based rewriting. Weevaluated CLAST on four open-source and three industrial projects. The resultsdemonstrate that CLAST largely outperforms UTgen, the state-of-the-artrefinement technique, in both preserving test effectiveness and enhancingsemantic clarity. Specifically, CLAST fully retains the original effectivenessof unit tests, while UTgen reduces compilation success rate (CSR), pass rate(PR), test coverage (Cov), and mutation score (MS) by an average of 12.90%,35.82%, 4.65%, and 5.07%, respectively. Over 85.33% of participants in our userstudy preferred the semantic clarity of CLAST-refined tests. Notably,incorporating CLAST-refined tests as examples effectively improves ICL-basedunit test generation approaches such as RAGGen and TELPA, resulting in anaverage increase of 25.97% in CSR, 28.22% in PR, and 45.99% in Cov forgenerated tests, compared to incorporating UTgen-refined tests. The insightsfrom the follow-up user study not only reinforce CLAST's potential impact insoftware testing practice but also illuminate avenues for future research.
摘要: 大型语言模型（LLMs）的最新进展通过上下文学习（ICL）在单元测试生成方面展现出良好的性能。然而，上下文示例的质量显著影响生成测试的有效性——结构不良或语义不清晰的测试示例往往导致次优输出。在本文中，我们提出了CLAST，这是一种新颖技术，通过系统性地优化单元测试来提升其语义清晰度，从而增强其作为上下文示例的实用性。该方法将复杂测试分解为逻辑更清晰的测试，并结合程序分析和基于LLM的重写来提升语义清晰度。我们在四个开源项目和三个工业项目上对CLAST进行了评估。结果表明，在保留测试有效性和提升语义清晰度方面，CLAST显著优于最先进的优化技术UTgen。具体而言，CLAST完全保留了单元测试的原始有效性，而UTgen则使编译成功率（CSR）、通过率（PR）、测试覆盖率（Cov）和变异得分（MS）分别平均降低了12.90%、35.82%、4.65%和5.07%。在我们用户研究中，超过85.33%的参与者更倾向于CLAST优化后的测试的语义清晰度。值得注意的是，将CLAST优化后的测试作为示例，有效提升了基于ICL的单元测试生成方法（如RAGGen和TELPA）的性能，与采用UTgen优化后的测试相比，生成测试的CSR、PR和Cov分别平均提升了25.97%、28.22%和45.99%。后续用户研究的见解不仅强化了CLAST在软件测试实践中的潜在影响，也为未来研究指明了方向。
Link: http://arxiv.org/abs/2510.01994v1
Updated: 2025-10-02T13:15:40Z

83: Generating Findings for Jaw Cysts in Dental Panoramic Radiographs Using  GPT-4o: Building a Two-Stage Self-Correction Loop with Structured Output  (SLSO) Framework
Authors: ['Nanaka Hosokawa', 'Ryo Takahashi', 'Tomoya Kitano', 'Yukihiro Iida', 'Chisako Muramatsu', 'Tatsuro Hayashi', 'Yuta Seino', 'Xiangrong Zhou', 'Takeshi Hara', 'Akitoshi Katsumata', 'Hiroshi Fujita']
Summary: In this study, we utilized the multimodal capabilities of OpenAI GPT-4o toautomatically generate jaw cyst findings on dental panoramic radiographs. Toimprove accuracy, we constructed a Self-correction Loop with Structured Output(SLSO) framework and verified its effectiveness. A 10-step process wasimplemented for 22 cases of jaw cysts, including image input and analysis,structured data generation, tooth number extraction and consistency checking,iterative regeneration when inconsistencies were detected, and findinggeneration with subsequent restructuring and consistency verification. Acomparative experiment was conducted using the conventional Chain-of-Thought(CoT) method across seven evaluation items: transparency, internal structure,borders, root resorption, tooth movement, relationships with other structures,and tooth number. The results showed that the proposed SLSO framework improvedoutput accuracy for many items, with 66.9%, 33.3%, and 28.6% improvement ratesfor tooth number, tooth movement, and root resorption, respectively. In thesuccessful cases, a consistently structured output was achieved after up tofive regenerations. Although statistical significance was not reached becauseof the small size of the dataset, the overall SLSO framework enforced negativefinding descriptions, suppressed hallucinations, and improved tooth numberidentification accuracy. However, the accurate identification of extensivelesions spanning multiple teeth is limited. Nevertheless, further refinement isrequired to enhance overall performance and move toward a practical findinggeneration system.
摘要: 在本研究中，我们利用OpenAI GPT-4o的多模态功能，在口腔全景X光片上自动生成颌骨囊肿的影像学发现。为提高准确性，我们构建了一种带结构化输出的自校正循环框架，并验证了其有效性。针对22例颌骨囊肿病例，实施了一个包含图像输入与分析、结构化数据生成、牙位编号提取及一致性检查、检测到不一致时进行迭代再生成，以及结果生成后进行结构重组和一致性验证的十步流程。我们采用传统的思维链方法进行对比实验，评估项目包括透明度、内部结构、边界、牙根吸收、牙齿移位、与其他结构的关系以及牙位编号。结果显示，所提出的SLSO框架在多项评估指标上提升了输出准确率，其中牙位编号、牙齿移位和牙根吸收的准确率分别提高了66.9%、33.3%和28.6%。在成功案例中，经过最多五次再生成后实现了结构一致性的输出。尽管由于数据集规模较小未能达到统计学显著性，但SLSO框架整体上强化了阴性发现的描述，抑制了幻觉现象，并提高了牙位编号识别的准确性。然而，对于跨越多颗牙齿的广泛病变的准确识别仍存在局限。尽管如此，仍需进一步优化以提升整体性能，推动系统向实用的发现生成方向发展。
Link: http://arxiv.org/abs/2510.02001v1
Updated: 2025-10-02T13:22:13Z

84: Zero-shot reasoning for simulating scholarly peer-review
Authors: ['Khalid M. Saqr']
Summary: The scholarly publishing ecosystem faces a dual crisis of unmanageablesubmission volumes and unregulated AI, creating an urgent need for newgovernance models to safeguard scientific integrity. The traditional human-onlypeer review regime lacks a scalable, objective benchmark, making editorialprocesses opaque and difficult to audit. Here we investigate a deterministicsimulation framework that provides the first stable, evidence-based standardfor evaluating AI-generated peer review reports. Analyzing 352 peer-reviewsimulation reports, we identify consistent system state indicators thatdemonstrate its reliability. First, the system is able to simulate calibratededitorial judgment, with 'Revise' decisions consistently forming the majorityoutcome (>50%) across all disciplines, while 'Reject' rates dynamically adaptto field-specific norms, rising to 45% in Health Sciences. Second, it maintainsunwavering procedural integrity, enforcing a stable 29% evidence-anchoringcompliance rate that remains invariant across diverse review tasks andscientific domains. These findings demonstrate a system that is predictablyrule-bound, mitigating the stochasticity of generative AI. For the scientificcommunity, this provides a transparent tool to ensure fairness; for publishingstrategists, it offers a scalable instrument for auditing workflows, managingintegrity risks, and implementing evidence-based governance. The frameworkrepositions AI as an essential component of institutional accountability,providing the critical infrastructure to maintain trust in scholarlycommunication.
摘要: 学术出版生态系统面临着投稿量不堪重负与人工智能不受监管的双重危机，亟需建立新的治理模式以保障科学诚信。传统的纯人工同行评审制度缺乏可扩展、客观的基准，导致编辑流程不透明且难以审计。在此，我们研究了一种确定性模拟框架，该框架为评估人工智能生成的同行评审报告提供了首个稳定、基于证据的标准。通过分析352份同行评审模拟报告，我们识别出一致的系统状态指标，证明了其可靠性。首先，该系统能够模拟经过校准的编辑判断，在所有学科中，“修改”决策始终构成主要结果（>50%），而“拒稿”率则动态适应特定领域的规范，在健康科学领域升至45%。其次，它保持了坚定不移的程序完整性，执行了29%的基于证据的锚定合规率，该比率在不同评审任务和科学领域中保持不变。这些发现表明，该系统具有可预测的规则约束性，减轻了生成式人工智能的随机性。对科学界而言，这提供了一个确保公平性的透明工具；对出版战略家而言，它提供了一种可扩展的审计工作流、管理诚信风险和实施基于证据的治理的工具。该框架将人工智能重新定位为机构问责制的重要组成部分，为维持学术交流的信任提供了关键基础设施。
Link: http://arxiv.org/abs/2510.02027v1
Updated: 2025-10-02T13:59:14Z

85: LiLa-Net: Lightweight Latent LiDAR Autoencoder for 3D Point Cloud  Reconstruction
Authors: ['Mario Resino', 'Borja Pérez', 'Jaime Godoy', 'Abdulla Al-Kaff', 'Fernando García']
Summary: This work proposed a 3D autoencoder architecture, named LiLa-Net, whichencodes efficient features from real traffic environments, employing only theLiDAR's point clouds. For this purpose, we have real semi-autonomous vehicle,equipped with Velodyne LiDAR. The system leverage skip connections concept toimprove the performance without using extensive resources as thestate-of-the-art architectures. Key changes include reducing the number ofencoder layers and simplifying the skip connections, while still producing anefficient and representative latent space which allows to accuratelyreconstruct the original point cloud. Furthermore, an effective balance hasbeen achieved between the information carried by the skip connections and thelatent encoding, leading to improved reconstruction quality withoutcompromising performance. Finally, the model demonstrates strong generalizationcapabilities, successfully reconstructing objects unrelated to the originaltraffic environment.
摘要: 本研究提出了一种名为LiLa-Net的三维自编码器架构，该架构仅利用激光雷达的点云数据，从真实交通环境中高效地编码特征。为此，我们配备了一台搭载Velodyne激光雷达的真实半自动驾驶车辆。该系统利用跳跃连接的概念，在不使用现有先进架构所需的大量资源的情况下提升了性能。关键改进包括减少编码器层数并简化跳跃连接，同时仍能生成高效且具有代表性的潜在空间，从而能够精确地重建原始点云。此外，在跳跃连接所携带的信息与潜在编码之间实现了有效平衡，在不影响性能的前提下提高了重建质量。最后，该模型展现出强大的泛化能力，能够成功重建与原始交通环境无关的物体。
Link: http://arxiv.org/abs/2510.02028v1
Updated: 2025-10-02T14:00:20Z

86: The Current State of AI Bias Bounties: An Overview of Existing  Programmes and Research
Authors: ['Sergej Kucenko', 'Nathaniel Dennler', 'Fengxiang He']
Summary: Current bias evaluation methods rarely engage with communities impacted by AIsystems. Inspired by bug bounties, bias bounties have been proposed as areward-based method that involves communities in AI bias detection by askingusers of AI systems to report biases they encounter when interacting with suchsystems. In the absence of a state-of-the-art review, this survey aimed toidentify and analyse existing AI bias bounty programmes and to present academicliterature on bias bounties. Google, Google Scholar, PhilPapers, and IEEEXplore were searched, and five bias bounty programmes, as well as five researchpublications, were identified. All bias bounties were organised by U.S.-basedorganisations as time-limited contests, with public participation in fourprogrammes and prize pools ranging from 7,000 to 24,000 USD. The five researchpublications included a report on the application of bug bounties toalgorithmic harms, an article addressing Twitter's bias bounty, a proposal forbias bounties as an institutional mechanism to increase AI scrutiny, a workshopdiscussing bias bounties from queer perspectives, and an algorithmic frameworkfor bias bounties. We argue that reducing the technical requirements to enterbounty programmes is important to include those without coding experience.Given the limited adoption of bias bounties, future efforts should explore thetransferability of the best practices from bug bounties and examine how suchprogrammes can be designed to be sensitive to underrepresented groups whilelowering adoption barriers for organisations.
摘要: 目前的偏见评估方法很少与受人工智能系统影响的社区互动。受漏洞赏金的启发，偏见赏金被提出作为一种基于奖励的方法，通过要求人工智能系统的用户报告他们在与这些系统互动时遇到的偏见，从而让社区参与人工智能偏见检测。由于缺乏最先进的综述，本调查旨在识别和分析现有的人工智能偏见赏金计划，并呈现关于偏见赏金的学术文献。我们检索了Google、Google Scholar、PhilPapers和IEEE Xplore，确定了五个偏见赏金计划和五篇研究出版物。所有偏见赏金均由美国组织作为限时竞赛举办，其中四个计划允许公众参与，奖金池从7000美元到24000美元不等。五篇研究出版物包括一份关于将漏洞赏金应用于算法危害的报告、一篇讨论Twitter偏见赏金的文章、一项将偏见赏金作为增加人工智能审查的机构机制的提案、一个从酷儿视角讨论偏见赏金的研讨会，以及一个偏见赏金的算法框架。我们认为，降低参与赏金计划的技术要求对于吸纳没有编码经验的人员至关重要。鉴于偏见赏金的采用有限，未来的努力应探索从漏洞赏金中借鉴最佳实践的可转移性，并研究如何设计此类计划，使其对代表性不足的群体保持敏感，同时降低组织的采用障碍。
Link: http://arxiv.org/abs/2510.02036v1
Updated: 2025-10-02T14:09:11Z

87: ReTabAD: A Benchmark for Restoring Semantic Context in Tabular Anomaly  Detection
Authors: ['Sanghyu Yoon', 'Dongmin Kim', 'Suhee Yoon', 'Ye Seul Sim', 'Seungdong Yoa', 'Hye-Seung Cho', 'Soonyoung Lee', 'Hankook Lee', 'Woohyung Lim']
Summary: In tabular anomaly detection (AD), textual semantics often carry criticalsignals, as the definition of an anomaly is closely tied to domain-specificcontext. However, existing benchmarks provide only raw data points withoutsemantic context, overlooking rich textual metadata such as featuredescriptions and domain knowledge that experts rely on in practice. Thislimitation restricts research flexibility and prevents models from fullyleveraging domain knowledge for detection. ReTabAD addresses this gap byrestoring textual semantics to enable context-aware tabular AD research. Weprovide (1) 20 carefully curated tabular datasets enriched with structuredtextual metadata, together with implementations of state-of-the-art ADalgorithms including classical, deep learning, and LLM-based approaches, and(2) a zero-shot LLM framework that leverages semantic context withouttask-specific training, establishing a strong baseline for future research.Furthermore, this work provides insights into the role and utility of textualmetadata in AD through experiments and analysis. Results show that semanticcontext improves detection performance and enhances interpretability bysupporting domain-aware reasoning. These findings establish ReTabAD as abenchmark for systematic exploration of context-aware AD.
摘要: 在表格异常检测（AD）中，文本语义通常承载着关键信号，因为异常的定义与特定领域的背景密切相关。然而，现有的基准仅提供原始数据点，而缺乏语义背景，忽略了专家在实践中所依赖的丰富文本元数据（如特征描述和领域知识）。这一局限性限制了研究的灵活性，并阻碍了模型充分利用领域知识进行检测。ReTabAD通过恢复文本语义来解决这一缺口，从而支持上下文感知的表格异常检测研究。我们提供了（1）20个精心策划的表格数据集，这些数据集附有结构化的文本元数据，并实现了包括经典方法、深度学习和基于大语言模型（LLM）方法在内的最先进异常检测算法；（2）一个零样本大语言模型框架，该框架无需任务特定训练即可利用语义背景，为未来研究奠定了强有力的基准。此外，本研究通过实验和分析深入探讨了文本元数据在异常检测中的作用和效用。结果表明，语义背景不仅提升了检测性能，还通过支持领域感知推理增强了可解释性。这些发现确立了ReTabAD作为系统探索上下文感知异常检测的基准地位。
Link: http://arxiv.org/abs/2510.02060v1
Updated: 2025-10-02T14:28:45Z

88: KAIROS: Unified Training for Universal Non-Autoregressive Time Series  Forecasting
Authors: ['Kuiye Ding', 'Fanda Fan', 'Zheya Wang', 'Hongxiao Li', 'Yifan Wang', 'Lei Wang', 'Chunjie Luo', 'Jianfeng Zhan']
Summary: In the World Wide Web, reliable time series forecasts provide theforward-looking signals that drive resource planning, cache placement, andanomaly response, enabling platforms to operate efficiently as user behaviorand content distributions evolve. Compared with other domains, time seriesforecasting for Web applications requires much faster responsiveness to supportreal-time decision making. We present KAIROS, a non-autoregressive time seriesforecasting framework that directly models segment-level multi-peakdistributions. Unlike autoregressive approaches, KAIROS avoids erroraccumulation and achieves just-in-time inference, while improving over existingnon-autoregressive models that collapse to over-smoothed predictions. Trainedon the large-scale corpus, KAIROS demonstrates strong zero-shot generalizationon six widely used benchmarks, delivering forecasting performance comparable tostate-of-the-art foundation models with similar scale, at a fraction of theirinference cost. Beyond empirical results, KAIROS highlights the importance ofnon-autoregressive design as a scalable paradigm for foundation models in timeseries.
摘要: 在万维网中，可靠的时间序列预测提供前瞻性信号，这些信号驱动资源规划、缓存放置和异常响应，使平台能够在用户行为和内容分布不断演变的情况下高效运行。与其他领域相比，Web应用的时间序列预测需要更快的响应速度以支持实时决策。我们提出了KAIROS，这是一个非自回归时间序列预测框架，直接建模分段级多峰分布。与自回归方法不同，KAIROS避免了误差累积，实现了即时推理，同时改进了现有非自回归模型中预测过度平滑的问题。在大规模语料库上训练后，KAIROS在六个广泛使用的基准测试中展现了强大的零样本泛化能力，其预测性能可与规模相近的最先进基础模型相媲美，但推理成本仅为后者的一小部分。除了实证结果外，KAIROS还凸显了非自回归设计作为时间序列基础模型可扩展范式的重要性。
Link: http://arxiv.org/abs/2510.02084v1
Updated: 2025-10-02T14:50:50Z

89: Demystifying the Roles of LLM Layers in Retrieval, Knowledge, and  Reasoning
Authors: ['Xinyuan Song', 'Keyu Wang', 'PengXiang Li', 'Lu Yin', 'Shiwei Liu']
Summary: Recent studies suggest that the deeper layers of Large Language Models (LLMs)contribute little to representation learning and can often be removed withoutsignificant performance loss. However, such claims are typically drawn fromnarrow evaluations and may overlook important aspects of model behavior. Inthis work, we present a systematic study of depth utilization across diversedimensions, including evaluation protocols, task categories, and modelarchitectures. Our analysis confirms that very deep layers are generally lesseffective than earlier ones, but their contributions vary substantially withthe evaluation setting. Under likelihood-based metrics without generation,pruning most layers preserves performance, with only the initial few beingcritical. By contrast, generation-based evaluation uncovers indispensable rolesfor middle and deeper layers in enabling reasoning and maintaining long-rangecoherence. We further find that knowledge and retrieval are concentrated inshallow components, whereas reasoning accuracy relies heavily on deeper layers-- yet can be reshaped through distillation. These results highlight that depthusage in LLMs is highly heterogeneous and context-dependent, underscoring theneed for task-, metric-, and model-aware perspectives in both interpreting andcompressing large models.
摘要: 近期研究表明，大型语言模型（LLM）的深层对表征学习的贡献甚微，且通常可在不造成显著性能损失的情况下将其移除。然而，此类结论往往源于狭隘的评估，可能忽略了模型行为的重要方面。本研究对深度利用率进行了系统性考察，涵盖评估协议、任务类别及模型架构等多个维度。分析证实，极深层通常不如早期层有效，但其贡献随评估设置差异显著。在无生成的基于似然的指标下，剪枝多数层可保持性能，仅初始少数层至关重要。相比之下，基于生成的评估揭示了中层和深层在实现推理及维持长程连贯性方面的不可或缺作用。我们进一步发现，知识与检索集中于浅层组件，而推理准确性则高度依赖深层——但可通过蒸馏重塑。这些结果凸显了LLM中深度利用的高度异质性与情境依赖性，强调在解读与压缩大型模型时需采取任务、指标及模型感知的视角。
Link: http://arxiv.org/abs/2510.02091v1
Updated: 2025-10-02T14:57:13Z

90: When Tracking Fails: Analyzing Failure Modes of SAM2 for Point-Based  Tracking in Surgical Videos
Authors: ['Woowon Jang', 'Jiwon Im', 'Juseung Choi', 'Niki Rashidian', 'Wesley De Neve', 'Utku Ozbulak']
Summary: Video object segmentation (VOS) models such as SAM2 offer promising zero-shottracking capabilities for surgical videos using minimal user input. Among theavailable input types, point-based tracking offers an efficient and low-costalternative, yet its reliability and failure cases in complex surgicalenvironments are not well understood. In this work, we systematically analyzethe failure modes of point-based tracking in laparoscopic cholecystectomyvideos. Focusing on three surgical targets, the gallbladder, grasper, andL-hook electrocautery, we compare the performance of point-based tracking withsegmentation mask initialization. Our results show that point-based tracking iscompetitive for surgical tools but consistently underperforms for anatomicaltargets, where tissue similarity and ambiguous boundaries lead to failure.Through qualitative analysis, we reveal key factors influencing trackingoutcomes and provide several actionable recommendations for selecting andplacing tracking points to improve performance in surgical video analysis.
摘要: 视频对象分割（VOS）模型（如SAM2）利用最少的用户输入，为手术视频提供了有前景的零样本跟踪能力。在可用的输入类型中，基于点的跟踪提供了一种高效且低成本的选择，然而，其在复杂手术环境中的可靠性和失效案例尚未得到充分理解。在本研究中，我们系统分析了基于点的跟踪在腹腔镜胆囊切除术视频中的失效模式。我们聚焦于三个手术目标——胆囊、抓持器和L型电钩，比较了基于点的跟踪与分割掩码初始化的性能。研究结果表明，基于点的跟踪对于手术工具具有竞争力，但在解剖目标上表现始终不佳，组织相似性和模糊边界是其失效的主要原因。通过定性分析，我们揭示了影响跟踪结果的关键因素，并为在手术视频分析中选择和放置跟踪点以提升性能提供了若干切实可行的建议。
Link: http://arxiv.org/abs/2510.02100v1
Updated: 2025-10-02T15:06:49Z

91: Unlocking Symbol-Level Precoding Efficiency Through Tensor Equivariant  Neural Network
Authors: ['Jinshuo Zhang', 'Yafei Wang', 'Xinping Yi', 'Wenjin Wang', 'Shi Jin', 'Symeon Chatzinotas', 'Björn Ottersten']
Summary: Although symbol-level precoding (SLP) based on constructive interference (CI)exploitation offers performance gains, its high complexity remains abottleneck. This paper addresses this challenge with an end-to-end deeplearning (DL) framework with low inference complexity that leverages thestructure of the optimal SLP solution in the closed-form and its inherenttensor equivariance (TE), where TE denotes that a permutation of the inputinduces the corresponding permutation of the output. Building upon thecomputationally efficient model-based formulations, as well as their knownclosed-form solutions, we analyze their relationship with linear precoding (LP)and investigate the corresponding optimality condition. We then construct amapping from the problem formulation to the solution and prove its TE, based onwhich the designed networks reveal a specific parameter-sharing pattern thatdelivers low computational complexity and strong generalization. Leveragingthese, we propose the backbone of the framework with an attention-based TEmodule, achieving linear computational complexity. Furthermore, we demonstratethat such a framework is also applicable to imperfect CSI scenarios, where wedesign a TE-based network to map the CSI, statistics, and symbols to auxiliaryvariables. Simulation results show that the proposed framework capturessubstantial performance gains of optimal SLP, while achieving an approximately80-times speedup over conventional methods and maintaining stronggeneralization across user numbers and symbol block lengths.
摘要: 尽管基于建设性干扰利用的符号级预编码能够带来性能增益，但其高复杂度仍然是一个瓶颈。本文提出了一种端到端的深度学习框架，通过利用最优符号级预编码闭式解的结构及其固有的张量等变性来解决这一挑战，该框架具有较低的推理复杂度。其中，张量等变性指的是输入的置换会引发输出的相应置换。在计算高效的基于模型的公式及其已知的闭式解的基础上，我们分析了它们与线性预编码的关系，并研究了相应的最优性条件。随后，我们构建了从问题公式到解的映射，并证明了其张量等变性。基于此，所设计的网络展现出一种特定的参数共享模式，从而实现了低计算复杂度和强泛化能力。利用这些特性，我们提出了框架的主干，其中包含一个基于注意力的张量等变性模块，实现了线性计算复杂度。此外，我们证明了该框架同样适用于不完美信道状态信息场景，并设计了一种基于张量等变性的网络，将信道状态信息、统计量和符号映射到辅助变量。仿真结果表明，所提出的框架不仅捕捉了最优符号级预编码的显著性能增益，而且相比传统方法实现了约80倍的加速，同时在用户数量和符号块长度变化时保持了强泛化能力。
Link: http://arxiv.org/abs/2510.02108v1
Updated: 2025-10-02T15:15:50Z

92: SpurBreast: A Curated Dataset for Investigating Spurious Correlations in  Real-world Breast MRI Classification
Authors: ['Jong Bum Won', 'Wesley De Neve', 'Joris Vankerschaver', 'Utku Ozbulak']
Summary: Deep neural networks (DNNs) have demonstrated remarkable success in medicalimaging, yet their real-world deployment remains challenging due to spuriouscorrelations, where models can learn non-clinical features instead ofmeaningful medical patterns. Existing medical imaging datasets are not designedto systematically study this issue, largely due to restrictive licensing andlimited supplementary patient data. To address this gap, we introduceSpurBreast, a curated breast MRI dataset that intentionally incorporatesspurious correlations to evaluate their impact on model performance. Analyzingover 100 features involving patient, device, and imaging protocol, we identifytwo dominant spurious signals: magnetic field strength (a global featureinfluencing the entire image) and image orientation (a local feature affectingspatial alignment). Through controlled dataset splits, we demonstrate that DNNscan exploit these non-clinical signals, achieving high validation accuracywhile failing to generalize to unbiased test data. Alongside these two datasetscontaining spurious correlations, we also provide benchmark datasets withoutspurious correlations, allowing researchers to systematically investigateclinically relevant and irrelevant features, uncertainty estimation,adversarial robustness, and generalization strategies. Models and datasets areavailable at https://github.com/utkuozbulak/spurbreast.
摘要: 深度神经网络（DNN）在医学影像领域已展现出显著的成功，但由于虚假关联的存在，其在现实世界中的部署仍面临挑战。所谓虚假关联，是指模型可能学习到非临床特征，而非有意义的医学模式。现有的医学影像数据集并未被设计用于系统性地研究这一问题，这在很大程度上归因于其限制性许可和有限的患者补充数据。为填补这一空白，我们推出了SpurBreast，这是一个精心策划的乳腺MRI数据集，它特意引入了虚假关联，以评估其对模型性能的影响。通过分析涉及患者、设备和成像协议的100多个特征，我们识别出两个主要的虚假信号：磁场强度（一种影响整个图像的全局特征）和图像方向（一种影响空间对齐的局部特征）。通过受控的数据集划分，我们证明了DNN可以利用这些非临床信号，在实现高验证准确率的同时，却无法泛化到无偏见的测试数据上。除了这两个包含虚假关联的数据集外，我们还提供了不含虚假关联的基准数据集，使研究人员能够系统地研究与临床相关及无关的特征、不确定性估计、对抗鲁棒性以及泛化策略。模型和数据集可在https://github.com/utkuozbulak/spurbreast获取。
Link: http://arxiv.org/abs/2510.02109v1
Updated: 2025-10-02T15:16:20Z

93: VarCoNet: A variability-aware self-supervised framework for functional  connectome extraction from resting-state fMRI
Authors: ['Charalampos Lamprou', 'Aamna Alshehhi', 'Leontios J. Hadjileontiadis', 'Mohamed L. Seghier']
Summary: Accounting for inter-individual variability in brain function is key toprecision medicine. Here, by considering functional inter-individualvariability as meaningful data rather than noise, we introduce VarCoNet, anenhanced self-supervised framework for robust functional connectome (FC)extraction from resting-state fMRI (rs-fMRI) data. VarCoNet employsself-supervised contrastive learning to exploit inherent functionalinter-individual variability, serving as a brain function encoder thatgenerates FC embeddings readily applicable to downstream tasks even in theabsence of labeled data. Contrastive learning is facilitated by a novelaugmentation strategy based on segmenting rs-fMRI signals. At its core,VarCoNet integrates a 1D-CNN-Transformer encoder for advanced time-seriesprocessing, enhanced with a robust Bayesian hyperparameter optimization. OurVarCoNet framework is evaluated on two downstream tasks: (i) subjectfingerprinting, using rs-fMRI data from the Human Connectome Project, and (ii)autism spectrum disorder (ASD) classification, using rs-fMRI data from theABIDE I and ABIDE II datasets. Using different brain parcellations, ourextensive testing against state-of-the-art methods, including 13 deep learningmethods, demonstrates VarCoNet's superiority, robustness, interpretability, andgeneralizability. Overall, VarCoNet provides a versatile and robust frameworkfor FC analysis in rs-fMRI.
摘要: 考虑脑功能的个体间变异性是精准医学的关键。在此，我们将功能个体间变异性视为有意义的数据而非噪声，并由此引入VarCoNet，这是一种增强的自监督框架，用于从静息态功能性磁共振成像（rs-fMRI）数据中稳健地提取功能连接组（FC）。VarCoNet采用自监督对比学习来利用固有的功能个体间变异性，其作为一个脑功能编码器，即使在缺乏标记数据的情况下，也能生成可直接应用于下游任务的FC嵌入。对比学习通过一种基于分割rs-fMRI信号的新型增强策略得以促进。VarCoNet的核心集成了一个一维卷积神经网络-Transformer（1D-CNN-Transformer）编码器，用于先进的时间序列处理，并通过稳健的贝叶斯超参数优化得到增强。我们的VarCoNet框架在两项下游任务上进行了评估：（i）使用来自人类连接组计划的rs-fMRI数据进行个体指纹识别，以及（ii）使用来自ABIDE I和ABIDE II数据集的rs-fMRI数据进行自闭症谱系障碍（ASD）分类。通过使用不同的脑区划分方案，我们针对包括13种深度学习方法在内的最先进方法进行了广泛测试，结果证明了VarCoNet的优越性、稳健性、可解释性和泛化能力。总体而言，VarCoNet为rs-fMRI中的FC分析提供了一个多功能且稳健的框架。
Link: http://arxiv.org/abs/2510.02120v1
Updated: 2025-10-02T15:29:17Z

94: Do AI Models Perform Human-like Abstract Reasoning Across Modalities?
Authors: ['Claas Beger', 'Ryan Yi', 'Shuhao Fu', 'Arseny Moskvichev', 'Sarah W. Tsai', 'Sivasankaran Rajamanickam', 'Melanie Mitchell']
Summary: OpenAI's o3-preview reasoning model exceeded human accuracy on the ARC-AGIbenchmark, but does that mean state-of-the-art models recognize and reason withthe abstractions that the task creators intended? We investigate models'abstraction abilities on ConceptARC. We evaluate models under settings thatvary the input modality (textual vs. visual), whether the model is permitted touse external Python tools, and, for reasoning models, the amount of reasoningeffort. In addition to measuring output accuracy, we perform fine-grainedevaluation of the natural-language rules that models generate to explain theirsolutions. This dual evaluation lets us assess whether models solve tasks usingthe abstractions ConceptARC was designed to elicit, rather than relying onsurface-level patterns. Our results show that, while some models usingtext-based representations match human output accuracy, the best models' rulesare often based on surface-level ``shortcuts'' and capture intendedabstractions far less often than humans. Thus their capabilities for generalabstract reasoning may be overestimated by evaluations based on accuracy alone.In the visual modality, AI models' output accuracy drops sharply, yet ourrule-level analysis reveals that models might be underestimated, as they stillexhibit a substantial share of rules that capture intended abstractions, butare often unable to correctly apply these rules. In short, our results showthat models still lag humans in abstract reasoning, and that using accuracyalone to evaluate abstract reasoning on ARC-like tasks may overestimateabstract-reasoning capabilities in textual modalities and underestimate it invisual modalities. We believe that our evaluation framework offers a morefaithful picture of multimodal models' abstract reasoning abilities and a moreprincipled way to track progress toward human-like, abstraction-centeredintelligence.
摘要: OpenAI的o3-preview推理模型在ARC-AGI基准测试上超越了人类准确率，但这是否意味着最先进的模型能够识别并运用任务创建者所设想的抽象概念进行推理？我们在ConceptARC上研究了模型的抽象能力。我们在不同设置下评估了模型，这些设置包括输入模态（文本与视觉）、模型是否被允许使用外部Python工具，以及对于推理模型，推理投入的程度。除了衡量输出准确率外，我们还对模型为解释其解决方案而生成的自然语言规则进行了细粒度评估。这种双重评估使我们能够判断模型是否利用了ConceptARC旨在引出的抽象概念来解决问题，而非依赖表面模式。我们的结果表明，尽管一些使用文本表示的模型在输出准确率上与人类相当，但最佳模型的规则通常基于“捷径”式的表面模式，其捕捉到预期抽象概念的比例远低于人类。因此，仅基于准确率的评估可能会高估模型的通用抽象推理能力。在视觉模态下，AI模型的输出准确率急剧下降，但我们的规则层面分析显示，模型的能力可能被低估，因为它们仍然展现出相当比例的规则能够捕捉预期抽象概念，只是常常无法正确应用这些规则。总之，我们的结果表明模型在抽象推理方面仍落后于人类，并且仅用准确率来评估ARC类任务上的抽象推理能力，可能会在文本模态下高估、在视觉模态下低估这种能力。我们相信，我们的评估框架为多模态模型的抽象推理能力提供了更真实的写照，也为追踪向类人的、以抽象为核心智能的进展提供了更系统的方法。
Link: http://arxiv.org/abs/2510.02125v1
Updated: 2025-10-02T15:35:10Z

95: The Disparate Impacts of Speculative Decoding
Authors: ['Jameson Sandler', 'Ahmet Üstün', 'Marco Romanelli', 'Sara Hooker', 'Ferdinando Fioretto']
Summary: The practice of speculative decoding, whereby inference is probabilisticallysupported by a smaller, cheaper, ``drafter'' model, has become a standardtechnique for systematically reducing the decoding time of large languagemodels. This paper conducts an analysis of speculative decoding through thelens of its potential disparate speed-up rates across tasks. Crucially, thepaper shows that speed-up gained from speculative decoding is not uniformlydistributed across tasks, consistently diminishing for under-fit, and oftenunderrepresented tasks. To better understand this phenomenon, we derive ananalysis to quantify this observed ``unfairness'' and draw attention to thefactors that motivate such disparate speed-ups to emerge. Further, guided bythese insights, the paper proposes a mitigation strategy designed to reducespeed-up disparities and validates the approach across several model pairs,revealing on average a 12% improvement in our fairness metric.
摘要: 推测解码（Speculative decoding）是一种通过一个更小、更便宜的“草稿”模型来概率性地支持推理过程的技术，现已成为系统性地减少大型语言模型解码时间的标准方法。本文从不同任务间潜在加速率差异的角度对推测解码进行了分析。关键在于，论文表明，推测解码带来的加速效果在不同任务间并非均匀分布，对于拟合不足且通常代表性不足的任务，其加速效果会持续减弱。为了更好地理解这一现象，我们推导出一种分析方法来量化这种观察到的“不公平性”，并揭示了导致此类差异化加速出现的因素。此外，基于这些见解，本文提出了一种旨在减少加速差异的缓解策略，并在多个模型对上验证了该方法，结果显示我们的公平性指标平均提升了12%。
Link: http://arxiv.org/abs/2510.02128v1
Updated: 2025-10-02T15:38:57Z

96: FlexDoc: Parameterized Sampling for Diverse Multilingual Synthetic  Documents for Training Document Understanding Models
Authors: ['Karan Dua', 'Hitesh Laxmichand Patel', 'Puneet Mittal', 'Ranjeet Gupta', 'Amit Agarwal', 'Praneet Pabolu', 'Srikant Panda', 'Hansa Meghwani', 'Graham Horwood', 'Fahad Shah']
Summary: Developing document understanding models at enterprise scale requires large,diverse, and well-annotated datasets spanning a wide range of document types.However, collecting such data is prohibitively expensive due to privacyconstraints, legal restrictions, and the sheer volume of manual annotationneeded - costs that can scale into millions of dollars. We introduce FlexDoc, ascalable synthetic data generation framework that combines Stochastic Schemasand Parameterized Sampling to produce realistic, multilingual semi-structureddocuments with rich annotations. By probabilistically modeling layout patterns,visual structure, and content variability, FlexDoc enables the controlledgeneration of diverse document variants at scale. Experiments on KeyInformation Extraction (KIE) tasks demonstrate that FlexDoc-generated dataimproves the absolute F1 Score by up to 11% when used to augment real datasets,while reducing annotation effort by over 90% compared to traditionalhard-template methods. The solution is in active deployment, where it hasaccelerated the development of enterprise-grade document understanding modelswhile significantly reducing data acquisition and annotation costs.
摘要: 在企业规模上开发文档理解模型，需要大量、多样且标注精良的数据集，这些数据集需涵盖多种文档类型。然而，由于隐私限制、法律约束以及所需的大量人工标注，收集此类数据的成本高得令人望而却步——这些成本可能高达数百万美元。我们推出了FlexDoc，这是一个可扩展的合成数据生成框架，它结合了随机模式和参数化采样技术，以生成具有丰富标注的逼真多语言半结构化文档。通过对布局模式、视觉结构和内容可变性进行概率建模，FlexDoc能够实现大规模、可控的多样化文档变体生成。在关键信息提取（KIE）任务上的实验表明，当用于增强真实数据集时，FlexDoc生成的数据将绝对F1分数提高了高达11%，同时与传统硬模板方法相比，将标注工作量减少了90%以上。该解决方案已投入实际部署，它不仅加速了企业级文档理解模型的开发，还显著降低了数据获取和标注成本。
Link: http://arxiv.org/abs/2510.02133v1
Updated: 2025-10-02T15:42:35Z

97: BioinfoMCP: A Unified Platform Enabling MCP Interfaces in Agentic  Bioinformatics
Authors: ['Florensia Widjaja', 'Zhangtianyi Chen', 'Juexiao Zhou']
Summary: Bioinformatics tools are essential for complex computational biology tasks,yet their integration with emerging AI-agent frameworks is hindered byincompatible interfaces, heterogeneous input-output formats, and inconsistentparameter conventions. The Model Context Protocol (MCP) provides a standardizedframework for tool-AI communication, but manually converting hundreds ofexisting and rapidly growing specialized bioinformatics tools intoMCP-compliant servers is labor-intensive and unsustainable. Here, we presentBioinfoMCP, a unified platform comprising two components: BioinfoMCP Converter,which automatically generates robust MCP servers from tool documentation usinglarge language models, and BioinfoMCP Benchmark, which systematically validatesthe reliability and versatility of converted tools across diverse computationaltasks. We present a platform of 38 MCP-converted bioinformatics tools,extensively validated to show that 94.7% successfully executed complexworkflows across three widely used AI-agent platforms. By removing technicalbarriers to AI automation, BioinfoMCP enables natural-language interaction withsophisticated bioinformatics analyses without requiring extensive programmingexpertise, offering a scalable path to intelligent, interoperable computationalbiology.
摘要: 生物信息学工具对于复杂的计算生物学任务至关重要，然而，其与新兴AI代理框架的集成却因不兼容的接口、异构的输入输出格式以及不一致的参数约定而受阻。模型上下文协议（MCP）为工具与AI之间的通信提供了一个标准化框架，但将数百个现有且快速增长的专用生物信息学工具手动转换为符合MCP标准的服务器，既耗时又难以持续。在此，我们提出BioinfoMCP，这是一个统一平台，包含两个组件：BioinfoMCP转换器，它利用大型语言模型根据工具文档自动生成稳健的MCP服务器；以及BioinfoMCP基准测试，它系统性地验证了转换后工具在不同计算任务中的可靠性和多功能性。我们展示了一个包含38个经MCP转换的生物信息学工具的平台，经过广泛验证，表明其中94.7%的工具在三个广泛使用的AI代理平台上成功执行了复杂的工作流。通过消除AI自动化的技术障碍，BioinfoMCP实现了与复杂生物信息学分析的自然语言交互，而无需用户具备广泛的编程专业知识，为智能、可互操作的计算生物学提供了一条可扩展的路径。
Link: http://arxiv.org/abs/2510.02139v1
Updated: 2025-10-02T15:47:59Z

98: How to Find Fantastic Papers: Self-Rankings as a Powerful Predictor of  Scientific Impact Beyond Peer Review
Authors: ['Buxin Su', 'Natalie Collina', 'Garrett Wen', 'Didong Li', 'Kyunghyun Cho', 'Jianqing Fan', 'Bingxin Zhao', 'Weijie Su']
Summary: Peer review in academic research aims not only to ensure factual correctnessbut also to identify work of high scientific potential that can shape futureresearch directions. This task is especially critical in fast-moving fieldssuch as artificial intelligence (AI), yet it has become increasingly difficultgiven the rapid growth of submissions. In this paper, we investigate anunderexplored measure for identifying high-impact research: authors' ownrankings of their multiple submissions to the same AI conference. Grounded ingame-theoretic reasoning, we hypothesize that self-rankings are informativebecause authors possess unique understanding of their work's conceptual depthand long-term promise. To test this hypothesis, we conducted a large-scaleexperiment at a leading AI conference, where 1,342 researchers self-rankedtheir 2,592 submissions by perceived quality. Tracking outcomes over more thana year, we found that papers ranked highest by their authors received twice asmany citations as their lowest-ranked counterparts; self-rankings wereespecially effective at identifying highly cited papers (those with over 150citations). Moreover, we showed that self-rankings outperformed peer reviewscores in predicting future citation counts. Our results remained robust afteraccounting for confounders such as preprint posting time and self-citations.Together, these findings demonstrate that authors' self-rankings provide areliable and valuable complement to peer review for identifying and elevatinghigh-impact research in AI.
摘要: 学术研究中的同行评审不仅旨在确保事实的正确性，还旨在识别具有高科学潜力、能够塑造未来研究方向的工作。在人工智能（AI）等快速发展领域，这项任务尤为关键，但随着投稿数量的快速增长，其难度也日益增加。在本文中，我们探讨了一种用于识别高影响力研究但尚未被充分探索的衡量标准：作者对其向同一AI会议提交的多篇稿件的自评排名。基于博弈论推理，我们假设自评排名具有信息价值，因为作者对其工作的概念深度和长期前景具有独特理解。为检验这一假设，我们在一个顶级AI会议上进行了一项大规模实验，1342名研究人员根据感知质量对其2592篇投稿进行了自评排名。通过追踪一年多的结果，我们发现作者排名最高的论文获得的引用量是排名最低论文的两倍；自评排名在识别高被引论文（引用量超过150次的论文）方面尤为有效。此外，我们还证明，在预测未来引用次数方面，自评排名优于同行评审分数。在考虑了预印本发布时间和自引等混杂因素后，我们的结果依然稳健。总之，这些研究结果表明，作者的自评排名为识别和提升AI领域高影响力研究提供了可靠且宝贵的同行评审补充手段。
Link: http://arxiv.org/abs/2510.02143v1
Updated: 2025-10-02T15:50:21Z

99: Human-Robo-advisor collaboration in decision-making: Evidence from a  multiphase mixed methods experimental study
Authors: ['Hasan Mahmud', 'Najmul Islam', 'Satish Krishnan']
Summary: Robo-advisors (RAs) are cost-effective, bias-resistant alternatives to humanfinancial advisors, yet adoption remains limited. While prior research hasexamined user interactions with RAs, less is known about how individualsinterpret RA roles and integrate their advice into decision-making. To addressthis gap, this study employs a multiphase mixed methods design integrating abehavioral experiment (N = 334), thematic analysis, and follow-up quantitativetesting. Findings suggest that people tend to rely on RAs, with reliance shapedby information about RA performance and the framing of advice as gains orlosses. Thematic analysis reveals three RA roles in decision-making and fouruser types, each reflecting distinct patterns of advice integration. Inaddition, a 2 x 2 typology categorizes antecedents of acceptance into enablersand inhibitors at both the individual and algorithmic levels. By combiningbehavioral, interpretive, and confirmatory evidence, this study advancesunderstanding of human-RA collaboration and provides actionable insights fordesigning more trustworthy and adaptive RA systems.
摘要: 机器人顾问（RAs）是具有成本效益、能抵抗偏见的人工金融顾问替代方案，但其采用率仍然有限。尽管先前的研究已考察了用户与机器人顾问的互动，但对于个体如何解读机器人顾问的角色并将其建议融入决策过程，人们知之甚少。为填补这一空白，本研究采用多阶段混合方法设计，整合了一项行为实验（N = 334）、主题分析和后续定量测试。研究结果表明，人们倾向于依赖机器人顾问，这种依赖受到机器人顾问表现信息以及建议被框定为收益或损失的影响。主题分析揭示了决策中的三种机器人顾问角色和四种用户类型，每种类型均反映了独特的建议整合模式。此外，一项2×2类型学将接受度的前因在个体和算法层面划分为促进因素和抑制因素。通过结合行为性、解释性和验证性证据，本研究推进了对人类与机器人顾问协作的理解，并为设计更值得信赖和更具适应性的机器人顾问系统提供了可行的见解。
Link: http://dx.doi.org/10.1016/j.dss.2025.114541
Updated: 2025-10-02T16:04:31Z

100: Unlocking Vision-Language Models for Video Anomaly Detection via  Fine-Grained Prompting
Authors: ['Shu Zou', 'Xinyu Tian', 'Lukas Wesemann', 'Fabian Waschkowski', 'Zhaoyuan Yang', 'Jing Zhang']
Summary: Prompting has emerged as a practical way to adapt frozen vision-languagemodels (VLMs) for video anomaly detection (VAD). Yet, existing prompts areoften overly abstract, overlooking the fine-grained human-object interactionsor action semantics that define complex anomalies in surveillance videos. Wepropose ASK-Hint, a structured prompting framework that leveragesaction-centric knowledge to elicit more accurate and interpretable reasoningfrom frozen VLMs. Our approach organizes prompts into semantically coherentgroups (e.g. violence, property crimes, public safety) and formulatesfine-grained guiding questions that align model predictions with discriminativevisual cues. Extensive experiments on UCF-Crime and XD-Violence show thatASK-Hint consistently improves AUC over prior baselines, achievingstate-of-the-art performance compared to both fine-tuned and training-freemethods. Beyond accuracy, our framework provides interpretable reasoning tracestowards anomaly and demonstrates strong generalization across datasets and VLMbackbones. These results highlight the critical role of prompt granularity andestablish ASK-Hint as a new training-free and generalizable solution forexplainable video anomaly detection.
摘要: 提示（Prompting）已成为一种实用的方法，用于调整冻结的视觉-语言模型（VLMs）以进行视频异常检测（VAD）。然而，现有的提示通常过于抽象，忽略了监控视频中定义复杂异常的细粒度人-物交互或动作语义。我们提出了ASK-Hint，这是一种结构化的提示框架，它利用以动作为中心的知识，从冻结的VLMs中引出更准确和可解释的推理。我们的方法将提示组织成语义连贯的组（例如暴力、财产犯罪、公共安全），并制定细粒度的引导性问题，使模型预测与区分性的视觉线索保持一致。在UCF-Crime和XD-Violence上进行的大量实验表明，ASK-Hint持续提高了AUC，与先前的基线相比，实现了最先进的性能，并与微调和免训练的方法相比具有优势。除了准确性之外，我们的框架还提供了针对异常的可解释推理轨迹，并展示了在不同数据集和VLM主干上的强大泛化能力。这些结果凸显了提示粒度的关键作用，并将ASK-Hint确立为一种用于可解释视频异常检测的新的免训练且可泛化的解决方案。
Link: http://arxiv.org/abs/2510.02155v1
Updated: 2025-10-02T16:06:31Z

101: Comparing Contrastive and Triplet Loss in Audio-Visual Embedding:  Intra-Class Variance and Greediness Analysis
Authors: ['Donghuo Zeng']
Summary: Contrastive loss and triplet loss are widely used objectives in deep metriclearning, yet their effects on representation quality remain insufficientlyunderstood. We present a theoretical and empirical comparison of these losses,focusing on intra- and inter-class variance and optimization behavior (e.g.,greedy updates). Through task-specific experiments with consistent settings onsynthetic data and real datasets-MNIST, CIFAR-10-it is shown that triplet losspreserves greater variance within and across classes, supporting finer-graineddistinctions in the learned representations. In contrast, contrastive losstends to compact intra-class embeddings, which may obscure subtle semanticdifferences. To better understand their optimization dynamics, By examiningloss-decay rate, active ratio, and gradient norm, we find that contrastive lossdrives many small updates early on, while triplet loss produces fewer butstronger updates that sustain learning on hard examples. Finally, across bothclassification and retrieval tasks on MNIST, CIFAR-10, CUB-200, and CARS196datasets, our results consistently show that triplet loss yields superiorperformance, which suggests using triplet loss for detail retention andhard-sample focus, and contrastive loss for smoother, broad-based embeddingrefinement.
摘要: 对比损失和三元组损失是深度度量学习中广泛使用的目标函数，但它们对表征质量的影响仍未被充分理解。我们对这些损失进行了理论和实证的比较，重点关注类内和类间方差以及优化行为（例如，贪婪更新）。通过在合成数据和真实数据集（MNIST、CIFAR-10）上采用一致设置进行特定任务的实验，结果表明，三元组损失能够保留更大的类内和类间方差，从而支持在学习的表征中进行更细粒度的区分。相比之下，对比损失倾向于压缩类内嵌入，这可能会模糊细微的语义差异。为了更好地理解它们的优化动态，我们通过检查损失衰减率、活跃比率和梯度范数，发现对比损失在早期驱动许多小的更新，而三元组损失则产生更少但更强的更新，这些更新能够持续学习困难样本。最后，在MNIST、CIFAR-10、CUB-200和CARS196数据集上的分类和检索任务中，我们的结果一致表明，三元组损失取得了更优越的性能，这表明在需要保留细节和关注困难样本时应使用三元组损失，而在进行更平滑、广泛的嵌入优化时应使用对比损失。
Link: http://arxiv.org/abs/2510.02161v1
Updated: 2025-10-02T16:11:46Z

102: SIEVE: Towards Verifiable Certification for Code-datasets
Authors: ['Fatou Ndiaye Mbodji', 'El-hacen Diallo', 'Jordan Samhi', 'Kui Liu', 'Jacques Klein', 'Tegawendé F. Bissyande']
Summary: Code agents and empirical software engineering rely on public code datasets,yet these datasets lack verifiable quality guarantees. Static 'dataset cards'inform, but they are neither auditable nor do they offer statisticalguarantees, making it difficult to attest to dataset quality. Teams buildisolated, ad-hoc cleaning pipelines. This fragments effort and raises cost. Wepresent SIEVE, a community-driven framework. It turns per-property checks intoConfidence Cards-machine-readable, verifiable certificates with anytime-validstatistical bounds. We outline a research plan to bring SIEVE to maturity,replacing narrative cards with anytime-verifiable certification. This shift isexpected to lower quality-assurance costs and increase trust in code-datasets.
摘要: 代码代理和实证软件工程依赖于公共代码数据集，然而这些数据集缺乏可验证的质量保证。静态的“数据集卡片”提供信息，但它们既不可审计，也不提供统计保证，因此难以证明数据集的质量。团队构建孤立的、临时的清洗管道，这分散了精力并增加了成本。我们提出了SIEVE，一个社区驱动的框架。它将针对每个属性的检查转化为置信卡片——一种机器可读、可验证的证书，具有随时有效的统计边界。我们概述了一项研究计划，旨在使SIEVE成熟化，用随时可验证的认证取代描述性卡片。这一转变预计将降低质量保证成本，并提高对代码数据集的信任。
Link: http://arxiv.org/abs/2510.02166v1
Updated: 2025-10-02T16:14:23Z

103: Go witheFlow: Real-time Emotion Driven Audio Effects Modulation
Authors: ['Edmund Dervakos', 'Spyridon Kantarelis', 'Vassilis Lyberatos', 'Jason Liartis', 'Giorgos Stamou']
Summary: Music performance is a distinctly human activity, intrinsically linked to theperformer's ability to convey, evoke, or express emotion. Machines cannotperform music in the human sense; they can produce, reproduce, execute, orsynthesize music, but they lack the capacity for affective or emotionalexperience. As such, music performance is an ideal candidate through which toexplore aspects of collaboration between humans and machines. In this paper, weintroduce the witheFlow system, designed to enhance real-time music performanceby automatically modulating audio effects based on features extracted from bothbiosignals and the audio itself. The system, currently in a proof-of-conceptphase, is designed to be lightweight, able to run locally on a laptop, and isopen-source given the availability of a compatible Digital Audio Workstationand sensors.
摘要: 音乐表演是一种独特的人类活动，其本质与表演者传达、唤起或表达情感的能力息息相关。机器无法以人类的方式表演音乐；它们可以生成、复制、执行或合成音乐，但它们缺乏情感或情绪体验的能力。因此，音乐表演是探索人机协作方面的一个理想选择。在本文中，我们介绍了 witheFlow 系统，该系统旨在通过基于从生物信号和音频本身提取的特征来自动调制音频效果，从而增强实时音乐表演。该系统目前处于概念验证阶段，其设计轻量级，能够在笔记本电脑上本地运行，并且在有兼容的数字音频工作站和传感器的情况下是开源的。
Link: http://arxiv.org/abs/2510.02171v1
Updated: 2025-10-02T16:23:47Z

104: Learning to Reason for Hallucination Span Detection
Authors: ['Hsuan Su', 'Ting-Yao Hu', 'Hema Swetha Koppula', 'Kundan Krishna', 'Hadi Pouransari', 'Cheng-Yu Hsieh', 'Cem Koc', 'Joseph Yitan Cheng', 'Oncel Tuzel', 'Raviteja Vemulapalli']
Summary: Large language models (LLMs) often generate hallucinations -- unsupportedcontent that undermines reliability. While most prior works frame hallucinationdetection as a binary task, many real-world applications require identifyinghallucinated spans, which is a multi-step decision making process. Thisnaturally raises the question of whether explicit reasoning can help thecomplex task of detecting hallucination spans. To answer this question, wefirst evaluate pretrained models with and without Chain-of-Thought (CoT)reasoning, and show that CoT reasoning has the potential to generate at leastone correct answer when sampled multiple times. Motivated by this, we proposeRL4HS, a reinforcement learning framework that incentivizes reasoning with aspan-level reward function. RL4HS builds on Group Relative Policy Optimizationand introduces Class-Aware Policy Optimization to mitigate reward imbalanceissue. Experiments on the RAGTruth benchmark (summarization, questionanswering, data-to-text) show that RL4HS surpasses pretrained reasoning modelsand supervised fine-tuning, demonstrating the necessity of reinforcementlearning with span-level rewards for detecting hallucination spans.
摘要: 大型语言模型（LLM）经常会产生幻觉——即缺乏依据的内容，这会损害其可靠性。尽管此前大多数研究将幻觉检测视为一项二元分类任务，但许多实际应用需要识别出具体的幻觉片段，这是一个多步骤的决策过程。这自然引出了一个核心问题：显式推理是否有助于检测幻觉片段这一复杂任务？为解答此问题，我们首先评估了带和不带思维链（CoT）推理的预训练模型，结果表明，在多次采样时，CoT推理有潜力生成至少一个正确答案。基于此，我们提出了RL4HS，一种通过片段级奖励函数来激励推理的强化学习框架。RL4HS构建于群体相对策略优化之上，并引入了类别感知策略优化以缓解奖励不平衡问题。在RAGTruth基准测试（涵盖摘要生成、问答、数据到文本任务）上的实验表明，RL4HS超越了预训练推理模型和监督微调方法，证明了采用片段级奖励的强化学习对于检测幻觉片段的必要性。
Link: http://arxiv.org/abs/2510.02173v1
Updated: 2025-10-02T16:24:28Z

105: GRACE: A Language Model Framework for Explainable Inverse Reinforcement  Learning
Authors: ['Silvia Sapora', 'Devon Hjelm', 'Alexander Toshev', 'Omar Attia', 'Bogdan Mazoure']
Summary: Inverse Reinforcement Learning aims to recover reward models from expertdemonstrations, but traditional methods yield "black-box" models that aredifficult to interpret and debug. In this work, we introduce GRACE (GeneratingRewards As CodE), a method for using Large Language Models within anevolutionary search to reverse-engineer an interpretable, code-based rewardfunction directly from expert trajectories. The resulting reward function isexecutable code that can be inspected and verified. We empirically validateGRACE on the BabyAI and AndroidWorld benchmarks, where it efficiently learnshighly accurate rewards, even in complex, multi-task settings. Further, wedemonstrate that the resulting reward leads to strong policies, compared toboth competitive Imitation Learning and online RL approaches with ground-truthrewards. Finally, we show that GRACE is able to build complex reward APIs inmulti-task setups.
摘要: 逆向强化学习旨在从专家演示中恢复奖励模型，但传统方法产生的“黑盒”模型难以解释和调试。在这项工作中，我们介绍了GRACE（生成代码作为奖励，Generating Rewards As CodE），该方法在进化搜索中使用大型语言模型，直接从专家轨迹逆向工程出可解释的、基于代码的奖励函数。生成的奖励函数是可执行代码，可以进行检查和验证。我们在BabyAI和AndroidWorld基准测试上对GRACE进行了实证验证，结果表明，即使在复杂的多任务环境中，它也能高效地学习到高度准确的奖励。此外，我们证明，与竞争性的模仿学习和使用真实奖励的在线强化学习方法相比，GRACE生成的奖励能够带来更优的策略。最后，我们展示了GRACE能够在多任务设置中构建复杂的奖励API。
Link: http://arxiv.org/abs/2510.02180v1
Updated: 2025-10-02T16:31:39Z

106: EvolveCaptions: Empowering DHH Users Through Real-Time Collaborative  Captioning
Authors: ['Liang-Yuan Wu', 'Dhruv Jain']
Summary: Automatic Speech Recognition (ASR) systems often fail to accuratelytranscribe speech from Deaf and Hard of Hearing (DHH) individuals, especiallyduring real-time conversations. Existing personalization approaches typicallyrequire extensive pre-recorded data and place the burden of adaptation on theDHH speaker. We present EvolveCaptions, a real-time, collaborative ASRadaptation system that supports in-situ personalization with minimal effort.Hearing participants correct ASR errors during live conversations. Based onthese corrections, the system generates short, phonetically targeted promptsfor the DHH speaker to record, which are then used to fine-tune the ASR model.In a study with 12 DHH and six hearing participants, EvolveCaptions reducedWord Error Rate (WER) across all DHH users within one hour of use, using onlyfive minutes of recording time on average. Participants described the system asintuitive, low-effort, and well-integrated into communication. These findingsdemonstrate the promise of collaborative, real-time ASR adaptation for moreequitable communication.
摘要: 自动语音识别（ASR）系统在准确转录听障人士（DHH）的语音时常常表现不佳，尤其是在实时对话中。现有的个性化方法通常需要大量的预录数据，并将适应的负担强加于听障说话者。我们提出了EvolveCaptions，这是一个实时、协作的ASR适应系统，支持以最小化努力进行现场个性化。听力参与者在实时对话中纠正ASR错误。基于这些纠正，系统为听障说话者生成简短、针对语音的提示以供录制，随后这些提示被用于微调ASR模型。在一项涉及12名听障和6名听力参与者的研究中，EvolveCaptions在使用一小时内降低了所有听障用户的词错误率（WER），平均仅使用五分钟的录制时间。参与者将系统描述为直观、省力且能很好地融入沟通中。这些发现证明了协作式、实时ASR适应在促进更公平沟通方面的潜力。
Link: http://arxiv.org/abs/2510.02181v1
Updated: 2025-10-02T16:32:29Z

107: A Rigorous Benchmark with Multidimensional Evaluation for Deep Research  Agents: From Answers to Reports
Authors: ['Yang Yao', 'Yixu Wang', 'Yuxuan Zhang', 'Yi Lu', 'Tianle Gu', 'Lingyu Li', 'Dingyi Zhao', 'Keming Wu', 'Haozhe Wang', 'Ping Nie', 'Yan Teng', 'Yingchun Wang']
Summary: Artificial intelligence is undergoing the paradigm shift from closed languagemodels to interconnected agent systems capable of external perception andinformation integration. As a representative embodiment, Deep Research Agents(DRAs) systematically exhibit the capabilities for task decomposition,cross-source retrieval, multi-stage reasoning, and structured output, whichmarkedly enhance performance on complex and open-ended tasks. However, existingbenchmarks remain deficient in evaluation dimensions, response formatting, andscoring mechanisms, limiting their capacity to assess such systems effectively.This paper introduces a rigorous benchmark and a multidimensional evaluationframework tailored to DRAs and report-style responses. The benchmark comprises214 expert-curated challenging queries distributed across 10 broad thematicdomains, each accompanied by manually constructed reference bundles to supportcomposite evaluation. The framework enables comprehensive evaluation oflong-form reports generated by DRAs, incorporating integrated scoring metricsfor semantic quality, topical focus, and retrieval trustworthiness. Extensiveexperimentation confirms the superior performance of mainstream DRAs overweb-search-tool-augmented reasoning models, yet reveals considerable scope forfurther improvement. This study provides a robust foundation for capabilityassessment, architectural refinement, and paradigm advancement in DRA systems.
摘要: 人工智能正在经历从封闭语言模型到具备外部感知和信息整合能力的互联代理系统的范式转变。作为其典型代表，深度研究代理（DRA）系统性地展现了任务分解、跨源检索、多阶段推理和结构化输出等能力，显著提升了其在复杂和开放式任务上的表现。然而，现有基准在评估维度、响应格式和评分机制方面仍存在不足，限制了其有效评估此类系统的能力。本文介绍了一个专为深度研究代理及报告式响应设计的严格基准和多维评估框架。该基准包含214个由专家精心策划的难题，涵盖10个广泛的主题领域，每个问题均配有手动构建的参考包以支持综合评估。该框架能够对深度研究代理生成的长篇报告进行全面评估，整合了语义质量、主题聚焦和检索可信度的评分指标。大量实验证实，主流深度研究代理在性能上优于配备网络搜索工具的推理模型，但同时也揭示了其进一步改进的巨大空间。本研究为深度研究代理系统的能力评估、架构优化和范式演进提供了坚实的基础。
Link: http://arxiv.org/abs/2510.02190v1
Updated: 2025-10-02T16:40:02Z

108: UpSafe$^\circ$C: Upcycling for Controllable Safety in Large Language  Models
Authors: ['Yuhao Sun', 'Zhuoer Xu', 'Shiwen Cui', 'Kun Yang', 'Lingyun Yu', 'Yongdong Zhang', 'Hongtao Xie']
Summary: Large Language Models (LLMs) have achieved remarkable progress across a widerange of tasks, but remain vulnerable to safety risks such as harmful contentgeneration and jailbreak attacks. Existing safety techniques -- includingexternal guardrails, inference-time guidance, and post-training alignment --each face limitations in balancing safety, utility, and controllability. Inthis work, we propose UpSafe$^\circ$C, a unified framework for enhancing LLMsafety through safety-aware upcycling. Our approach first identifiessafety-critical layers and upcycles them into a sparse Mixture-of-Experts (MoE)structure, where the router acts as a soft guardrail that selectively activatesoriginal MLPs and added safety experts. We further introduce a two-stage SFTstrategy to strengthen safety discrimination while preserving generalcapabilities. To enable flexible control at inference time, we introduce asafety temperature mechanism, allowing dynamic adjustment of the trade-offbetween safety and utility. Experiments across multiple benchmarks, base model,and model scales demonstrate that UpSafe$^\circ$C achieves robust safetyimprovements against harmful and jailbreak inputs, while maintainingcompetitive performance on general tasks. Moreover, analysis shows that safetytemperature provides fine-grained inference-time control that achieves thePareto-optimal frontier between utility and safety. Our results highlight a newdirection for LLM safety: moving from static alignment toward dynamic, modular,and inference-aware control.
摘要: 大型语言模型（LLMs）在广泛任务中取得了显著进展，但仍面临有害内容生成和越狱攻击等安全风险。现有的安全技术——包括外部护栏、推理时指导和训练后对齐——在平衡安全性、实用性和可控性方面均存在局限。在本研究中，我们提出了UpSafe$^\circ$C，一个通过安全感知升级来增强LLM安全性的统一框架。我们的方法首先识别安全关键层，并将其升级为稀疏的专家混合（MoE）结构，其中路由器作为软护栏，选择性激活原始MLP和新增的安全专家。我们进一步引入两阶段SFT策略，以在保留通用能力的同时强化安全判别能力。为在推理时实现灵活控制，我们引入了安全温度机制，允许动态调整安全性与实用性之间的权衡。在多个基准测试、基础模型和模型规模上的实验表明，UpSafe$^\circ$C在应对有害和越狱输入时实现了稳健的安全提升，同时在通用任务上保持了具有竞争力的性能。此外，分析显示，安全温度提供了细粒度的推理时控制，实现了实用性与安全性之间的帕累托最优前沿。我们的结果凸显了LLM安全的新方向：从静态对齐转向动态、模块化和推理感知控制。
Link: http://arxiv.org/abs/2510.02194v1
Updated: 2025-10-02T16:43:33Z

109: ARUQULA -- An LLM based Text2SPARQL Approach using ReAct and Knowledge  Graph Exploration Utilities
Authors: ['Felix Brei', 'Lorenz Bühmann', 'Johannes Frey', 'Daniel Gerber', 'Lars-Peter Meyer', 'Claus Stadler', 'Kirill Bulert']
Summary: Interacting with knowledge graphs can be a daunting task for people without abackground in computer science since the query language that is used (SPARQL)has a high barrier of entry. Large language models (LLMs) can lower thatbarrier by providing support in the form of Text2SPARQL translation. In thispaper we introduce a generalized method based on SPINACH, an LLM backed agentthat translates natural language questions to SPARQL queries not in a singleshot, but as an iterative process of exploration and execution. We describe theoverall architecture and reasoning behind our design decisions, and alsoconduct a thorough analysis of the agent behavior to gain insights into futureareas for targeted improvements. This work was motivated by the Text2SPARQLchallenge, a challenge that was held to facilitate improvements in theText2SPARQL domain.
摘要: 对于没有计算机科学背景的人来说，与知识图谱交互可能是一项艰巨的任务，因为所使用的查询语言（SPARQL）具有很高的入门门槛。大型语言模型（LLM）可以通过提供Text2SPARQL翻译支持来降低这一门槛。在本文中，我们介绍了一种基于SPINACH的通用方法，SPINACH是一个由大型语言模型支持的代理，它将自然语言问题翻译成SPARQL查询，不是一次性完成，而是作为一个探索和执行的迭代过程。我们描述了整体架构以及我们设计决策背后的原因，并对代理行为进行了彻底的分析，以深入了解未来需要针对性改进的领域。这项工作受到了Text2SPARQL挑战的推动，该挑战旨在促进Text2SPARQL领域的改进。
Link: http://arxiv.org/abs/2510.02200v1
Updated: 2025-10-02T16:49:27Z

110: Detection of Chagas Disease from the ECG: The George B. Moody PhysioNet  Challenge 2025
Authors: ['Matthew A. Reyna', 'Zuzana Koscova', 'Jan Pavlus', 'Soheil Saghafi', 'James Weigle', 'Andoni Elola', 'Salman Seyedi', 'Kiersten Campbell', 'Qiao Li', 'Ali Bahrami Rad', 'Antônio H. Ribeiro', 'Antonio Luiz P. Ribeiro', 'Reza Sameni', 'Gari D. Clifford']
Summary: Objective: Chagas disease is a parasitic infection that is endemic to SouthAmerica, Central America, and, more recently, the U.S., primarily transmittedby insects. Chronic Chagas disease can cause cardiovascular diseases anddigestive problems. Serological testing capacities for Chagas disease arelimited, but Chagas cardiomyopathy often manifests in ECGs, providing anopportunity to prioritize patients for testing and treatment. Approach: TheGeorge B. Moody PhysioNet Challenge 2025 invites teams to develop algorithmicapproaches for identifying Chagas disease from electrocardiograms (ECGs). Mainresults: This Challenge provides multiple innovations. First, we leveragedseveral datasets with labels from patient reports and serological testing,provided a large dataset with weak labels and smaller datasets with stronglabels. Second, we augmented the data to support model robustness andgeneralizability to unseen data sources. Third, we applied an evaluation metricthat captured the local serological testing capacity for Chagas disease toframe the machine learning problem as a triage task. Significance: Over 630participants from 111 teams submitted over 1300 entries during the Challenge,representing diverse approaches from academia and industry worldwide.
摘要: 目标：查加病是一种寄生虫感染，流行于南美洲、中美洲，以及最近的美国，主要通过昆虫传播。慢性查加病可导致心血管疾病和消化系统问题。查加病的血清学检测能力有限，但查加病心肌病常在心电图（ECG）中显现，为优先安排患者进行检测和治疗提供了机会。方法：2025年George B. Moody PhysioNet挑战赛邀请各团队开发算法方法，从心电图（ECG）中识别查加病。主要成果：本挑战赛提供了多项创新。首先，我们利用了多个来自患者报告和血清学检测的标签数据集，提供了一个带有弱标签的大型数据集和多个带有强标签的小型数据集。其次，我们通过数据增强来提升模型的鲁棒性和对未见数据源的泛化能力。第三，我们采用了一种能够反映查加病局部血清学检测能力的评估指标，将机器学习问题构建为分诊任务。意义：在挑战赛期间，来自111个团队的630多名参与者提交了1300多份作品，展现了来自全球学术界和工业界的多样化方法。
Link: http://arxiv.org/abs/2510.02202v1
Updated: 2025-10-02T16:50:36Z

111: DiFFPO: Training Diffusion LLMs to Reason Fast and Furious via  Reinforcement Learning
Authors: ['Hanyang Zhao', 'Dawen Liang', 'Wenpin Tang', 'David Yao', 'Nathan Kallus']
Summary: We propose DiFFPO, Diffusion Fast and Furious Policy Optimization, a unifiedframework for training masked diffusion large language models (dLLMs) to reasonnot only better (furious), but also faster via reinforcement learning (RL). Wefirst unify the existing baseline approach such as d1 by proposing to trainsurrogate policies via off-policy RL, whose likelihood is much more tractableas an approximation to the true dLLM policy. This naturally motivates a moreaccurate and informative two-stage likelihood approximation combined withimportance sampling correction, which leads to generalized RL algorithms withbetter sample efficiency and superior task performance. Second, we propose anew direction of joint training efficient samplers/controllers of dLLMs policy.Via RL, we incentivize dLLMs' natural multi-token prediction capabilities byletting the model learn to adaptively allocate an inference threshold for eachprompt. By jointly training the sampler, we yield better accuracies with lowernumber of function evaluations (NFEs) compared to training the model only,obtaining the best performance in improving the Pareto frontier of theinference-time compute of dLLMs. We showcase the effectiveness of our pipelineby training open source large diffusion language models over benchmark math andplanning tasks.
摘要: 我们提出了DiFFPO，即扩散快速与激进的策略优化，这是一个通过强化学习（RL）训练掩码扩散大型语言模型（dLLM）的统一框架，旨在使其推理不仅更好（激进），而且更快。我们首先通过提出使用离线策略RL训练替代策略，将现有基线方法（如d1）进行统一，这些策略的似然性作为真实dLLM策略的近似，更具可计算性。这自然地激发了一种更准确且信息丰富的两阶段似然近似方法，并结合重要性采样校正，从而产生具有更好样本效率和卓越任务性能的广义RL算法。其次，我们提出了联合训练dLLM策略的高效采样器/控制器的新方向。通过RL，我们通过让模型学习为每个提示自适应分配推理阈值，来激励dLLM的自然多令牌预测能力。通过联合训练采样器，与仅训练模型相比，我们以更少的函数评估次数（NFEs）获得了更高的准确性，在提升dLLM推理时间计算的帕累托前沿方面取得了最佳性能。我们通过在基准数学和规划任务上训练开源大型扩散语言模型，展示了我们流程的有效性。
Link: http://arxiv.org/abs/2510.02212v1
Updated: 2025-10-02T16:57:24Z

112: TempoControl: Temporal Attention Guidance for Text-to-Video Models
Authors: ['Shira Schiber', 'Ofir Lindenbaum', 'Idan Schwartz']
Summary: Recent advances in generative video models have enabled the creation ofhigh-quality videos based on natural language prompts. However, these modelsfrequently lack fine-grained temporal control, meaning they do not allow usersto specify when particular visual elements should appear within a generatedsequence. In this work, we introduce TempoControl, a method that allows fortemporal alignment of visual concepts during inference, without requiringretraining or additional supervision. TempoControl utilizes cross-attentionmaps, a key component of text-to-video diffusion models, to guide the timing ofconcepts through a novel optimization approach. Our method steers attentionusing three complementary principles: aligning its temporal shape with acontrol signal (via correlation), amplifying it where visibility is needed (viaenergy), and maintaining spatial focus (via entropy). TempoControl allowsprecise control over timing while ensuring high video quality and diversity. Wedemonstrate its effectiveness across various video generation applications,including temporal reordering for single and multiple objects, as well asaction and audio-aligned generation.
摘要: 生成式视频模型的最新进展使得基于自然语言提示创建高质量视频成为可能。然而，这些模型通常缺乏细粒度的时序控制能力，即不允许用户指定特定视觉元素应在生成序列中的何时出现。在这项工作中，我们介绍了 TempoControl，这是一种在推理过程中实现视觉概念时序对齐的方法，无需重新训练或额外的监督。TempoControl 利用交叉注意力图（这是文本到视频扩散模型的一个关键组件），通过一种新颖的优化方法来引导概念的时序。我们的方法通过三个互补的原则来引导注意力：将其时序形状与控制信号对齐（通过相关性），在需要可见性的地方对其进行放大（通过能量），以及保持空间焦点（通过熵）。TempoControl 允许对时序进行精确控制，同时确保高质量的视频和多样性。我们在各种视频生成应用中展示了其有效性，包括对单个和多个对象的时序重排，以及动作和音频对齐的生成。
Link: http://arxiv.org/abs/2510.02226v1
Updated: 2025-10-02T17:13:35Z

113: More Than One Teacher: Adaptive Multi-Guidance Policy Optimization for  Diverse Exploration
Authors: ['Xiaoyang Yuan', 'Yujuan Ding', 'Yi Bin', 'Wenqi Shao', 'Jinyu Cai', 'Jingkuan Song', 'Yang Yang', 'Hengtao Shen']
Summary: Reinforcement Learning with Verifiable Rewards (RLVR) is a promising paradigmfor enhancing the reasoning ability in Large Language Models (LLMs). However,prevailing methods primarily rely on self-exploration or a single off-policyteacher to elicit long chain-of-thought (LongCoT) reasoning, which mayintroduce intrinsic model biases and restrict exploration, ultimately limitingreasoning diversity and performance. Drawing inspiration from multi-teacherstrategies in knowledge distillation, we introduce Adaptive Multi-GuidancePolicy Optimization (AMPO), a novel framework that adaptively leveragesguidance from multiple proficient teacher models, but only when the on-policymodel fails to generate correct solutions. This "guidance-on-demand" approachexpands exploration while preserving the value of self-discovery. Moreover,AMPO incorporates a comprehension-based selection mechanism, prompting thestudent to learn from the reasoning paths that it is most likely to comprehend,thus balancing broad exploration with effective exploitation. Extensiveexperiments show AMPO substantially outperforms a strong baseline (GRPO), witha 4.3% improvement on mathematical reasoning tasks and 12.2% onout-of-distribution tasks, while significantly boosting Pass@k performance andenabling more diverse exploration. Notably, using four peer-sized teachers, ourmethod achieves comparable results to approaches that leverage a single, morepowerful teacher (e.g., DeepSeek-R1) with more data. These results demonstratea more efficient and scalable path to superior reasoning and generalizability.Our code is available at https://github.com/SII-Enigma/AMPO.
摘要: 可验证奖励强化学习（RLVR）是一种增强大型语言模型（LLMs）推理能力的前沿范式。然而，现有方法主要依赖自我探索或单一离线教师模型来生成长链式思维（LongCoT）推理，这可能会引入固有的模型偏差并限制探索，最终限制推理的多样性和性能。受知识蒸馏中多教师策略的启发，我们提出了自适应多引导策略优化（AMPO），这是一种新颖的框架，仅在策略模型无法生成正确解决方案时，才自适应地利用多个熟练教师模型的引导。这种“按需引导”的方法在扩展探索的同时保留了自我发现的价值。此外，AMPO还融入了一种基于理解的选择机制，促使学生模型从其最可能理解的推理路径中学习，从而在广泛探索与有效利用之间取得平衡。大量实验表明，AMPO显著优于强大的基线模型（GRPO），在数学推理任务上提升了4.3%，在分布外任务上提升了12.2%，同时显著提高了Pass@k性能并实现了更多样化的探索。值得注意的是，使用四个同等规模的教师模型，我们的方法取得了与利用单一更强大教师模型（如DeepSeek-R1）和更多数据的方法相当的结果。这些结果展示了一条通往卓越推理和泛化能力的更高效、可扩展的路径。我们的代码可在https://github.com/SII-Enigma/AMPO获取。
Link: http://arxiv.org/abs/2510.02227v1
Updated: 2025-10-02T17:14:00Z

114: The Reasoning Boundary Paradox: How Reinforcement Learning Constrains  Language Models
Authors: ['Phuc Minh Nguyen', 'Chinh D. La', 'Duy M. H. Nguyen', 'Nitesh V. Chawla', 'Binh T. Nguyen', 'Khoa D. Doan']
Summary: Reinforcement Learning with Verifiable Rewards (RLVR) has emerged as a keymethod for improving Large Language Models' reasoning capabilities, yet recentevidence suggests it may paradoxically shrink the reasoning boundary ratherthan expand it. This paper investigates the shrinkage issue of RLVR byanalyzing its learning dynamics and reveals two critical phenomena that explainthis failure. First, we expose negative interference in RLVR, where learning tosolve certain training problems actively reduces the likelihood of correctsolutions for others, leading to the decline of Pass@$k$ performance, or theprobability of generating a correct solution within $k$ attempts. Second, weuncover the winner-take-all phenomenon: RLVR disproportionately reinforcesproblems with high likelihood, correct solutions, under the base model, whilesuppressing other initially low-likelihood ones. Through extensive theoreticaland empirical analysis on multiple mathematical reasoning benchmarks, we showthat this effect arises from the inherent on-policy sampling in standard RLobjectives, causing the model to converge toward narrow solution strategies.Based on these insights, we propose a simple yet effective data curationalgorithm that focuses RLVR learning on low-likelihood problems, achievingnotable improvement in Pass@$k$ performance. Our code is available athttps://github.com/mail-research/SELF-llm-interference.
摘要: 可验证奖励强化学习（RLVR）已成为提升大型语言模型推理能力的关键方法，但近期证据表明，它可能反而会缩小而非扩展模型的推理边界。本文通过分析RLVR的学习动态来研究其收缩问题，并揭示了解释这一失败的两个关键现象。首先，我们揭示了RLVR中的负干扰现象：学习解决某些训练问题会主动降低其他问题正确解答的可能性，从而导致Pass@$k$性能（即在$k$次尝试内生成正确解的概率）下降。其次，我们发现了赢家通吃现象：RLVR会不成比例地强化基础模型下高可能性、正确解答的问题，同时抑制其他初始低可能性的问题。通过对多个数学推理基准进行广泛的理论和实证分析，我们表明这种效应源于标准强化学习目标中固有的在策略采样，导致模型收敛于狭窄的解决策略。基于这些见解，我们提出了一种简单而有效的数据筛选算法，将RLVR的学习重点集中在低可能性问题上，从而显著提升了Pass@$k$性能。我们的代码可在https://github.com/mail-research/SELF-llm-interference获取。
Link: http://arxiv.org/abs/2510.02230v1
Updated: 2025-10-02T17:17:27Z

115: RewardMap: Tackling Sparse Rewards in Fine-grained Visual Reasoning via  Multi-Stage Reinforcement Learning
Authors: ['Sicheng Feng', 'Kaiwen Tuo', 'Song Wang', 'Lingdong Kong', 'Jianke Zhu', 'Huan Wang']
Summary: Fine-grained visual reasoning remains a core challenge for multimodal largelanguage models (MLLMs). The recently introduced ReasonMap highlights this gapby showing that even advanced MLLMs struggle with spatial reasoning instructured and information-rich settings such as transit maps, a task of clearpractical and scientific importance. However, standard reinforcement learning(RL) on such tasks is impeded by sparse rewards and unstable optimization. Toaddress this, we first construct ReasonMap-Plus, an extended dataset thatintroduces dense reward signals through Visual Question Answering (VQA) tasks,enabling effective cold-start training of fine-grained visual understandingskills. Next, we propose RewardMap, a multi-stage RL framework designed toimprove both visual understanding and reasoning capabilities of MLLMs.RewardMap incorporates two key designs. First, we introduce a difficulty-awarereward design that incorporates detail rewards, directly tackling the sparserewards while providing richer supervision. Second, we propose a multi-stage RLscheme that bootstraps training from simple perception to complex reasoningtasks, offering a more effective cold-start strategy than conventionalSupervised Fine-Tuning (SFT). Experiments on ReasonMap and ReasonMap-Plusdemonstrate that each component of RewardMap contributes to consistentperformance gains, while their combination yields the best results. Moreover,models trained with RewardMap achieve an average improvement of 3.47% across 6benchmarks spanning spatial reasoning, fine-grained visual reasoning, andgeneral tasks beyond transit maps, underscoring enhanced visual understandingand reasoning capabilities.
摘要: 细粒度视觉推理仍然是多模态大型语言模型（MLLM）的一个核心挑战。最近提出的ReasonMap通过表明即使先进的MLLMs在结构化且信息丰富的环境（如交通地图）中进行空间推理时也存在困难，从而凸显了这一差距，而这项任务具有明确的实践和科学重要性。然而，针对此类任务的标准强化学习（RL）因奖励稀疏和优化不稳定而受阻。为解决此问题，我们首先构建了ReasonMap-Plus，这是一个扩展数据集，通过视觉问答（VQA）任务引入密集奖励信号，从而实现细粒度视觉理解技能的有效冷启动训练。接下来，我们提出了RewardMap，这是一个旨在提升MLLMs视觉理解和推理能力的多阶段强化学习框架。RewardMap包含两个关键设计。首先，我们引入了一种难度感知奖励设计，该设计融合了细节奖励，直接解决奖励稀疏问题，同时提供更丰富的监督。其次，我们提出了一种多阶段强化学习方案，该方案将训练从简单感知逐步引导至复杂推理任务，比传统的监督微调（SFT）提供了更有效的冷启动策略。在ReasonMap和ReasonMap-Plus上的实验表明，RewardMap的每个组成部分均带来了持续的性能提升，而它们的组合则取得了最佳结果。此外，使用RewardMap训练的模型在涵盖空间推理、细粒度视觉推理及交通地图之外通用任务的6个基准测试中，平均实现了3.47%的提升，这凸显了其增强的视觉理解和推理能力。
Link: http://arxiv.org/abs/2510.02240v1
Updated: 2025-10-02T17:29:46Z

116: ExGRPO: Learning to Reason from Experience
Authors: ['Runzhe Zhan', 'Yafu Li', 'Zhi Wang', 'Xiaoye Qu', 'Dongrui Liu', 'Jing Shao', 'Derek F. Wong', 'Yu Cheng']
Summary: Reinforcement learning from verifiable rewards (RLVR) is an emerging paradigmfor improving the reasoning ability of large language models. However, standardon-policy training discards rollout experiences after a single update, leadingto computational inefficiency and instability. While prior work on RL hashighlighted the benefits of reusing past experience, the role of experiencecharacteristics in shaping learning dynamics of large reasoning models remainsunderexplored. In this paper, we are the first to investigate what makes areasoning experience valuable and identify rollout correctness and entropy aseffective indicators of experience value. Based on these insights, we proposeExGRPO (Experiential Group Relative Policy Optimization), a framework thatorganizes and prioritizes valuable experiences, and employs a mixed-policyobjective to balance exploration with experience exploitation. Experiments onfive backbone models (1.5B-8B parameters) show that ExGRPO consistentlyimproves reasoning performance on mathematical/general benchmarks, with anaverage gain of +3.5/7.6 points over on-policy RLVR. Moreover, ExGRPOstabilizes training on both stronger and weaker models where on-policy methodsfail. These results highlight principled experience management as a keyingredient for efficient and scalable RLVR.
摘要: 基于可验证奖励的强化学习（RLVR）是一种提升大语言模型推理能力的新兴范式。然而，标准的在策略训练在单次更新后即丢弃 rollout 经验，导致计算效率低下和不稳定。尽管先前关于强化学习的研究强调了复用过往经验的优势，但经验特征在塑造大型推理模型学习动态中的作用仍未得到充分探索。本文首次探讨了推理经验的价值所在，并识别出 rollout 正确性和熵作为经验价值的有效指标。基于这些见解，我们提出了 ExGRPO（经验分组相对策略优化），该框架通过组织和优先处理有价值的经验，并采用混合策略目标来平衡探索与经验利用。在五个基础模型（15亿-80亿参数）上的实验表明，ExGRPO 在数学/通用基准测试上持续提升推理性能，较在策略 RLVR 平均提升 3.5/7.6 个点。此外，ExGRPO 在更强和更弱模型上均能稳定训练，而在策略方法则无法做到。这些结果凸显了原则化的经验管理是实现高效且可扩展 RLVR 的关键要素。
Link: http://arxiv.org/abs/2510.02245v1
Updated: 2025-10-02T17:31:30Z

117: Explore Briefly, Then Decide: Mitigating LLM Overthinking via Cumulative  Entropy Regulation
Authors: ['Tianyi Jiang', 'Yi Bin', 'Yujuan Ding', 'Kainian Zhu', 'Fei Ma', 'Jingkuan Song', 'Heng Tao Shen']
Summary: Large Language Models (LLMs) have demonstrated remarkable reasoning abilitieson complex problems using long Chain-of-Thought (CoT) reasoning. However, theyoften suffer from overthinking, meaning generating unnecessarily lengthyreasoning steps for simpler problems. This issue may degrade the efficiency ofthe models and make them difficult to adapt the reasoning depth to thecomplexity of problems. To address this, we introduce a novel metric TokenEntropy Cumulative Average (TECA), which measures the extent of explorationthroughout the reasoning process. We further propose a novel reasoning paradigm-- Explore Briefly, Then Decide -- with an associated Cumulative EntropyRegulation (CER) mechanism. This paradigm leverages TECA to help the modeldynamically determine the optimal point to conclude its thought process andprovide a final answer, thus achieving efficient reasoning. Experimentalresults across diverse mathematical benchmarks show that our approachsubstantially mitigates overthinking without sacrificing problem-solvingability. With our thinking paradigm, the average response length decreases byup to 71% on simpler datasets, demonstrating the effectiveness of our method increating a more efficient and adaptive reasoning process.
摘要: 大型语言模型（LLMs）已通过长链式思维（CoT）推理展现出在复杂问题上的卓越推理能力。然而，它们常常陷入过度思考，即为简单问题生成不必要的冗长推理步骤。此问题可能降低模型效率，并使其难以根据问题复杂度调整推理深度。为解决此问题，我们引入了一种新颖的度量指标——令牌熵累积平均值（TECA），用于衡量推理过程中的探索程度。我们进一步提出了一种新型推理范式——“简短探索，后做决策”，并辅以累积熵调节（CER）机制。该范式利用TECA帮助模型动态确定结束思维过程并提供最终答案的最优节点，从而实现高效推理。在多样化数学基准测试中的实验结果表明，我们的方法在保持解题能力的同时显著缓解了过度思考。采用我们的思维范式后，模型在简单数据集上的平均响应长度缩短高达71%，证明了该方法在构建更高效、更具适应性的推理流程上的有效性。
Link: http://arxiv.org/abs/2510.02249v1
Updated: 2025-10-02T17:36:50Z

118: The Unreasonable Effectiveness of Scaling Agents for Computer Use
Authors: ['Gonzalo Gonzalez-Pumariega', 'Vincent Tu', 'Chih-Lun Lee', 'Jiachen Yang', 'Ang Li', 'Xin Eric Wang']
Summary: Computer-use agents (CUAs) hold promise for automating everyday digitaltasks, but their unreliability and high variance hinder their application tolong-horizon, complex tasks. We introduce Behavior Best-of-N (bBoN), a methodthat scales over agents by generating multiple rollouts and selecting amongthem using behavior narratives that describe the agents' rollouts. It enablesboth wide exploration and principled trajectory selection, substantiallyimproving robustness and success rates. On OSWorld, our bBoN scaling methodestablishes a new state of the art (SoTA) at 69.9%, significantly outperformingprior methods and approaching human-level performance at 72%, withcomprehensive ablations validating key design choices. We further demonstratestrong generalization results to different operating systems onWindowsAgentArena and AndroidWorld. Crucially, our results highlight theunreasonable effectiveness of scaling CUAs, when you do it right: effectivescaling requires structured trajectory understanding and selection, and bBoNprovides a practical framework to achieve this.
摘要: 计算机使用代理（CUA）有望实现日常数字任务的自动化，但其不可靠性和高方差阻碍了它们在长周期复杂任务中的应用。我们提出了行为最优N采样（bBoN）方法，该方法通过生成多个轨迹并使用描述代理轨迹的行为叙事来进行选择，从而实现代理的规模化。它既能进行广泛探索，又能实现原则性的轨迹选择，显著提高了鲁棒性和成功率。在OSWorld上，我们的bBoN规模化方法以69.9%的成绩树立了新的最先进水平（SoTA），显著优于先前的方法，并接近72%的人类水平表现，全面的消融实验验证了关键的设计选择。我们进一步展示了在WindowsAgentArena和AndroidWorld上对不同操作系统的强大泛化结果。至关重要的是，我们的结果突显了当方法正确时，规模化CUA的非凡有效性：有效的规模化需要结构化的轨迹理解和选择，而bBoN为实现这一目标提供了一个实用的框架。
Link: http://arxiv.org/abs/2510.02250v1
Updated: 2025-10-02T17:37:08Z

119: DragFlow: Unleashing DiT Priors with Region Based Supervision for Drag  Editing
Authors: ['Zihan Zhou', 'Shilin Lu', 'Shuli Leng', 'Shaocong Zhang', 'Zhuming Lian', 'Xinlei Yu', 'Adams Wai-Kin Kong']
Summary: Drag-based image editing has long suffered from distortions in the targetregion, largely because the priors of earlier base models, Stable Diffusion,are insufficient to project optimized latents back onto the natural imagemanifold. With the shift from UNet-based DDPMs to more scalable DiT with flowmatching (e.g., SD3.5, FLUX), generative priors have become significantlystronger, enabling advances across diverse editing tasks. However, drag-basedediting has yet to benefit from these stronger priors. This work proposes thefirst framework to effectively harness FLUX's rich prior for drag-basedediting, dubbed DragFlow, achieving substantial gains over baselines. We firstshow that directly applying point-based drag editing to DiTs performs poorly:unlike the highly compressed features of UNets, DiT features are insufficientlystructured to provide reliable guidance for point-wise motion supervision. Toovercome this limitation, DragFlow introduces a region-based editing paradigm,where affine transformations enable richer and more consistent featuresupervision. Additionally, we integrate pretrained open-domain personalizationadapters (e.g., IP-Adapter) to enhance subject consistency, while preservingbackground fidelity through gradient mask-based hard constraints. Multimodallarge language models (MLLMs) are further employed to resolve task ambiguities.For evaluation, we curate a novel Region-based Dragging benchmark (ReD Bench)featuring region-level dragging instructions. Extensive experiments onDragBench-DR and ReD Bench show that DragFlow surpasses both point-based andregion-based baselines, setting a new state-of-the-art in drag-based imageediting. Code and datasets will be publicly available upon publication.
摘要: 基于拖拽的图像编辑长期以来一直受到目标区域失真问题的困扰，这主要是因为早期基础模型（如Stable Diffusion）的先验知识不足，无法将优化后的潜在变量有效投影回自然图像流形。随着基于UNet的DDPM向更具可扩展性的流匹配DiT（如SD3.5、FLUX）的转变，生成先验已显著增强，推动了多样化编辑任务的进步。然而，基于拖拽的编辑尚未从这些更强的先验中受益。本研究提出了首个有效利用FLUX丰富先验进行基于拖拽的编辑的框架，命名为DragFlow，相较于基线模型实现了显著提升。我们首先证明，直接将基于点的拖拽编辑应用于DiT效果不佳：与UNet的高度压缩特征不同，DiT特征结构化程度不足，无法为逐点运动监督提供可靠指导。为克服这一局限，DragFlow引入了基于区域的编辑范式，其中仿射变换实现了更丰富、更一致的特征监督。此外，我们集成了预训练的开放域个性化适配器（如IP-Adapter）以增强主体一致性，同时通过基于梯度掩码的硬约束保持背景保真度。多模态大型语言模型（MLLMs）被进一步用于解决任务歧义。为进行评估，我们构建了一个包含区域级拖拽指令的新型基于区域拖拽基准（ReD Bench）。在DragBench-DR和ReD Bench上的大量实验表明，DragFlow超越了基于点和基于区域的基线模型，在基于拖拽的图像编辑领域树立了新的最先进水平。代码和数据集将在发表后公开可用。
Link: http://arxiv.org/abs/2510.02253v1
Updated: 2025-10-02T17:39:13Z

120: RLAD: Training LLMs to Discover Abstractions for Solving Reasoning  Problems
Authors: ['Yuxiao Qu', 'Anikait Singh', 'Yoonho Lee', 'Amrith Setlur', 'Ruslan Salakhutdinov', 'Chelsea Finn', 'Aviral Kumar']
Summary: Reasoning requires going beyond pattern matching or memorization of solutionsto identify and implement "algorithmic procedures" that can be used to deduceanswers to hard problems. Doing so requires realizing the most relevantprimitives, intermediate results, or shared procedures, and building upon them.While RL post-training on long chains of thought ultimately aims to uncoverthis kind of algorithmic behavior, most reasoning traces learned by largemodels fail to consistently capture or reuse procedures, instead drifting intoverbose and degenerate exploration. To address more effective reasoning, weintroduce reasoning abstractions: concise natural language descriptions ofprocedural and factual knowledge that guide the model toward learningsuccessful reasoning. We train models to be capable of proposing multipleabstractions given a problem, followed by RL that incentivizes building asolution while using the information provided by these abstractions. Thisresults in a two-player RL training paradigm, abbreviated as RLAD, that jointlytrains an abstraction generator and a solution generator. This setupeffectively enables structured exploration, decouples learning signals ofabstraction proposal and solution generation, and improves generalization toharder problems. We also show that allocating more test-time compute togenerating abstractions is more beneficial for performance than generating moresolutions at large test budgets, illustrating the role of abstractions inguiding meaningful exploration.
摘要: 推理需要超越模式匹配或对解决方案的简单记忆，以识别并实现可用于推导难题答案的“算法程序”。这需要识别最相关的基元、中间结果或共享程序，并在此基础上进行构建。虽然基于长思维链的强化学习后训练最终旨在揭示此类算法行为，但大模型学习到的大多数推理轨迹未能持续捕获或重用程序，反而陷入冗长且退化的探索。为解决更有效的推理问题，我们引入了推理抽象：对程序性和事实性知识的简洁自然语言描述，用于引导模型学习成功的推理。我们训练模型能够针对给定问题提出多种抽象，随后通过强化学习激励模型利用这些抽象提供的信息构建解决方案。这形成了一种双人强化学习训练范式，简称为RLAD，该范式联合训练抽象生成器和解决方案生成器。这种设置有效实现了结构化探索，解耦了抽象提议与解决方案生成的学习信号，并提升了对更难问题的泛化能力。我们还证明，在较大的测试预算下，将更多测试时间计算资源分配给生成抽象比生成更多解决方案更有利于性能提升，这说明了抽象在引导有意义探索中的作用。
Link: http://arxiv.org/abs/2510.02263v1
Updated: 2025-10-02T17:44:23Z

121: Paving the Way Towards Kinematic Assessment Using Monocular Video: A  Preclinical Benchmark of State-of-the-Art Deep-Learning-Based 3D Human Pose  Estimators Against Inertial Sensors in Daily Living Activities
Authors: ['Mario Medrano-Paredes', 'Carmen Fernández-González', 'Francisco-Javier Díaz-Pernas', 'Hichem Saoudi', 'Javier González-Alonso', 'Mario Martínez-Zarzuela']
Summary: Advances in machine learning and wearable sensors offer new opportunities forcapturing and analyzing human movement outside specialized laboratories.Accurate assessment of human movement under real-world conditions is essentialfor telemedicine, sports science, and rehabilitation. This preclinicalbenchmark compares monocular video-based 3D human pose estimation models withinertial measurement units (IMUs), leveraging the VIDIMU dataset containing atotal of 13 clinically relevant daily activities which were captured using bothcommodity video cameras and five IMUs. During this initial study only healthysubjects were recorded, so results cannot be generalized to pathologicalcohorts. Joint angles derived from state-of-the-art deep learning frameworks(MotionAGFormer, MotionBERT, MMPose 2D-to-3D pose lifting, and NVIDIABodyTrack) were evaluated against joint angles computed from IMU data usingOpenSim inverse kinematics following the Human3.6M dataset format with 17keypoints. Among them, MotionAGFormer demonstrated superior performance,achieving the lowest overall RMSE ($9.27\deg \pm 4.80\deg$) and MAE ($7.86\deg\pm 4.18\deg$), as well as the highest Pearson correlation ($0.86 \pm 0.15$)and the highest coefficient of determination $R^{2}$ ($0.67 \pm 0.28$). Theresults reveal that both technologies are viable for out-of-the-lab kinematicassessment. However, they also highlight key trade-offs between video- andsensor-based approaches including costs, accessibility, and precision. Thisstudy clarifies where off-the-shelf video models already provide clinicallypromising kinematics in healthy adults and where they lag behind IMU-basedestimates while establishing valuable guidelines for researchers and cliniciansseeking to develop robust, cost-effective, and user-friendly solutions fortelehealth and remote patient monitoring.
摘要: 机器学习和可穿戴传感器的进步为在专业实验室之外捕捉和分析人体运动提供了新的机遇。在现实世界条件下对人体运动进行准确评估，对远程医疗、运动科学和康复医学至关重要。这项临床前基准研究对比了基于单目视频的三维人体姿态估计模型与惯性测量单元（IMUs），并利用了VIDIMU数据集，该数据集包含总共13种临床相关的日常活动，这些活动通过消费级视频摄像头和五个惯性测量单元进行捕捉。在此初步研究中，仅记录了健康受试者的数据，因此结果无法推广至病理队列。从最先进的深度学习框架（MotionAGFormer、MotionBERT、MMPose 2D到3D姿态提升以及NVIDIA BodyTrack）中得出的关节角度，与使用OpenSim逆向运动学并遵循Human3.6M数据集格式（包含17个关键点）从IMU数据计算出的关节角度进行了评估。在这些模型中，MotionAGFormer表现出卓越性能，实现了最低的整体均方根误差（$9.27\deg \pm 4.80\deg$）和平均绝对误差（$7.86\deg \pm 4.18\deg$），以及最高的皮尔逊相关系数（$0.86 \pm 0.15$）和最高的决定系数$R^{2}$（$0.67 \pm 0.28$）。结果表明，这两种技术都适用于实验室外的运动学评估。然而，研究也揭示了基于视频和基于传感器的方法之间的关键权衡，包括成本、可及性和精度。该研究明确了现成的视频模型在何处已能为健康成年人提供具有临床前景的运动学数据，以及在哪些方面仍落后于基于IMU的估计，同时为寻求开发稳健、经济高效且用户友好的远程医疗和远程患者监测解决方案的研究人员和临床医生提供了宝贵的指导。
Link: http://arxiv.org/abs/2510.02264v1
Updated: 2025-10-02T17:44:31Z

122: How to Combat Reactive and Dynamic Jamming Attacks with Reinforcement  Learning
Authors: ['Yalin E. Sagduyu', 'Tugba Erpek', 'Kemal Davaslioglu', 'Sastry Kompella']
Summary: This paper studies the problem of mitigating reactive jamming, where a jammeradopts a dynamic policy of selecting channels and sensing thresholds to detectand jam ongoing transmissions. The transmitter-receiver pair learns to avoidjamming and optimize throughput over time (without prior knowledge of channelconditions or jamming strategies) by using reinforcement learning (RL) to adapttransmit power, modulation, and channel selection. Q-learning is employed fordiscrete jamming-event states, while Deep Q-Networks (DQN) are employed forcontinuous states based on received power. Through different reward functionsand action sets, the results show that RL can adapt rapidly to spectrumdynamics and sustain high rates as channels and jamming policies change overtime.
摘要: 本文研究缓解反应式干扰的问题，其中干扰源采用动态策略来选择信道和感知阈值，以检测并干扰正在进行的传输。发送方-接收方对通过使用强化学习（RL）来调整发射功率、调制方式和信道选择，从而学会避免干扰并随时间优化吞吐量（无需事先了解信道状况或干扰策略）。针对离散的干扰事件状态，采用Q-learning；而对于基于接收功率的连续状态，则采用深度Q网络（DQN）。通过不同的奖励函数和动作集，结果表明，强化学习能够快速适应频谱动态，并在信道和干扰策略随时间变化时维持高速率。
Link: http://arxiv.org/abs/2510.02265v1
Updated: 2025-10-02T17:44:38Z

123: microCLIP: Unsupervised CLIP Adaptation via Coarse-Fine Token Fusion for  Fine-Grained Image Classification
Authors: ['Sathira Silva', 'Eman Ali', 'Chetan Arora', 'Muhammad Haris Khan']
Summary: Unsupervised adaptation of CLIP-based vision-language models (VLMs) forfine-grained image classification requires sensitivity to microscopic localcues. While CLIP exhibits strong zero-shot transfer, its reliance on coarseglobal features restricts its performance on fine-grained classification tasks.Prior efforts inject fine-grained knowledge by aligning large language model(LLM) descriptions with the CLIP $\texttt{[CLS]}$ token; however, this approachoverlooks spatial precision. We propose $\textbf{microCLIP}$, a self-trainingframework that jointly refines CLIP's visual and textual representations usingfine-grained cues. At its core is Saliency-Oriented Attention Pooling (SOAP)within a lightweight TokenFusion module, which builds a saliency-guided$\texttt{[FG]}$ token from patch embeddings and fuses it with the global$\texttt{[CLS]}$ token for coarse-fine alignment. To stabilize adaptation, weintroduce a two-headed LLM-derived classifier: a frozen classifier that, viamulti-view alignment, provides a stable text-based prior for pseudo-labeling,and a learnable classifier initialized from LLM descriptions and fine-tunedwith TokenFusion. We further develop Dynamic Knowledge Aggregation, whichconvexly combines fixed LLM/CLIP priors with TokenFusion's evolving logits toiteratively refine pseudo-labels. Together, these components uncover latentfine-grained signals in CLIP, yielding a consistent $2.90\%$ average accuracygain across 13 fine-grained benchmarks while requiring only light adaptation.Our code is available at https://github.com/sathiiii/microCLIP.
摘要: 对基于CLIP的视觉语言模型进行无监督调整以实现细粒度图像分类，需要对微观局部线索具备敏感性。尽管CLIP展现出强大的零样本迁移能力，其对粗粒度全局特征的依赖限制了其在细粒度分类任务上的性能。先前的研究通过将大型语言模型的描述与CLIP的[CLS]标记对齐来注入细粒度知识；然而，这种方法忽略了空间精度。我们提出了microCLIP，这是一个利用细粒度线索联合优化CLIP视觉和文本表示的自训练框架。其核心是在轻量级TokenFusion模块中实现的显著性导向注意力池化，该模块从图像块嵌入中构建由显著性引导的[FG]标记，并将其与全局[CLS]标记融合以实现粗细粒度对齐。为了稳定调整过程，我们引入了一个双头大型语言模型衍生分类器：一个冻结分类器通过多视图对齐为伪标签生成提供稳定的基于文本的先验知识，以及一个可学习分类器，该分类器由大型语言模型描述初始化并利用TokenFusion进行微调。我们进一步开发了动态知识聚合方法，该方法将固定的大型语言模型/CLIP先验知识与TokenFusion不断演化的逻辑值进行凸组合，以迭代优化伪标签。这些组件共同揭示了CLIP中潜在的细粒度信号，在13个细粒度基准测试上实现了2.90%的平均准确率提升，且仅需轻量级调整。我们的代码可在https://github.com/sathiiii/microCLIP获取。
Link: http://arxiv.org/abs/2510.02270v1
Updated: 2025-10-02T17:47:39Z

124: InfoMosaic-Bench: Evaluating Multi-Source Information Seeking in  Tool-Augmented Agents
Authors: ['Yaxin Du', 'Yuanshuo Zhang', 'Xiyuan Yang', 'Yifan Zhou', 'Cheng Wang', 'Gongyi Zou', 'Xianghe Pang', 'Wenhao Wang', 'Menglan Chen', 'Shuo Tang', 'Zhiyu Li', 'Siheng Chen']
Summary: Information seeking is a fundamental requirement for humans. However,existing LLM agents rely heavily on open-web search, which exposes twofundamental weaknesses: online content is noisy and unreliable, and manyreal-world tasks require precise, domain-specific knowledge unavailable fromthe web. The emergence of the Model Context Protocol (MCP) now allows agents tointerface with thousands of specialized tools, seemingly resolving thislimitation. Yet it remains unclear whether agents can effectively leverage suchtools -- and more importantly, whether they can integrate them withgeneral-purpose search to solve complex tasks. Therefore, we introduceInfoMosaic-Bench, the first benchmark dedicated to multi-source informationseeking in tool-augmented agents. Covering six representative domains(medicine, finance, maps, video, web, and multi-domain integration),InfoMosaic-Bench requires agents to combine general-purpose search withdomain-specific tools. Tasks are synthesized with InfoMosaic-Flow, a scalablepipeline that grounds task conditions in verified tool outputs, enforcescross-source dependencies, and filters out shortcut cases solvable by triviallookup. This design guarantees both reliability and non-triviality. Experimentswith 14 state-of-the-art LLM agents reveal three findings: (i) web informationalone is insufficient, with GPT-5 achieving only 38.2% accuracy and 67.5% passrate; (ii) domain tools provide selective but inconsistent benefits, improvingsome domains while degrading others; and (iii) 22.4% of failures arise fromincorrect tool usage or selection, highlighting that current LLMs stillstruggle with even basic tool handling.
摘要: 信息寻求是人类的一项基本需求。然而，现有的大型语言模型代理严重依赖开放式网络搜索，这暴露了两个根本性弱点：网络内容嘈杂且不可靠，并且许多现实世界的任务需要网络无法提供的精确、特定领域的知识。模型上下文协议（MCP）的出现现在允许代理与数千种专业工具进行交互，似乎解决了这一限制。然而，目前尚不清楚代理能否有效利用这些工具——更重要的是，它们能否将这些工具与通用搜索相结合以解决复杂任务。因此，我们引入了InfoMosaic-Bench，这是首个专门用于工具增强代理多源信息寻求的基准。InfoMosaic-Bench涵盖六个代表性领域（医学、金融、地图、视频、网络和多领域集成），要求代理将通用搜索与特定领域工具相结合。任务通过InfoMosaic-Flow合成，这是一个可扩展的流程，它将任务条件基于已验证的工具输出，强制执行跨源依赖关系，并过滤出可通过简单查找解决的捷径案例。这一设计既保证了可靠性，也确保了任务的复杂性。对14种最先进的大型语言模型代理的实验揭示了三个发现：（i）仅凭网络信息是不够的，GPT-5的准确率仅为38.2%，通过率为67.5%；（ii）领域工具提供选择性但不一致的收益，改进了某些领域，却降低了其他领域的表现；（iii）22.4%的失败源于工具使用或选择不当，这凸显了当前大型语言模型在处理基本工具操作方面仍然存在困难。
Link: http://arxiv.org/abs/2510.02271v1
Updated: 2025-10-02T17:48:03Z

125: Parallel Scaling Law: Unveiling Reasoning Generalization through A  Cross-Linguistic Perspective
Authors: ['Wen Yang', 'Junhong Wu', 'Chong Li', 'Chengqing Zong', 'Jiajun Zhang']
Summary: Recent advancements in Reinforcement Post-Training (RPT) have significantlyenhanced the capabilities of Large Reasoning Models (LRMs), sparking increasedinterest in the generalization of RL-based reasoning. While existing work hasprimarily focused on investigating its generalization across tasks ormodalities, this study proposes a novel cross-linguistic perspective toinvestigate reasoning generalization. This raises a crucial question:$\textit{Does the reasoning capability achieved from English RPT effectivelytransfer to other languages?}$ We address this by systematically evaluatingEnglish-centric LRMs on multilingual reasoning benchmarks and introducing ametric to quantify cross-lingual transferability. Our findings reveal thatcross-lingual transferability varies significantly across initial model, targetlanguage, and training paradigm. Through interventional studies, we find thatmodels with stronger initial English capabilities tend to over-rely onEnglish-specific patterns, leading to diminished cross-lingual generalization.To address this, we conduct a thorough parallel training study. Experimentalresults yield three key findings: $\textbf{First-Parallel Leap}$, a substantialleap in performance when transitioning from monolingual to just a singleparallel language, and a predictable $\textbf{Parallel Scaling Law}$, revealingthat cross-lingual reasoning transfer follows a power-law with the number oftraining parallel languages. Moreover, we identify the discrepancy betweenactual monolingual performance and the power-law prediction as$\textbf{Monolingual Generalization Gap}$, indicating that English-centric LRMsfail to fully generalize across languages. Our study challenges the assumptionthat LRM reasoning mirrors human cognition, providing critical insights for thedevelopment of more language-agnostic LRMs.
摘要: 强化后训练（RPT）的最新进展显著提升了大型推理模型（LRM）的能力，激发了对基于强化学习的推理泛化性的日益增长的兴趣。尽管现有工作主要集中于研究其在不同任务或模态间的泛化性，但本研究提出了一种新颖的跨语言视角来探究推理的泛化性。这引出了一个关键问题：从英语RPT中获得的推理能力能否有效迁移到其他语言？我们通过在多语言推理基准上系统评估以英语为中心的LRM，并引入一种量化跨语言迁移能力的指标来解答这一问题。我们的研究结果表明，跨语言迁移能力在初始模型、目标语言和训练范式方面存在显著差异。通过干预性研究，我们发现初始英语能力较强的模型倾向于过度依赖英语特定模式，从而导致跨语言泛化能力下降。为解决这一问题，我们进行了全面的平行训练研究。实验结果得出三个关键发现：首先是“并行飞跃”，即从单语训练过渡到仅引入一种平行语言时性能的显著提升；其次是可预测的“并行扩展定律”，揭示跨语言推理迁移遵循与训练平行语言数量相关的幂律分布。此外，我们将实际单语性能与幂律预测之间的差异定义为“单语泛化差距”，表明以英语为中心的LRM未能完全实现跨语言泛化。我们的研究挑战了LRM推理与人类认知相似的假设，为开发更具语言普适性的LRM提供了关键见解。
Link: http://arxiv.org/abs/2510.02272v1
Updated: 2025-10-02T17:49:49Z

126: BioX-Bridge: Model Bridging for Unsupervised Cross-Modal Knowledge  Transfer across Biosignals
Authors: ['Chenqi Li', 'Yu Liu', 'Timothy Denison', 'Tingting Zhu']
Summary: Biosignals offer valuable insights into the physiological states of the humanbody. Although biosignal modalities differ in functionality, signal fidelity,sensor comfort, and cost, they are often intercorrelated, reflecting theholistic and interconnected nature of human physiology. This opens up thepossibility of performing the same tasks using alternative biosignalmodalities, thereby improving the accessibility, usability, and adaptability ofhealth monitoring systems. However, the limited availability of large labeleddatasets presents challenges for training models tailored to specific tasks andmodalities of interest. Unsupervised cross-modal knowledge transfer offers apromising solution by leveraging knowledge from an existing modality to supportmodel training for a new modality. Existing methods are typically based onknowledge distillation, which requires running a teacher model alongsidestudent model training, resulting in high computational and memory overhead.This challenge is further exacerbated by the recent development of foundationmodels that demonstrate superior performance and generalization across tasks atthe cost of large model sizes. To this end, we explore a new framework forunsupervised cross-modal knowledge transfer of biosignals by training alightweight bridge network to align the intermediate representations and enableinformation flow between foundation models and across modalities. Specifically,we introduce an efficient strategy for selecting alignment positions where thebridge should be constructed, along with a flexible prototype network as thebridge architecture. Extensive experiments across multiple biosignalmodalities, tasks, and datasets show that BioX-Bridge reduces the number oftrainable parameters by 88--99\% while maintaining or even improving transferperformance compared to state-of-the-art methods.
摘要: 生物信号为深入了解人体生理状态提供了宝贵的信息。尽管不同的生物信号模式在功能、信号保真度、传感器舒适度和成本方面存在差异，但它们通常是相互关联的，这反映了人体生理的整体性和相互关联性。这为使用替代性的生物信号模式执行相同任务开辟了可能性，从而提高了健康监测系统的可及性、可用性和适应性。然而，大型标记数据集的有限可用性给针对特定任务和感兴趣的模式训练模型带来了挑战。无监督跨模态知识转移通过利用现有模式的知识来支持新模式的模型训练，提供了一个有前景的解决方案。现有方法通常基于知识蒸馏，这需要在学生模型训练的同时运行教师模型，从而导致高昂的计算和内存开销。最近开发的基础模型在跨任务上展现出卓越的性能和泛化能力，但其庞大的模型规模进一步加剧了这一挑战。为此，我们通过训练一个轻量级的桥接网络来对齐中间表示并促进基础模型之间以及跨模态之间的信息流动，从而探索了一种新的生物信号无监督跨模态知识转移框架。具体而言，我们引入了一种高效的策略来选择应构建桥接的对齐位置，并采用一个灵活的原型网络作为桥接架构。在多个生物信号模式、任务和数据集上进行的大量实验表明，与最先进的方法相比，BioX-Bridge在保持甚至提高转移性能的同时，将可训练参数的数量减少了88%至99%。
Link: http://arxiv.org/abs/2510.02276v1
Updated: 2025-10-02T17:51:19Z

127: Addressing Pitfalls in the Evaluation of Uncertainty Estimation Methods  for Natural Language Generation
Authors: ['Mykyta Ielanskyi', 'Kajetan Schweighofer', 'Lukas Aichberger', 'Sepp Hochreiter']
Summary: Hallucinations are a common issue that undermine the reliability of largelanguage models (LLMs). Recent studies have identified a specific subset ofhallucinations, known as confabulations, which arise due to predictiveuncertainty of LLMs. To detect confabulations, various methods for estimatingpredictive uncertainty in natural language generation (NLG) have beendeveloped. These methods are typically evaluated by correlating uncertaintyestimates with the correctness of generated text, with question-answering (QA)datasets serving as the standard benchmark. However, commonly used approximatecorrectness functions have substantial disagreement between each other and,consequently, in the ranking of the uncertainty estimation methods. This allowsone to inflate the apparent performance of uncertainty estimation methods. Wepropose using several alternative risk indicators for risk correlationexperiments that improve robustness of empirical assessment of UE algorithmsfor NLG. For QA tasks, we show that marginalizing over multiple LLM-as-a-judgevariants leads to reducing the evaluation biases. Furthermore, we explorestructured tasks as well as out of distribution and perturbation detectiontasks which provide robust and controllable risk indicators. Finally, wepropose to use an Elo rating of uncertainty estimation methods to give anobjective summarization over extensive evaluation settings.
摘要: 幻觉是一个普遍存在的问题，它会削弱大型语言模型（LLM）的可靠性。最近的研究发现，幻觉的一个特定子集，即虚构，源于LLM的预测不确定性。为了检测虚构，研究人员开发了多种用于估计自然语言生成（NLG）中预测不确定性的方法。这些方法通常通过将不确定性估计值与生成文本的正确性进行关联来评估，其中问答（QA）数据集作为标准基准。然而，常用的近似正确性函数之间存在显著分歧，从而导致对不确定性估计方法的排序也不一致。这使得人们可以夸大不确定性估计方法的表面性能。我们建议在风险关联实验中使用多种替代风险指标，以提高对NLG中不确定性估计算法的实证评估的稳健性。对于QA任务，我们表明，对多个“LLM作为裁判”的变体进行边缘化处理可以减少评估偏差。此外，我们还探索了结构化任务以及分布外和扰动检测任务，这些任务提供了稳健且可控的风险指标。最后，我们提出使用不确定性估计方法的Elo评分来对广泛的评估设置进行客观总结。
Link: http://arxiv.org/abs/2510.02279v1
Updated: 2025-10-02T17:54:09Z

128: Self-Forcing++: Towards Minute-Scale High-Quality Video Generation
Authors: ['Justin Cui', 'Jie Wu', 'Ming Li', 'Tao Yang', 'Xiaojie Li', 'Rui Wang', 'Andrew Bai', 'Yuanhao Ban', 'Cho-Jui Hsieh']
Summary: Diffusion models have revolutionized image and video generation, achievingunprecedented visual quality. However, their reliance on transformerarchitectures incurs prohibitively high computational costs, particularly whenextending generation to long videos. Recent work has explored autoregressiveformulations for long video generation, typically by distilling fromshort-horizon bidirectional teachers. Nevertheless, given that teacher modelscannot synthesize long videos, the extrapolation of student models beyond theirtraining horizon often leads to pronounced quality degradation, arising fromthe compounding of errors within the continuous latent space. In this paper, wepropose a simple yet effective approach to mitigate quality degradation inlong-horizon video generation without requiring supervision from long-videoteachers or retraining on long video datasets. Our approach centers onexploiting the rich knowledge of teacher models to provide guidance for thestudent model through sampled segments drawn from self-generated long videos.Our method maintains temporal consistency while scaling video length by up to20x beyond teacher's capability, avoiding common issues such as over-exposureand error-accumulation without recomputing overlapping frames like previousmethods. When scaling up the computation, our method shows the capability ofgenerating videos up to 4 minutes and 15 seconds, equivalent to 99.9% of themaximum span supported by our base model's position embedding and more than 50xlonger than that of our baseline model. Experiments on standard benchmarks andour proposed improved benchmark demonstrate that our approach substantiallyoutperforms baseline methods in both fidelity and consistency. Our long-horizonvideos demo can be found at https://self-forcing-plus-plus.github.io/
摘要: 扩散模型彻底改变了图像和视频的生成，实现了前所未有的视觉质量。然而，它们对Transformer架构的依赖带来了极高的计算成本，尤其是在将生成长度扩展到长视频时。近期的研究探索了用于长视频生成的自回归公式，通常是通过从短时程双向教师模型中进行知识蒸馏。然而，由于教师模型无法合成长视频，学生模型在其训练时程之外的扩展往往会导致明显的质量下降，这是由连续潜在空间内误差的累积所造成的。在本文中，我们提出了一种简单而有效的方法，以缓解长时程视频生成中的质量下降问题，且无需长视频教师模型的监督或对长视频数据集进行重新训练。我们的方法核心在于利用教师模型的丰富知识，通过从自生成的长视频中抽取的片段为学生模型提供指导。我们的方法在保持时间一致性的同时，将视频长度扩展至教师模型能力的20倍，避免了过度曝光和误差累积等常见问题，并且无需像以往方法那样重新计算重叠帧。当增加计算量时，我们的方法展现了生成长达4分15秒视频的能力，这相当于我们基础模型位置嵌入所支持最大跨度的99.9%，并且比我们的基线模型长50倍以上。在标准基准和我们提出的改进基准上的实验表明，我们的方法在保真度和一致性方面均显著优于基线方法。我们的长时程视频演示可在https://self-forcing-plus-plus.github.io/查看。
Link: http://arxiv.org/abs/2510.02283v1
Updated: 2025-10-02T17:55:42Z

129: Learning to Generate Object Interactions with Physics-Guided Video  Diffusion
Authors: ['David Romero', 'Ariana Bermudez', 'Hao Li', 'Fabio Pizzati', 'Ivan Laptev']
Summary: Recent models for video generation have achieved remarkable progress and arenow deployed in film, social media production, and advertising. Beyond theircreative potential, such models also hold promise as world simulators forrobotics and embodied decision making. Despite strong advances, however,current approaches still struggle to generate physically plausible objectinteractions and lack physics-grounded control mechanisms. To address thislimitation, we introduce KineMask, an approach for physics-guided videogeneration that enables realistic rigid body control, interactions, andeffects. Given a single image and a specified object velocity, our methodgenerates videos with inferred motions and future object interactions. Wepropose a two-stage training strategy that gradually removes future motionsupervision via object masks. Using this strategy we train video diffusionmodels (VDMs) on synthetic scenes of simple interactions and demonstratesignificant improvements of object interactions in real scenes. Furthermore,KineMask integrates low-level motion control with high-level textualconditioning via predictive scene descriptions, leading to effective supportfor synthesis of complex dynamical phenomena. Extensive experiments show thatKineMask achieves strong improvements over recent models of comparable size.Ablation studies further highlight the complementary roles of low- andhigh-level conditioning in VDMs. Our code, model, and data will be madepublicly available.
摘要: 近期的视频生成模型已取得显著进展，并已应用于电影、社交媒体制作和广告领域。除了其创作潜力，此类模型作为机器人和具身决策的世界模拟器也展现出广阔前景。然而，尽管取得了长足进步，当前方法仍难以生成物理上合理的物体交互，且缺乏基于物理的控制机制。为解决这一局限，我们提出了KineMask，一种物理引导的视频生成方法，能够实现逼真的刚体控制、交互和效果。给定单张图像和指定的物体速度，我们的方法可生成具有推断运动及未来物体交互的视频。我们提出了一种两阶段训练策略，通过物体掩码逐步移除未来运动监督。利用该策略，我们在简单交互的合成场景上训练视频扩散模型（VDMs），并显著提升了真实场景中的物体交互效果。此外，KineMask通过预测性场景描述将低级运动控制与高级文本条件相结合，从而有效支持复杂动态现象的合成。大量实验表明，KineMask相比近期同等规模的模型实现了显著改进。消融研究进一步凸显了VDMs中低级与高级条件的互补作用。我们的代码、模型和数据将公开提供。
Link: http://arxiv.org/abs/2510.02284v1
Updated: 2025-10-02T17:56:46Z

130: Tree-based Dialogue Reinforced Policy Optimization for Red-Teaming  Attacks
Authors: ['Ruohao Guo', 'Afshin Oroojlooy', 'Roshan Sridhar', 'Miguel Ballesteros', 'Alan Ritter', 'Dan Roth']
Summary: Despite recent rapid progress in AI safety, current large language modelsremain vulnerable to adversarial attacks in multi-turn interaction settings,where attackers strategically adapt their prompts across conversation turns andpose a more critical yet realistic challenge. Existing approaches that discoversafety vulnerabilities either rely on manual red-teaming with human experts oremploy automated methods using pre-defined templates and human-curated attackdata, with most focusing on single-turn attacks. However, these methods did notexplore the vast space of possible multi-turn attacks, failing to considernovel attack trajectories that emerge from complex dialogue dynamics andstrategic conversation planning. This gap is particularly critical given recentfindings that LLMs exhibit significantly higher vulnerability to multi-turnattacks compared to single-turn attacks. We propose DialTree-RPO, an on-policyreinforcement learning framework integrated with tree search that autonomouslydiscovers diverse multi-turn attack strategies by treating the dialogue as asequential decision-making problem, enabling systematic exploration withoutmanually curated data. Through extensive experiments, our approach not onlyachieves more than 25.9% higher ASR across 10 target models compared toprevious state-of-the-art approaches, but also effectively uncovers new attackstrategies by learning optimal dialogue policies that maximize attack successacross multiple turns.
摘要: 尽管人工智能安全领域近期取得了快速进展，但当前的大型语言模型在多轮交互环境中仍然容易受到对抗性攻击，攻击者会在对话轮次中策略性地调整其提示，从而构成一个更为关键且现实的挑战。现有的安全漏洞发现方法要么依赖人类专家进行手动红队测试，要么采用基于预定义模板和人工筛选攻击数据的自动化方法，且多数聚焦于单轮攻击。然而，这些方法未能探索广阔的多轮攻击可能性空间，忽略了由复杂对话动态和策略性对话规划所产生的新型攻击轨迹。鉴于近期研究发现大型语言模型对多轮攻击的脆弱性显著高于单轮攻击，这一缺口尤为关键。我们提出了DialTree-RPO，一种集成树搜索的在策略强化学习框架，通过将对话视为序列决策问题，自主发现多样化的多轮攻击策略，从而无需人工筛选数据即可实现系统性探索。通过大量实验，我们的方法不仅在与10个目标模型的对比中，相较于以往最先进的方法实现了超过25.9%的更高攻击成功率，还通过学习跨多轮最大化攻击成功率的最优对话策略，有效揭示了新的攻击策略。
Link: http://arxiv.org/abs/2510.02286v1
Updated: 2025-10-02T17:57:05Z

131: F2LLM Technical Report: Matching SOTA Embedding Performance with 6  Million Open-Source Data
Authors: ['Ziyin Zhang', 'Zihan Liao', 'Hang Yu', 'Peng Di', 'Rui Wang']
Summary: We introduce F2LLM - Foundation to Feature Large Language Models, a suite ofstate-of-the-art embedding models in three sizes: 0.6B, 1.7B, and 4B. Unlikeprevious top-ranking embedding models that require massive contrastivepretraining, sophisticated training pipelines, and costly synthetic trainingdata, F2LLM is directly finetuned from foundation models on 6 millionquery-document-negative tuples curated from open-source, non-syntheticdatasets, striking a strong balance between training cost, model size, andembedding performance. On the MTEB English leaderboard, F2LLM-4B ranks 2ndamong models with approximately 4B parameters and 7th overall, while F2LLM-1.7Branks 1st among models in the 1B-2B size range. To facilitate future researchin the field, we release the models, training dataset, and code, positioningF2LLM as a strong, reproducible, and budget-friendly baseline for future works.
摘要: 我们推出F2LLM——从基础模型到特征大语言模型，这是一套最先进的嵌入模型，包含三种尺寸：0.6B、1.7B和4B。与以往需要大规模对比预训练、复杂训练流程和高成本合成训练数据的顶级嵌入模型不同，F2LLM直接在从开源、非合成数据集中精心筛选的600万查询-文档-负样本元组上对基础模型进行微调，在训练成本、模型尺寸和嵌入性能之间实现了卓越的平衡。在MTEB英文排行榜上，F2LLM-4B在参数量约4B的模型中排名第二，总排名第七；而F2LLM-1.7B在1B-2B尺寸范围内的模型中排名第一。为促进该领域的未来研究，我们发布了模型、训练数据集和代码，将F2LLM定位为未来研究工作中一个强大、可复现且经济实惠的基线模型。
Link: http://arxiv.org/abs/2510.02294v1
Updated: 2025-10-02T17:58:49Z

132: VideoNSA: Native Sparse Attention Scales Video Understanding
Authors: ['Enxin Song', 'Wenhao Chai', 'Shusheng Yang', 'Ethan Armand', 'Xiaojun Shan', 'Haiyang Xu', 'Jianwen Xie', 'Zhuowen Tu']
Summary: Video understanding in multimodal language models remains limited by contextlength: models often miss key transition frames and struggle to maintaincoherence across long time scales. To address this, we adapt Native SparseAttention (NSA) to video-language models. Our method, VideoNSA, adaptsQwen2.5-VL through end-to-end training on a 216K video instruction dataset. Weemploy a hardware-aware hybrid approach to attention, preserving denseattention for text, while employing NSA for video. Compared totoken-compression and training-free sparse baselines, VideoNSA achievesimproved performance on long-video understanding, temporal reasoning, andspatial benchmarks. Further ablation analysis reveals four key findings: (1)reliable scaling to 128K tokens; (2) an optimal global-local attentionallocation at a fixed budget; (3) task-dependent branch usage patterns; and (4)the learnable combined sparse attention help induce dynamic attention sinks.
摘要: 多模态语言模型中的视频理解仍受限于上下文长度：模型常常会遗漏关键的过渡帧，并且难以在长时间跨度上保持连贯性。为解决此问题，我们将原生稀疏注意力（NSA）适配于视频语言模型。我们的方法VideoNSA，通过在一个包含21.6万条视频指令的数据集上进行端到端训练，对Qwen2.5-VL模型进行了适配。我们采用了一种硬件感知的混合注意力方法，对文本保留密集注意力，同时对视频采用NSA。与令牌压缩和无训练稀疏基线相比，VideoNSA在长视频理解、时序推理和空间基准测试上均取得了更优的性能。进一步的消融分析揭示了四个关键发现：（1）可靠地扩展至12.8万个令牌；（2）在固定预算下实现全局-局部注意力的最优分配；（3）依赖于任务的分支使用模式；以及（4）可学习的组合稀疏注意力有助于诱导动态注意力汇聚点。
Link: http://arxiv.org/abs/2510.02295v1
Updated: 2025-10-02T17:58:54Z

133: Interactive Training: Feedback-Driven Neural Network Optimization
Authors: ['Wentao Zhang', 'Yang Young Lu', 'Yuntian Deng']
Summary: Traditional neural network training typically follows fixed, predefinedoptimization recipes, lacking the flexibility to dynamically respond toinstabilities or emerging training issues. In this paper, we introduceInteractive Training, an open-source framework that enables real-time,feedback-driven intervention during neural network training by human experts orautomated AI agents. At its core, Interactive Training uses a control server tomediate communication between users or agents and the ongoing training process,allowing users to dynamically adjust optimizer hyperparameters, training data,and model checkpoints. Through three case studies, we demonstrate thatInteractive Training achieves superior training stability, reduced sensitivityto initial hyperparameters, and improved adaptability to evolving user needs,paving the way toward a future training paradigm where AI agents autonomouslymonitor training logs, proactively resolve instabilities, and optimize trainingdynamics.
摘要: 传统的神经网络训练通常遵循固定的、预定义的优化方案，缺乏动态响应不稳定性或新出现的训练问题的灵活性。在本文中，我们介绍了交互式训练，这是一个开源框架，它允许人类专家或自动化AI代理在神经网络训练过程中进行实时的、反馈驱动的干预。其核心在于，交互式训练使用一个控制服务器来调解用户或代理与正在进行的训练过程之间的通信，从而允许用户动态调整优化器超参数、训练数据和模型检查点。通过三个案例研究，我们证明了交互式训练实现了卓越的训练稳定性、降低了对初始超参数的敏感性，并提高了对不断变化的用户需求的适应性，为未来的训练范式铺平了道路，即AI代理自主监控训练日志、主动解决不稳定性并优化训练动态。
Link: http://arxiv.org/abs/2510.02297v1
Updated: 2025-10-02T17:59:00Z

134: Equilibrium Matching: Generative Modeling with Implicit Energy-Based  Models
Authors: ['Runqian Wang', 'Yilun Du']
Summary: We introduce Equilibrium Matching (EqM), a generative modeling frameworkbuilt from an equilibrium dynamics perspective. EqM discards thenon-equilibrium, time-conditional dynamics in traditional diffusion andflow-based generative models and instead learns the equilibrium gradient of animplicit energy landscape. Through this approach, we can adopt anoptimization-based sampling process at inference time, where samples areobtained by gradient descent on the learned landscape with adjustable stepsizes, adaptive optimizers, and adaptive compute. EqM surpasses the generationperformance of diffusion/flow models empirically, achieving an FID of 1.90 onImageNet 256$\times$256. EqM is also theoretically justified to learn andsample from the data manifold. Beyond generation, EqM is a flexible frameworkthat naturally handles tasks including partially noised image denoising, OODdetection, and image composition. By replacing time-conditional velocities witha unified equilibrium landscape, EqM offers a tighter bridge between flow andenergy-based models and a simple route to optimization-driven inference.
摘要: 我们提出了平衡匹配（EqM），这是一个从平衡动力学视角构建的生成建模框架。EqM摒弃了传统扩散模型和基于流的生成模型中的非平衡、时间条件动力学，转而学习隐式能量景观的平衡梯度。通过这种方法，我们可以在推理时采用基于优化的采样过程，其中样本通过在学习的景观上进行梯度下降获得，并支持可调节步长、自适应优化器和自适应计算。实验表明，EqM在生成性能上超越了扩散/流模型，在ImageNet 256$\times$256上实现了1.90的FID分数。EqM在理论上也被证明能够从数据流形中学习和采样。除了生成任务，EqM还是一个灵活的框架，能自然处理部分噪声图像去噪、分布外检测和图像合成等任务。通过用统一的平衡景观替代时间条件速度，EqM在流模型和基于能量的模型之间架起了更紧密的桥梁，并为基于优化的推理提供了简单途径。
Link: http://arxiv.org/abs/2510.02300v1
Updated: 2025-10-02T17:59:06Z

135: Diffusion Models and the Manifold Hypothesis: Log-Domain Smoothing is  Geometry Adaptive
Authors: ['Tyler Farghly', 'Peter Potaptchik', 'Samuel Howard', 'George Deligiannidis', 'Jakiw Pidstrigach']
Summary: Diffusion models have achieved state-of-the-art performance, demonstratingremarkable generalisation capabilities across diverse domains. However, themechanisms underpinning these strong capabilities remain only partiallyunderstood. A leading conjecture, based on the manifold hypothesis, attributesthis success to their ability to adapt to low-dimensional geometric structurewithin the data. This work provides evidence for this conjecture, focusing onhow such phenomena could result from the formulation of the learning problemthrough score matching. We inspect the role of implicit regularisation byinvestigating the effect of smoothing minimisers of the empirical scorematching objective. Our theoretical and empirical results confirm thatsmoothing the score function -- or equivalently, smoothing in the log-densitydomain -- produces smoothing tangential to the data manifold. In addition, weshow that the manifold along which the diffusion model generalises can becontrolled by choosing an appropriate smoothing.
摘要: 扩散模型已实现最先进的性能，在多个领域展现出卓越的泛化能力。然而，支撑这些强大能力的机制仍仅得到部分理解。基于流形假说的一个主流猜想认为，其成功源于它们适应数据内部低维几何结构的能力。本研究为该猜想提供了证据，重点探讨了此类现象如何通过基于分数匹配的学习问题表述而产生。我们通过研究经验分数匹配目标函数平滑最小化器的影响，检验了隐式正则化的作用。我们的理论和实证结果证实，对分数函数进行平滑处理——或在等价情况下，在对数密度域进行平滑处理——会产生沿数据流形的切向平滑。此外，我们还表明，通过选择适当的平滑方法，可以控制扩散模型泛化所沿的流形。
Link: http://arxiv.org/abs/2510.02305v1
Updated: 2025-10-02T17:59:39Z

136: NoiseShift: Resolution-Aware Noise Recalibration for Better  Low-Resolution Image Generation
Authors: ['Ruozhen He', 'Moayed Haji-Ali', 'Ziyan Yang', 'Vicente Ordonez']
Summary: Text-to-image diffusion models trained on a fixed set of resolutions oftenfail to generalize, even when asked to generate images at lower resolutionsthan those seen during training. High-resolution text-to-image generators arecurrently unable to easily offer an out-of-the-box budget-efficient alternativeto their users who might not need high-resolution images. We identify a keytechnical insight in diffusion models that when addressed can help tackle thislimitation: Noise schedulers have unequal perceptual effects acrossresolutions. The same level of noise removes disproportionately more signalfrom lower-resolution images than from high-resolution images, leading to atrain-test mismatch. We propose NoiseShift, a training-free method thatrecalibrates the noise level of the denoiser conditioned on resolution size.NoiseShift requires no changes to model architecture or sampling schedule andis compatible with existing models. When applied to Stable Diffusion 3, StableDiffusion 3.5, and Flux-Dev, quality at low resolutions is significantlyimproved. On LAION-COCO, NoiseShift improves SD3.5 by 15.89%, SD3 by 8.56%, andFlux-Dev by 2.44% in FID on average. On CelebA, NoiseShift improves SD3.5 by10.36%, SD3 by 5.19%, and Flux-Dev by 3.02% in FID on average. These resultsdemonstrate the effectiveness of NoiseShift in mitigating resolution-dependentartifacts and enhancing the quality of low-resolution image generation.
摘要: 在固定分辨率集上训练的文本到图像扩散模型通常无法泛化，即使在要求生成低于训练期间所见分辨率的图像时也是如此。目前，高分辨率文本到图像生成器无法为其可能不需要高分辨率图像的用户轻松提供开箱即用且经济高效的替代方案。我们发现了扩散模型中的一个关键技术见解：解决该问题有助于克服这一局限性，即噪声调度器在不同分辨率下具有不等的感知效应。同等水平的噪声从低分辨率图像中去除的信号不成比例地多于从高分辨率图像中去除的信号，从而导致训练-测试不匹配。我们提出了NoiseShift，这是一种无需训练的方法，可根据分辨率大小对去噪器的噪声水平进行重新校准。NoiseShift无需更改模型架构或采样计划，并与现有模型兼容。当应用于Stable Diffusion 3、Stable Diffusion 3.5和Flux-Dev时，低分辨率下的图像质量得到显著提升。在LAION-COCO数据集上，NoiseShift在FID指标上平均将SD3.5的性能提升15.89%，SD3提升8.56%，Flux-Dev提升2.44%。在CelebA数据集上，NoiseShift在FID指标上平均将SD3.5的性能提升10.36%，SD3提升5.19%，Flux-Dev提升3.02%。这些结果证明了NoiseShift在减轻分辨率相关伪影并提升低分辨率图像生成质量方面的有效性。
Link: http://arxiv.org/abs/2510.02307v1
Updated: 2025-10-02T17:59:43Z

